#!/usr/bin/env python3
"""
é‚»å±…æ•°æ®åˆ†æè„šæœ¬
===============

åˆ†æé¢„è®¡ç®—çš„é‚»å±…å…³ç³»æ•°æ®ï¼Œäº†è§£ï¼š
- é‚»å±…åˆ†å¸ƒç»Ÿè®¡
- ç©ºé—´åˆ†å¸ƒç‰¹å¾
- æ•°æ®è´¨é‡è¯„ä¼°
- ä¸ºè®­ç»ƒé›†åˆ›å»ºæä¾›æŒ‡å¯¼
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pandas as pd
from typing import Dict, List, Tuple
import logging

# è®¾ç½®æ—¥å¿—å’Œç»˜å›¾
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

plt.rcParams['font.size'] = 12
plt.rcParams['figure.figsize'] = (12, 8)
sns.set_style("whitegrid")

def load_neighbor_data(file_path: str) -> Dict:
    """åŠ è½½é‚»å±…æ•°æ®æ–‡ä»¶"""
    logger.info(f"åŠ è½½é‚»å±…æ•°æ®: {file_path}")
    data = torch.load(file_path, map_location='cpu')
    
    # æå–åŸºæœ¬ä¿¡æ¯
    info = {
        'radius': data['radius'],
        'kmax': data['kmax'],
        'indices': data['indices'],
        'row_splits': data['row_splits'],
        'count': data['count'],
        'mean_log_scale': data['mean_log_scale'],
        'scale_sum': data['scale_sum'],
    }
    
    # å¦‚æœæ˜¯é‡‡æ ·ç‰ˆæœ¬ï¼Œè¿˜æœ‰é‡‡æ ·ç´¢å¼•
    if 'colmap_sample_indices' in data:
        info['colmap_sample_indices'] = data['colmap_sample_indices']
        info['gauss_sample_indices'] = data['gauss_sample_indices']
        info['is_sampled'] = True
    else:
        info['is_sampled'] = False
    
    return info

def analyze_neighbor_distribution(neighbor_data: Dict) -> Dict:
    """åˆ†æé‚»å±…æ•°é‡åˆ†å¸ƒ"""
    counts = neighbor_data['count'].numpy()
    
    stats = {
        'total_points': len(counts),
        'total_edges': len(neighbor_data['indices']),
        'mean_neighbors': float(counts.mean()),
        'median_neighbors': float(np.median(counts)),
        'std_neighbors': float(counts.std()),
        'min_neighbors': int(counts.min()),
        'max_neighbors': int(counts.max()),
        'zero_neighbor_points': int(np.sum(counts == 0)),
        'zero_neighbor_ratio': float(np.sum(counts == 0) / len(counts)),
    }
    
    # ç™¾åˆ†ä½æ•°
    percentiles = [5, 10, 25, 75, 90, 95, 99]
    for p in percentiles:
        stats[f'p{p}_neighbors'] = float(np.percentile(counts, p))
    
    return stats

def analyze_spatial_statistics(neighbor_data: Dict) -> Dict:
    """åˆ†æç©ºé—´ç»Ÿè®¡ä¿¡æ¯"""
    mean_log_scale = neighbor_data['mean_log_scale'].numpy()
    scale_sum = neighbor_data['scale_sum'].numpy()
    
    # è¿‡æ»¤æ‰æ²¡æœ‰é‚»å±…çš„ç‚¹
    has_neighbors = neighbor_data['count'] > 0
    has_neighbors_np = has_neighbors.numpy()  # è½¬æ¢ä¸ºnumpy
    valid_mean_log_scale = mean_log_scale[has_neighbors_np]
    valid_scale_sum = scale_sum[has_neighbors_np]
    
    spatial_stats = {
        'valid_points': int(np.sum(has_neighbors_np)),
        'mean_log_scale_mean': float(valid_mean_log_scale.mean()) if len(valid_mean_log_scale) > 0 else 0,
        'mean_log_scale_std': float(valid_mean_log_scale.std()) if len(valid_mean_log_scale) > 0 else 0,
        'scale_sum_mean': float(valid_scale_sum.mean()) if len(valid_scale_sum) > 0 else 0,
        'scale_sum_std': float(valid_scale_sum.std()) if len(valid_scale_sum) > 0 else 0,
    }
    
    return spatial_stats

def plot_neighbor_distribution(neighbor_data: Dict, save_path: str):
    """ç»˜åˆ¶é‚»å±…æ•°é‡åˆ†å¸ƒå›¾"""
    counts = neighbor_data['count'].numpy()
    radius = neighbor_data['radius']
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. ç›´æ–¹å›¾
    axes[0,0].hist(counts, bins=50, alpha=0.7, edgecolor='black')
    axes[0,0].set_xlabel('é‚»å±…æ•°é‡')
    axes[0,0].set_ylabel('é¢‘æ¬¡')
    axes[0,0].set_title(f'é‚»å±…æ•°é‡åˆ†å¸ƒ (åŠå¾„={radius:.3f})')
    axes[0,0].axvline(counts.mean(), color='red', linestyle='--', label=f'å‡å€¼={counts.mean():.1f}')
    axes[0,0].axvline(np.median(counts), color='green', linestyle='--', label=f'ä¸­ä½æ•°={np.median(counts):.1f}')
    axes[0,0].legend()
    
    # 2. ç´¯ç§¯åˆ†å¸ƒ
    sorted_counts = np.sort(counts)
    cumulative = np.arange(1, len(sorted_counts) + 1) / len(sorted_counts)
    axes[0,1].plot(sorted_counts, cumulative)
    axes[0,1].set_xlabel('é‚»å±…æ•°é‡')
    axes[0,1].set_ylabel('ç´¯ç§¯æ¦‚ç‡')
    axes[0,1].set_title('é‚»å±…æ•°é‡ç´¯ç§¯åˆ†å¸ƒ')
    axes[0,1].grid(True)
    
    # 3. å¯¹æ•°å°ºåº¦ç›´æ–¹å›¾
    nonzero_counts = counts[counts > 0]
    if len(nonzero_counts) > 0:
        axes[1,0].hist(nonzero_counts, bins=50, alpha=0.7, edgecolor='black')
        axes[1,0].set_xlabel('é‚»å±…æ•°é‡')
        axes[1,0].set_ylabel('é¢‘æ¬¡')
        axes[1,0].set_title('éé›¶é‚»å±…æ•°é‡åˆ†å¸ƒ')
        axes[1,0].set_yscale('log')
    
    # 4. ç®±çº¿å›¾
    axes[1,1].boxplot(counts, vert=True)
    axes[1,1].set_ylabel('é‚»å±…æ•°é‡')
    axes[1,1].set_title('é‚»å±…æ•°é‡ç®±çº¿å›¾')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"é‚»å±…åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")

def plot_spatial_analysis(neighbor_data: Dict, save_path: str):
    """ç»˜åˆ¶ç©ºé—´åˆ†æå›¾"""
    counts = neighbor_data['count'].numpy()
    mean_log_scale = neighbor_data['mean_log_scale'].numpy()
    scale_sum = neighbor_data['scale_sum'].numpy()
    radius = neighbor_data['radius']
    
    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    valid_mask = counts > 0
    valid_counts = counts[valid_mask]
    valid_mean_log_scale = mean_log_scale[valid_mask]
    valid_scale_sum = scale_sum[valid_mask]
    
    if len(valid_counts) == 0:
        logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„é‚»å±…æ•°æ®ç”¨äºç©ºé—´åˆ†æ")
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. é‚»å±…æ•° vs å¹³å‡å¯¹æ•°å°ºåº¦
    axes[0,0].scatter(valid_counts, valid_mean_log_scale, alpha=0.5, s=1)
    axes[0,0].set_xlabel('é‚»å±…æ•°é‡')
    axes[0,0].set_ylabel('å¹³å‡å¯¹æ•°å°ºåº¦')
    axes[0,0].set_title(f'é‚»å±…æ•°é‡ vs å¹³å‡å¯¹æ•°å°ºåº¦ (åŠå¾„={radius:.3f})')
    
    # 2. é‚»å±…æ•° vs å°ºåº¦æ€»å’Œ
    axes[0,1].scatter(valid_counts, valid_scale_sum, alpha=0.5, s=1)
    axes[0,1].set_xlabel('é‚»å±…æ•°é‡')
    axes[0,1].set_ylabel('å°ºåº¦æ€»å’Œ')
    axes[0,1].set_title('é‚»å±…æ•°é‡ vs å°ºåº¦æ€»å’Œ')
    
    # 3. å¹³å‡å¯¹æ•°å°ºåº¦åˆ†å¸ƒ
    axes[1,0].hist(valid_mean_log_scale, bins=50, alpha=0.7, edgecolor='black')
    axes[1,0].set_xlabel('å¹³å‡å¯¹æ•°å°ºåº¦')
    axes[1,0].set_ylabel('é¢‘æ¬¡')
    axes[1,0].set_title('å¹³å‡å¯¹æ•°å°ºåº¦åˆ†å¸ƒ')
    
    # 4. å°ºåº¦æ€»å’Œåˆ†å¸ƒ
    axes[1,1].hist(valid_scale_sum, bins=50, alpha=0.7, edgecolor='black')
    axes[1,1].set_xlabel('å°ºåº¦æ€»å’Œ')
    axes[1,1].set_ylabel('é¢‘æ¬¡')
    axes[1,1].set_title('å°ºåº¦æ€»å’Œåˆ†å¸ƒ')
    axes[1,1].set_yscale('log')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"ç©ºé—´åˆ†æå›¾å·²ä¿å­˜: {save_path}")

def analyze_multi_radius_comparison(data_files: List[str], save_dir: str):
    """æ¯”è¾ƒä¸åŒåŠå¾„çš„é‚»å±…åˆ†å¸ƒ"""
    all_data = []
    
    for file_path in data_files:
        neighbor_data = load_neighbor_data(file_path)
        dist_stats = analyze_neighbor_distribution(neighbor_data)
        spatial_stats = analyze_spatial_statistics(neighbor_data)
        
        combined_stats = {
            'radius': neighbor_data['radius'],
            'kmax': neighbor_data['kmax'],
            **dist_stats,
            **spatial_stats
        }
        all_data.append(combined_stats)
    
    # è½¬æ¢ä¸ºDataFrameç”¨äºåˆ†æ
    df = pd.DataFrame(all_data)
    
    # ä¿å­˜ç»Ÿè®¡è¡¨
    csv_path = Path(save_dir) / "multi_radius_stats.csv"
    df.to_csv(csv_path, index=False)
    logger.info(f"å¤šåŠå¾„ç»Ÿè®¡è¡¨å·²ä¿å­˜: {csv_path}")
    
    # ç»˜åˆ¶æ¯”è¾ƒå›¾
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. å¹³å‡é‚»å±…æ•° vs åŠå¾„
    axes[0,0].plot(df['radius'], df['mean_neighbors'], 'bo-', linewidth=2, markersize=8)
    axes[0,0].set_xlabel('åŠå¾„')
    axes[0,0].set_ylabel('å¹³å‡é‚»å±…æ•°')
    axes[0,0].set_title('å¹³å‡é‚»å±…æ•° vs åŠå¾„')
    axes[0,0].set_xscale('log')
    axes[0,0].grid(True)
    
    # 2. æ€»è¾¹æ•° vs åŠå¾„
    axes[0,1].plot(df['radius'], df['total_edges'], 'ro-', linewidth=2, markersize=8)
    axes[0,1].set_xlabel('åŠå¾„')
    axes[0,1].set_ylabel('æ€»è¾¹æ•°')
    axes[0,1].set_title('æ€»è¾¹æ•° vs åŠå¾„')
    axes[0,1].set_xscale('log')
    axes[0,1].set_yscale('log')
    axes[0,1].grid(True)
    
    # 3. é›¶é‚»å±…æ¯”ä¾‹ vs åŠå¾„
    axes[0,2].plot(df['radius'], df['zero_neighbor_ratio'] * 100, 'go-', linewidth=2, markersize=8)
    axes[0,2].set_xlabel('åŠå¾„')
    axes[0,2].set_ylabel('é›¶é‚»å±…æ¯”ä¾‹ (%)')
    axes[0,2].set_title('é›¶é‚»å±…æ¯”ä¾‹ vs åŠå¾„')
    axes[0,2].set_xscale('log')
    axes[0,2].grid(True)
    
    # 4. ä¸­ä½æ•°é‚»å±…æ•° vs åŠå¾„
    axes[1,0].plot(df['radius'], df['median_neighbors'], 'mo-', linewidth=2, markersize=8)
    axes[1,0].set_xlabel('åŠå¾„')
    axes[1,0].set_ylabel('ä¸­ä½æ•°é‚»å±…æ•°')
    axes[1,0].set_title('ä¸­ä½æ•°é‚»å±…æ•° vs åŠå¾„')
    axes[1,0].set_xscale('log')
    axes[1,0].grid(True)
    
    # 5. æœ€å¤§é‚»å±…æ•° vs åŠå¾„
    axes[1,1].plot(df['radius'], df['max_neighbors'], 'co-', linewidth=2, markersize=8)
    axes[1,1].set_xlabel('åŠå¾„')
    axes[1,1].set_ylabel('æœ€å¤§é‚»å±…æ•°')
    axes[1,1].set_title('æœ€å¤§é‚»å±…æ•° vs åŠå¾„')
    axes[1,1].set_xscale('log')
    axes[1,1].grid(True)
    
    # 6. é‚»å±…æ•°æ ‡å‡†å·® vs åŠå¾„
    axes[1,2].plot(df['radius'], df['std_neighbors'], 'yo-', linewidth=2, markersize=8)
    axes[1,2].set_xlabel('åŠå¾„')
    axes[1,2].set_ylabel('é‚»å±…æ•°æ ‡å‡†å·®')
    axes[1,2].set_title('é‚»å±…æ•°æ ‡å‡†å·® vs åŠå¾„')
    axes[1,2].set_xscale('log')
    axes[1,2].grid(True)
    
    plt.tight_layout()
    comparison_path = Path(save_dir) / "multi_radius_comparison.png"
    plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"å¤šåŠå¾„æ¯”è¾ƒå›¾å·²ä¿å­˜: {comparison_path}")
    
    return df

def main():
    # é…ç½®è·¯å¾„
    data_dir = Path("batches")
    output_dir = Path("neighbor_analysis")
    output_dir.mkdir(exist_ok=True)
    
    logger.info("ğŸ” å¼€å§‹é‚»å±…æ•°æ®åˆ†æ...")
    
    # æ‰¾åˆ°æ‰€æœ‰å¿«é€Ÿé‚»å±…æ•°æ®æ–‡ä»¶
    fast_files = sorted(list(data_dir.glob("*_fast.pt")))
    if not fast_files:
        logger.error("æœªæ‰¾åˆ°å¿«é€Ÿé‚»å±…æ•°æ®æ–‡ä»¶")
        return
    
    logger.info(f"æ‰¾åˆ° {len(fast_files)} ä¸ªå¿«é€Ÿé‚»å±…æ•°æ®æ–‡ä»¶")
    
    # åˆ†ææ¯ä¸ªåŠå¾„çš„æ•°æ®
    all_stats = []
    
    for file_path in fast_files:
        logger.info(f"åˆ†ææ–‡ä»¶: {file_path}")
        
        # åŠ è½½æ•°æ®
        neighbor_data = load_neighbor_data(str(file_path))
        radius = neighbor_data['radius']
        
        # åˆ†æåˆ†å¸ƒ
        dist_stats = analyze_neighbor_distribution(neighbor_data)
        spatial_stats = analyze_spatial_statistics(neighbor_data)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        combined_stats = {
            'file': file_path.name,
            'radius': radius,
            **dist_stats,
            **spatial_stats
        }
        all_stats.append(combined_stats)
        
        # ç”Ÿæˆå•ç‹¬çš„å¯è§†åŒ–
        file_prefix = file_path.stem
        
        # é‚»å±…åˆ†å¸ƒå›¾
        dist_plot_path = output_dir / f"{file_prefix}_distribution.png"
        plot_neighbor_distribution(neighbor_data, str(dist_plot_path))
        
        # ç©ºé—´åˆ†æå›¾
        spatial_plot_path = output_dir / f"{file_prefix}_spatial.png"
        plot_spatial_analysis(neighbor_data, str(spatial_plot_path))
        
        # æ‰“å°å…³é”®ç»Ÿè®¡
        logger.info(f"  åŠå¾„ {radius:.6f}:")
        logger.info(f"    å¹³å‡é‚»å±…æ•°: {dist_stats['mean_neighbors']:.2f}")
        logger.info(f"    ä¸­ä½æ•°é‚»å±…æ•°: {dist_stats['median_neighbors']:.2f}")
        logger.info(f"    é›¶é‚»å±…æ¯”ä¾‹: {dist_stats['zero_neighbor_ratio']*100:.1f}%")
        logger.info(f"    æ€»è¾¹æ•°: {dist_stats['total_edges']:,}")
    
    # å¤šåŠå¾„æ¯”è¾ƒåˆ†æ
    logger.info("è¿›è¡Œå¤šåŠå¾„æ¯”è¾ƒåˆ†æ...")
    comparison_df = analyze_multi_radius_comparison([str(f) for f in fast_files], str(output_dir))
    
    # ä¿å­˜å®Œæ•´ç»Ÿè®¡
    full_stats_path = output_dir / "detailed_stats.csv"
    full_df = pd.DataFrame(all_stats)
    full_df.to_csv(full_stats_path, index=False)
    
    logger.info(f"âœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
    logger.info(f"ğŸ“Š è¯¦ç»†ç»Ÿè®¡: {full_stats_path}")
    logger.info(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: {output_dir}/*.png")
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š é‚»å±…æ•°æ®åˆ†ææ€»ç»“")
    print("="*60)
    
    for stats in all_stats:
        print(f"\nğŸ” åŠå¾„ {stats['radius']:.6f}:")
        print(f"  â€¢ å¹³å‡é‚»å±…æ•°: {stats['mean_neighbors']:.2f}")
        print(f"  â€¢ ä¸­ä½æ•°é‚»å±…æ•°: {stats['median_neighbors']:.2f}")
        print(f"  â€¢ æœ€å¤§é‚»å±…æ•°: {stats['max_neighbors']}")
        print(f"  â€¢ é›¶é‚»å±…æ¯”ä¾‹: {stats['zero_neighbor_ratio']*100:.1f}%")
        print(f"  â€¢ æ€»è¾¹æ•°: {stats['total_edges']:,}")
        print(f"  â€¢ æœ‰æ•ˆç‚¹æ•°: {stats['valid_points']:,}")

if __name__ == "__main__":
    main() 