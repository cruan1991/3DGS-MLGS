#!/usr/bin/env python3
"""
Student Networkè®­ç»ƒè„šæœ¬
======================

è®­ç»ƒCOLMAP â†’ 3DGSç‰¹å¾æ˜ å°„çš„ç¥ç»ç½‘ç»œ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import json
import logging
from pathlib import Path
import argparse
from typing import Dict, List, Tuple
import time
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from create_training_dataset import StudentNetworkDataset
from student_network import StudentNetwork, StudentNetworkLoss, StudentNetworkEvaluator, create_model

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StudentNetworkTrainer:
    """Student Networkè®­ç»ƒå™¨"""
    
    def __init__(self, 
                 model: StudentNetwork,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 criterion: StudentNetworkLoss,
                 optimizer: optim.Optimizer,
                 scheduler: optim.lr_scheduler._LRScheduler = None,
                 device: str = 'cuda',
                 save_dir: str = 'student_checkpoints'):
        
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # è®­ç»ƒå†å²
        self.train_history = {
            'epoch': [],
            'train_loss': [],
            'val_loss': [],
            'learning_rate': []
        }
        
        # æœ€ä½³æ¨¡å‹è·Ÿè¸ª
        self.best_val_loss = float('inf')
        self.best_epoch = 0
        
        logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {device}")
        logger.info(f"è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}, éªŒè¯æ ·æœ¬: {len(val_loader.dataset)}")
    
    def train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        epoch_losses = {
            'total_loss': 0.0,
            'position_mse': 0.0,
            'position_smooth': 0.0,
            'scale_mse': 0.0,
            'scale_smooth': 0.0,
            'stats_mse': 0.0
        }
        
        num_batches = 0
        progress_bar = tqdm(self.train_loader, desc="è®­ç»ƒ")
        
        for batch in progress_bar:
            # æ•°æ®è½¬ç§»åˆ°è®¾å¤‡
            inputs = batch['input'].to(self.device)
            targets = batch['target'].to(self.device)
            radii = batch['radius'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            predictions = self.model(inputs, radii)
            
            # è®¡ç®—æŸå¤±
            losses = self.criterion(predictions, targets)
            
            # åå‘ä¼ æ’­
            losses['total_loss'].backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            # ä¼˜åŒ–å™¨æ­¥éª¤
            self.optimizer.step()
            
            # ç´¯åŠ æŸå¤±
            for key, value in losses.items():
                epoch_losses[key] += value.item()
            
            num_batches += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{losses['total_loss'].item():.4f}"
            })
        
        # å¹³å‡æŸå¤±
        avg_losses = {key: value / num_batches for key, value in epoch_losses.items()}
        
        return avg_losses
    
    def validate_epoch(self) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        evaluator = StudentNetworkEvaluator(self.model, self.device)
        return evaluator.evaluate(self.val_loader, self.criterion)
    
    def train(self, num_epochs: int, 
              save_every: int = 10,
              early_stopping_patience: int = 20) -> Dict[str, List]:
        """å®Œæ•´è®­ç»ƒå¾ªç¯"""
        logger.info(f"å¼€å§‹è®­ç»ƒ {num_epochs} ä¸ªepochs...")
        
        early_stopping_counter = 0
        
        for epoch in range(num_epochs):
            start_time = time.time()
            
            # è®­ç»ƒ
            train_losses = self.train_epoch()
            
            # éªŒè¯
            val_losses = self.validate_epoch()
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if self.scheduler is not None:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_losses['total_loss'])
                else:
                    self.scheduler.step()
            
            # è®°å½•å†å²
            self.train_history['epoch'].append(epoch + 1)
            self.train_history['train_loss'].append(train_losses['total_loss'])
            self.train_history['val_loss'].append(val_losses['total_loss'])
            self.train_history['learning_rate'].append(self.optimizer.param_groups[0]['lr'])
            
            # è®¡ç®—æ—¶é—´
            epoch_time = time.time() - start_time
            
            # æ—¥å¿—è¾“å‡º
            logger.info(f"Epoch {epoch+1}/{num_epochs} ({epoch_time:.1f}s)")
            logger.info(f"  è®­ç»ƒæŸå¤±: {train_losses['total_loss']:.4f}")
            logger.info(f"  éªŒè¯æŸå¤±: {val_losses['total_loss']:.4f}")
            logger.info(f"  å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_losses['total_loss'] < self.best_val_loss:
                self.best_val_loss = val_losses['total_loss']
                self.best_epoch = epoch + 1
                self.save_checkpoint(epoch + 1, is_best=True)
                early_stopping_counter = 0
                logger.info(f"  ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
            else:
                early_stopping_counter += 1
            
            # å®šæœŸä¿å­˜
            if (epoch + 1) % save_every == 0:
                self.save_checkpoint(epoch + 1, is_best=False)
            
            # æ—©åœ
            if early_stopping_counter >= early_stopping_patience:
                logger.info(f"æ—©åœè§¦å‘! è¿ç»­ {early_stopping_patience} ä¸ªepochséªŒè¯æŸå¤±æœªæ”¹å–„")
                break
        
        logger.info(f"è®­ç»ƒå®Œæˆ! æœ€ä½³æ¨¡å‹åœ¨epoch {self.best_epoch}, éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_training_history()
        
        return self.train_history
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_val_loss': self.best_val_loss,
            'train_history': self.train_history
        }
        
        # ä¿å­˜å½“å‰æ£€æŸ¥ç‚¹
        checkpoint_path = self.save_dir / f"checkpoint_epoch_{epoch}.pth"
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.save_dir / "best_model.pth"
            torch.save(checkpoint, best_path)
            logger.info(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")
    
    def save_training_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_path = self.save_dir / "training_history.json"
        with open(history_path, 'w') as f:
            json.dump(self.train_history, f, indent=2)
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves()
        
        logger.info(f"è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
    
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 1, figsize=(12, 8))
        
        # æŸå¤±æ›²çº¿
        epochs = self.train_history['epoch']
        axes[0].plot(epochs, self.train_history['train_loss'], label='è®­ç»ƒæŸå¤±', color='blue')
        axes[0].plot(epochs, self.train_history['val_loss'], label='éªŒè¯æŸå¤±', color='red')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('æŸå¤±')
        axes[0].set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
        axes[0].legend()
        axes[0].grid(True)
        
        # å­¦ä¹ ç‡æ›²çº¿
        axes[1].plot(epochs, self.train_history['learning_rate'], label='å­¦ä¹ ç‡', color='green')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('å­¦ä¹ ç‡')
        axes[1].set_title('å­¦ä¹ ç‡å˜åŒ–')
        axes[1].legend()
        axes[1].grid(True)
        axes[1].set_yscale('log')
        
        plt.tight_layout()
        plt.savefig(self.save_dir / "training_curves.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {self.save_dir / 'training_curves.png'}")

def load_datasets(data_dir: str, batch_size: int = 64, num_workers: int = 4) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """åŠ è½½è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†"""
    data_dir = Path(data_dir)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = StudentNetworkDataset(str(data_dir / "train.h5"))
    val_dataset = StudentNetworkDataset(str(data_dir / "val.h5"))
    test_dataset = StudentNetworkDataset(str(data_dir / "test.h5"))
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    logger.info(f"æ•°æ®é›†åŠ è½½å®Œæˆ:")
    logger.info(f"  è®­ç»ƒ: {len(train_dataset)} æ ·æœ¬")
    logger.info(f"  éªŒè¯: {len(val_dataset)} æ ·æœ¬")
    logger.info(f"  æµ‹è¯•: {len(test_dataset)} æ ·æœ¬")
    
    return train_loader, val_loader, test_loader

def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒStudent Network')
    parser.add_argument('--data_dir', type=str, default='training_data',
                       help='è®­ç»ƒæ•°æ®ç›®å½•')
    parser.add_argument('--save_dir', type=str, default='student_checkpoints',
                       help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=64,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning_rate', type=float, default=1e-3,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®­ç»ƒè®¾å¤‡')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--save_every', type=int, default=10,
                       help='æ¯éš”å¤šå°‘epochsä¿å­˜ä¸€æ¬¡')
    parser.add_argument('--early_stopping', type=int, default=20,
                       help='æ—©åœè€å¿ƒå€¼')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = args.device if torch.cuda.is_available() else 'cpu'
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½å…ƒæ•°æ®
    metadata_file = Path(args.data_dir) / "metadata.json"
    with open(metadata_file, 'r') as f:
        metadata = json.load(f)
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = {
        'input_dim': metadata['feature_dims']['input_dim'],
        'output_dim': metadata['feature_dims']['output_dim'],
        'feature_dims': [64, 128, 256],
        'decoder_dims': [256, 128, 64],
        'num_radii': len(metadata['radii_used']),
        'use_radius_aware': True
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(model_config)
    
    # åŠ è½½æ•°æ®
    train_loader, val_loader, test_loader = load_datasets(
        args.data_dir, 
        args.batch_size, 
        args.num_workers
    )
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = StudentNetworkLoss(
        mse_weight=1.0,
        smooth_l1_weight=0.5,
        position_weight=2.0,
        scale_weight=1.5
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=10,
        verbose=True
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = StudentNetworkTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        device=device,
        save_dir=args.save_dir
    )
    
    # å¼€å§‹è®­ç»ƒ
    training_history = trainer.train(
        num_epochs=args.num_epochs,
        save_every=args.save_every,
        early_stopping_patience=args.early_stopping
    )
    
    # æµ‹è¯•æœ€ä½³æ¨¡å‹
    logger.info("æµ‹è¯•æœ€ä½³æ¨¡å‹...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    best_checkpoint = torch.load(trainer.save_dir / "best_model.pth", map_location=device)
    model.load_state_dict(best_checkpoint['model_state_dict'])
    
    # æµ‹è¯•
    evaluator = StudentNetworkEvaluator(model, device)
    test_losses = evaluator.evaluate(test_loader, criterion)
    
    logger.info("æµ‹è¯•ç»“æœ:")
    for key, value in test_losses.items():
        logger.info(f"  {key}: {value:.4f}")
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    final_results = {
        'model_config': model_config,
        'training_args': vars(args),
        'best_epoch': trainer.best_epoch,
        'best_val_loss': trainer.best_val_loss,
        'test_losses': test_losses,
        'training_history': training_history
    }
    
    results_file = trainer.save_dir / "final_results.json"
    with open(results_file, 'w') as f:
        json.dump(final_results, f, indent=2, default=str)
    
    logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

if __name__ == "__main__":
    main() 