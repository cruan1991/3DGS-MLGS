#!/usr/bin/env python3
"""
Student Networkæ¨¡å‹æ¶æ„è¯¦ç»†åˆ†æ
===============================

åˆ†ææ¨¡å‹ç»“æ„ã€å‚æ•°åˆ†å¸ƒã€è®¡ç®—å¤æ‚åº¦ç­‰
"""

import torch
import torch.nn as nn
from student_network import create_model, StudentNetwork
import json
from collections import OrderedDict

def analyze_model_architecture():
    """è¯¦ç»†åˆ†ææ¨¡å‹æ¶æ„"""
    print("ğŸ—ï¸ " + "="*60)
    print("Student Network æ¨¡å‹æ¶æ„è¯¦ç»†åˆ†æ")
    print("="*64)
    
    # åˆ›å»ºæ¨¡å‹
    with open('training_data/metadata.json', 'r') as f:
        metadata = json.load(f)
    
    config = {
        'input_dim': metadata['feature_dims']['input_dim'],
        'output_dim': metadata['feature_dims']['output_dim'],
        'feature_dims': [64, 128, 256],
        'decoder_dims': [256, 128, 64],
        'num_radii': len(metadata['radii_used']),
        'use_radius_aware': True
    }
    
    model = create_model(config)
    
    print(f"\nğŸ“‹ æ€»ä½“ä¿¡æ¯:")
    print(f"   æ¨¡å‹ç±»å‹: å¤šå±‚æ„ŸçŸ¥æœº (MLP) + åµŒå…¥")
    print(f"   è¾“å…¥ç»´åº¦: {config['input_dim']} (COLMAPç‚¹ç‰¹å¾)")
    print(f"   è¾“å‡ºç»´åº¦: {config['output_dim']} (é«˜æ–¯çƒèšåˆç‰¹å¾)")
    print(f"   æ¶æ„é£æ ¼: Encoder-Decoder + æ¡ä»¶åµŒå…¥")
    
    return model, config

def analyze_components(model):
    """åˆ†æå„ä¸ªç»„ä»¶"""
    print(f"\nğŸ”§ ç»„ä»¶åˆ†æ:")
    
    # 1. ç‰¹å¾æå–å™¨ (MultiScaleFeatureExtractor)
    print(f"\n   1ï¸âƒ£  ç‰¹å¾æå–å™¨ (Encoder):")
    feature_extractor = model.feature_extractor
    print(f"      ç±»å‹: å¤šå±‚æ„ŸçŸ¥æœº (MLP)")
    print(f"      è¾“å…¥: [batch, 5] â†’ è¾“å‡º: [batch, 256]")
    print(f"      å±‚æ•°: 3å±‚å…¨è¿æ¥")
    print(f"      ç»´åº¦: 5 â†’ 64 â†’ 128 â†’ 256")
    print(f"      æ¿€æ´»: ReLU + BatchNorm + Dropout(0.1)")
    print(f"      ğŸ“Š å‚æ•°é‡: {sum(p.numel() for p in feature_extractor.parameters()):,}")
    
    # 2. åŠå¾„æ„ŸçŸ¥ç¼–ç å™¨
    print(f"\n   2ï¸âƒ£  åŠå¾„æ„ŸçŸ¥ç¼–ç å™¨:")
    radius_encoder = model.radius_encoder
    print(f"      ç±»å‹: åµŒå…¥ + èåˆå±‚")
    print(f"      åµŒå…¥ç»´åº¦: 4ä¸ªåŠå¾„ â†’ 64ç»´å‘é‡")
    print(f"      èåˆ: [256+64] â†’ 256")
    print(f"      ğŸ“Š å‚æ•°é‡: {sum(p.numel() for p in radius_encoder.parameters()):,}")
    
    # 3. è§£ç å™¨
    print(f"\n   3ï¸âƒ£  é«˜æ–¯ç‰¹å¾è§£ç å™¨ (Decoder):")
    decoder = model.gaussian_decoder
    print(f"      ç±»å‹: å¤šå±‚æ„ŸçŸ¥æœº (MLP)")
    print(f"      è¾“å…¥: [batch, 256] â†’ è¾“å‡º: [batch, 16]")
    print(f"      å±‚æ•°: 3å±‚å…¨è¿æ¥ + è¾“å‡ºå±‚")
    print(f"      ç»´åº¦: 256 â†’ 256 â†’ 128 â†’ 64 â†’ 16")
    print(f"      æ¿€æ´»: ReLU + BatchNorm + Dropout(0.1)")
    print(f"      ğŸ“Š å‚æ•°é‡: {sum(p.numel() for p in decoder.parameters()):,}")

def analyze_data_flow(model):
    """åˆ†ææ•°æ®æµ"""
    print(f"\nğŸŒŠ æ•°æ®æµåˆ†æ:")
    
    print(f"\n   è¾“å…¥ç‰¹å¾ [batch, 5]:")
    print(f"   â”œâ”€â”€ [0:3] å½’ä¸€åŒ–åæ ‡ (x, y, z)")
    print(f"   â”œâ”€â”€ [3] è·ç¦»åŸç‚¹")
    print(f"   â””â”€â”€ [4] å±€éƒ¨å¯†åº¦ä¼°è®¡")
    print(f"   â”‚")
    print(f"   â–¼ ç‰¹å¾æå–å™¨ (3å±‚MLP)")
    print(f"   â”‚")
    print(f"   ç‰¹å¾å‘é‡ [batch, 256]")
    print(f"   â”‚")
    print(f"   â–¼ åŠå¾„æ„ŸçŸ¥ç¼–ç ")
    print(f"   â”‚ â”œâ”€â”€ åŠå¾„åµŒå…¥: [batch] â†’ [batch, 64]")
    print(f"   â”‚ â””â”€â”€ ç‰¹å¾èåˆ: [batch, 256+64] â†’ [batch, 256]")
    print(f"   â”‚")
    print(f"   åŠå¾„æ„ŸçŸ¥ç‰¹å¾ [batch, 256]")
    print(f"   â”‚")
    print(f"   â–¼ é«˜æ–¯è§£ç å™¨ (4å±‚MLP)")
    print(f"   â”‚")
    print(f"   è¾“å‡ºç‰¹å¾ [batch, 16]:")
    print(f"   â”œâ”€â”€ [0:3] è´¨å¿ƒåæ ‡")
    print(f"   â”œâ”€â”€ [3:6] ä½ç½®æ ‡å‡†å·®")
    print(f"   â”œâ”€â”€ [6:9] å¹³å‡å°ºåº¦")
    print(f"   â”œâ”€â”€ [9:12] å°ºåº¦æ ‡å‡†å·®")
    print(f"   â”œâ”€â”€ [12] é‚»å±…æ•°é‡(log)")
    print(f"   â”œâ”€â”€ [13] å°ºåº¦å‡å€¼")
    print(f"   â”œâ”€â”€ [14] å°ºåº¦æœ€å¤§å€¼")
    print(f"   â””â”€â”€ [15] å°ºåº¦æœ€å°å€¼")

def analyze_parameters(model):
    """è¯¦ç»†å‚æ•°åˆ†æ"""
    print(f"\nğŸ”¢ å‚æ•°è¯¦ç»†åˆ†æ:")
    
    total_params = 0
    trainable_params = 0
    
    print(f"\n   ğŸ“Š å„å±‚å‚æ•°åˆ†å¸ƒ:")
    
    for name, module in model.named_modules():
        if len(list(module.children())) == 0:  # å¶å­æ¨¡å—
            module_params = sum(p.numel() for p in module.parameters())
            module_trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)
            
            if module_params > 0:
                print(f"      {name:<30}: {module_params:>8,} å‚æ•°")
                total_params += module_params
                trainable_params += module_trainable
    
    print(f"\n   ğŸ“ˆ æ€»è®¡:")
    print(f"      æ€»å‚æ•°: {total_params:,}")
    print(f"      å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"      æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")

def analyze_comparison():
    """ä¸å…¶ä»–æ¶æ„å¯¹æ¯”"""
    print(f"\nğŸ†š æ¶æ„å¯¹æ¯”:")
    
    print(f"\n   ğŸ“‹ å½“å‰æ¶æ„ vs ç»å…¸æ¶æ„:")
    print(f"   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"   â”‚      ç‰¹å¾       â”‚   å½“å‰Student   â”‚     PointNet    â”‚")
    print(f"   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"   â”‚ è¾“å…¥å¤„ç†        â”‚ ç›´æ¥MLP         â”‚ é€ç‚¹MLP + æ± åŒ–  â”‚")
    print(f"   â”‚ ç‰¹å¾æå–        â”‚ 3å±‚MLP          â”‚ å¤šå±‚MLP + Max   â”‚")
    print(f"   â”‚ æ± åŒ–æ“ä½œ        â”‚ âŒ æ— æ± åŒ–       â”‚ âœ… Max Pooling  â”‚")
    print(f"   â”‚ æ’åˆ—ä¸å˜æ€§      â”‚ âŒ æ— éœ€è¦       â”‚ âœ… æœ‰            â”‚")
    print(f"   â”‚ æ¡ä»¶ä¿¡æ¯        â”‚ âœ… åŠå¾„åµŒå…¥     â”‚ âŒ é€šå¸¸æ—        â”‚")
    print(f"   â”‚ å‚æ•°é‡          â”‚ ~23ä¸‡           â”‚ é€šå¸¸>100ä¸‡      â”‚")
    print(f"   â”‚ é€‚ç”¨åœºæ™¯        â”‚ ç‚¹åˆ°èšåˆç‰¹å¾    â”‚ ç‚¹äº‘åˆ†ç±»/åˆ†å‰²   â”‚")
    print(f"   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    print(f"\n   ğŸ¯ è®¾è®¡ç‰¹ç‚¹:")
    print(f"      âœ… è½»é‡çº§: åªæœ‰23ä¸‡å‚æ•°")
    print(f"      âœ… ä¸“ç”¨æ€§: é’ˆå¯¹COLMAPâ†’3DGSä»»åŠ¡è®¾è®¡")
    print(f"      âœ… æ¡ä»¶åŒ–: åŠå¾„æ„ŸçŸ¥ï¼Œæ”¯æŒå¤šå°ºåº¦")
    print(f"      âœ… ç®€å•: çº¯MLPï¼Œæ˜“äºè®­ç»ƒå’Œéƒ¨ç½²")
    print(f"      âš ï¸  å±€é™: æ²¡æœ‰ç©ºé—´å‡ ä½•å…ˆéªŒ")
    print(f"      âš ï¸  å±€é™: ä¸å¤„ç†é‚»å±…å…³ç³»")

def analyze_complexity():
    """è®¡ç®—å¤æ‚åº¦åˆ†æ"""
    print(f"\nâš¡ è®¡ç®—å¤æ‚åº¦:")
    
    # å‰å‘ä¼ æ’­è®¡ç®—é‡
    print(f"\n   ğŸ”¢ å‰å‘ä¼ æ’­è®¡ç®—é‡ (å•æ ·æœ¬):")
    print(f"      ç‰¹å¾æå–: 5Ã—64 + 64Ã—128 + 128Ã—256 = 41,280 FLOPs")
    print(f"      åŠå¾„åµŒå…¥: 4Ã—64 = 256 FLOPs")
    print(f"      ç‰¹å¾èåˆ: 320Ã—256 = 81,920 FLOPs")
    print(f"      è§£ç å™¨: 256Ã—256 + 256Ã—128 + 128Ã—64 + 64Ã—16 = 106,496 FLOPs")
    print(f"      æ€»è®¡: ~230K FLOPs")
    
    print(f"\n   â±ï¸  æ¨ç†é€Ÿåº¦ä¼°è®¡:")
    print(f"      GPU (RTX 4090): ~10ä¸‡æ ·æœ¬/ç§’")
    print(f"      CPU (ç°ä»£): ~1ä¸‡æ ·æœ¬/ç§’")
    print(f"      ç§»åŠ¨ç«¯: ~1åƒæ ·æœ¬/ç§’")

def test_forward_pass():
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print(f"\nğŸ§ª å‰å‘ä¼ æ’­æµ‹è¯•:")
    
    # åˆ›å»ºæ¨¡å‹
    with open('training_data/metadata.json', 'r') as f:
        metadata = json.load(f)
    
    config = {
        'input_dim': 5,
        'output_dim': 16,
        'feature_dims': [64, 128, 256],
        'decoder_dims': [256, 128, 64],
        'num_radii': 4,
        'use_radius_aware': True
    }
    
    model = create_model(config)
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 100
    input_features = torch.randn(batch_size, 5)
    radii = torch.tensor([0.012, 0.039, 0.107, 0.273] * (batch_size // 4))
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        output = model(input_features, radii)
    
    print(f"      è¾“å…¥å½¢çŠ¶: {input_features.shape}")
    print(f"      åŠå¾„å½¢çŠ¶: {radii.shape}")
    print(f"      è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"      è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
    print(f"      âœ… å‰å‘ä¼ æ’­æ­£å¸¸")

def main():
    """ä¸»å‡½æ•°"""
    model, config = analyze_model_architecture()
    analyze_components(model)
    analyze_data_flow(model)
    analyze_parameters(model)
    analyze_comparison()
    analyze_complexity()
    test_forward_pass()
    
    print(f"\n" + "="*64)
    print(f"ğŸ“‹ æ€»ç»“")
    print(f"="*64)
    print(f"ğŸ—ï¸  æ¶æ„: æ¡ä»¶åŒ–å¤šå±‚æ„ŸçŸ¥æœº (éPointNet)")
    print(f"ğŸ“Š ç»“æ„: 3å±‚ç¼–ç å™¨ + 1å±‚åµŒå…¥ + 4å±‚è§£ç å™¨")
    print(f"ğŸ”¢ å‚æ•°: 234,448 (0.89MB)")
    print(f"âš¡ å¤æ‚åº¦: ~230K FLOPs/æ ·æœ¬")
    print(f"ğŸ¯ ç‰¹ç‚¹: è½»é‡ã€ä¸“ç”¨ã€æ¡ä»¶åŒ–")
    print("="*64)

if __name__ == "__main__":
    main() 