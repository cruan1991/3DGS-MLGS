#!/usr/bin/env python3
# å®Œå…¨æŒ‰ç…§train.pyçš„é€»è¾‘è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬æ›å…‰å‚æ•°
import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import torch
import os
import argparse
from scene import Scene, GaussianModel
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render
from utils.graphics_utils import focal2fov

# Set CUDA device
torch.cuda.set_device(1)

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def complete_evaluation(model_path, ply_path):
    print("ğŸš€ Complete evaluation with exposure parameters")
    print(f"ğŸ“ Model path: {model_path}")
    print(f"ğŸ¯ PLY file: {ply_path}")
    
    # ğŸ”¥ æ£€æŸ¥SPARSE_ADAM_AVAILABLEï¼Œä¸train.pyä¿æŒä¸€è‡´
    try:
        from diff_gaussian_rasterization import SparseGaussianAdam
        SPARSE_ADAM_AVAILABLE = True
    except:
        SPARSE_ADAM_AVAILABLE = False
    
    print(f"ğŸ”§ SPARSE_ADAM_AVAILABLE: {SPARSE_ADAM_AVAILABLE}")
    
    # ===== å®Œå…¨æŒ‰ç…§train.pyçš„æ–¹å¼åŠ è½½æ•°æ®é›† =====
    parser = argparse.ArgumentParser()
    dataset_parser = ModelParams(parser)
    pipeline_parser = PipelineParams(parser)
    args = parser.parse_args([])
    
    # ğŸ”¥ å…³é”®ï¼šè®¾ç½®æ­£ç¡®çš„å‚æ•°ï¼Œç‰¹åˆ«æ˜¯train_test_exp
    args.source_path = model_path  # ä½¿ç”¨æ¨¡å‹è·¯å¾„ï¼Œè¿™æ ·ä¼šä»è®­ç»ƒæ—¶ä¿å­˜çš„ç›¸æœºå‚æ•°åŠ è½½
    args.model_path = model_path
    args.images = "images" 
    args.resolution = -1
    args.white_background = False
    args.data_device = "cuda"
    args.eval = False
    
    # ğŸ”¥ éå¸¸é‡è¦ï¼šå¯ç”¨train_test_expï¼Œè¿™æ ·ä¼šåŠ è½½æ›å…‰å‚æ•°
    # ä»è®­ç»ƒæ—¥å¿—æˆ‘ä»¬çŸ¥é“è¿™ä¸ªæ¨¡å‹æ˜¯ç”¨train_test_expè®­ç»ƒçš„
    args.train_test_exp = True
    
    # æå–å‚æ•°
    dataset = dataset_parser.extract(args)
    pipe = pipeline_parser.extract(args)
    
    print(f"ğŸ¨ Dataset train_test_exp: {dataset.train_test_exp}")
    
    # ===== æŒ‰ç…§train.pyåŠ è½½åœºæ™¯å’Œé«˜æ–¯æ¨¡å‹ =====
    gaussians = GaussianModel(dataset.sh_degree)
    
    # ğŸ”¥ å…³é”®ï¼šåŠ è½½é«˜æ–¯çƒæ—¶å¯ç”¨train_test_expï¼Œè¿™æ ·ä¼šåŠ è½½æ›å…‰å‚æ•°
    gaussians.load_ply(ply_path, use_train_test_exp=dataset.train_test_exp)
    print(f"âœ… Loaded {gaussians.get_xyz.shape[0]} gaussians")
    
    # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†æ›å…‰å‚æ•°
    if hasattr(gaussians, 'pretrained_exposures') and gaussians.pretrained_exposures is not None:
        print(f"âœ… Loaded exposure parameters for {len(gaussians.pretrained_exposures)} images")
    else:
        print("âš ï¸ No exposure parameters loaded")
    
    # åˆ›å»ºSceneï¼ˆè¿™ä¼šåˆ›å»ºç¬¦å·é“¾æ¥åˆ°åŸå§‹å›¾ç‰‡ï¼‰
    original_images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    model_images_path = os.path.join(model_path, "images")
    
    if not os.path.exists(model_images_path) or len(os.listdir(model_images_path)) == 0:
        print(f"ğŸ”— Creating symlink for images")
        if os.path.exists(model_images_path):
            os.rmdir(model_images_path)
        os.symlink(original_images_path, model_images_path)
    
    # åˆ›å»ºScene
    # ğŸ”¥ é‡è¦ï¼šä½¿ç”¨load_iteration=0æ¥é¿å…è°ƒç”¨create_from_pcd
    # è¿™æ ·Sceneä¼šå°è¯•ä»iteration_0åŠ è½½ï¼Œä½†å› ä¸ºæˆ‘ä»¬å·²ç»åŠ è½½äº†é«˜æ–¯çƒï¼Œä¸ä¼šé€ æˆé—®é¢˜
    try:
        scene = Scene(dataset, gaussians, load_iteration=0)
    except:
        # å¦‚æœæ²¡æœ‰iteration_0ï¼Œç›´æ¥åˆ›å»ºSceneä½†è·³è¿‡åˆå§‹åŒ–
        scene = Scene(dataset, gaussians, load_iteration=None, skip_train_test_split=True)
    
    # è·å–ç›¸æœº
    test_cameras = scene.getTestCameras()
    train_cameras = scene.getTrainCameras()
    
    print(f"ğŸ“· Test cameras: {len(test_cameras)}")
    print(f"ğŸ“· Train cameras: {len(train_cameras)}")
    
    # è®¾ç½®èƒŒæ™¯
    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")
    
    # é‡æ–°æ£€æŸ¥æ›å…‰å‚æ•°ï¼ˆSceneå¯èƒ½ä¼šé‡æ–°åŠ è½½ï¼‰
    if hasattr(gaussians, 'pretrained_exposures') and gaussians.pretrained_exposures is not None:
        print(f"âœ… Exposure parameters available for {len(gaussians.pretrained_exposures)} images")
    else:
        print("âš ï¸ No exposure parameters available")
    
    # ===== æŒ‰ç…§train.pyçš„æ–¹å¼è¯„ä¼° =====
    # ä½¿ç”¨train.pyä¸­å®Œå…¨ç›¸åŒçš„å‚æ•°
    renderArgs = (pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, dataset.train_test_exp)
    
    # å¦‚æœæ²¡æœ‰æµ‹è¯•ç›¸æœºï¼Œä½¿ç”¨è®­ç»ƒç›¸æœºçš„å­é›†
    if len(test_cameras) == 0:
        print("âš ï¸ No test cameras, using train camera subset")
        eval_cameras = [train_cameras[idx % len(train_cameras)] for idx in range(5, min(30, len(train_cameras)), 5)]
        camera_type = "train_subset"
    else:
        eval_cameras = test_cameras
        camera_type = "test"
    
    # è¯„ä¼°
    total_psnr = 0.0
    for i, viewpoint in enumerate(eval_cameras[:5]):
        # ğŸ”¥ å®Œå…¨æŒ‰ç…§train.pyçš„æ¸²æŸ“æ–¹å¼
        image = torch.clamp(render(viewpoint, gaussians, *renderArgs)["render"], 0.0, 1.0)
        gt_image = torch.clamp(viewpoint.original_image.to("cuda"), 0.0, 1.0)
        
        # ğŸ”¥ æŒ‰ç…§train.pyå¤„ç†train_test_exp
        if dataset.train_test_exp:
            image = image[..., image.shape[-1] // 2:]
            gt_image = gt_image[..., gt_image.shape[-1] // 2:]
        
        # è®¡ç®—PSNR
        psnr_val = psnr(image, gt_image).mean().item()
        total_psnr += psnr_val
        
        print(f"ğŸ“· Camera {i} ({viewpoint.image_name}): PSNR = {psnr_val:.2f} dB")
        
        # ä¿å­˜å›¾åƒç”¨äºæ£€æŸ¥
        if i < 3:
            from torchvision.utils import save_image
            os.makedirs("complete_renders", exist_ok=True)
            save_image(image, f"complete_renders/{viewpoint.image_name}_render.png")
            save_image(gt_image, f"complete_renders/{viewpoint.image_name}_gt.png")
    
    avg_psnr = total_psnr / min(5, len(eval_cameras))
    print(f"\nğŸ‰ Average PSNR: {avg_psnr:.2f} dB")
    print(f"ğŸ“Š Expected from training: ~33.83 dB")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', required=True)
    parser.add_argument('--ply-path', required=True)
    args = parser.parse_args()
    
    complete_evaluation(args.model_path, args.ply_path)

if __name__ == "__main__":
    main() 