import os
import sys
import torch
import numpy as np
import argparse
import json
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel
from scene.cameras import Camera
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render
from utils.general_utils import PILtoTorch
from utils.graphics_utils import focal2fov
from utils.loss_utils import l1_loss

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def load_cameras_sample(colmap_path, images_path, resolution_scale=2.0, num_cameras=5):
    """åŠ è½½å‡ ä¸ªé‡‡æ ·ç›¸æœºç”¨äºå¯¹æ¯”"""
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    # é€‰æ‹©å‡ ä¸ªæœ‰ä»£è¡¨æ€§çš„ç›¸æœºï¼ˆå‡åŒ€é‡‡æ ·ï¼‰
    img_ids = list(cam_extrinsics.keys())
    selected_ids = [img_ids[i] for i in np.linspace(0, len(img_ids)-1, num_cameras, dtype=int)]
    
    cameras = []
    
    for idx, img_id in enumerate(selected_ids):
        img_info = cam_extrinsics[img_id]
        intrinsic = cam_intrinsics[img_info.camera_id]
        
        # è§£æå‚æ•°
        fx, fy, cx, cy = intrinsic.params
        width = int(intrinsic.width / resolution_scale)
        height = int(intrinsic.height / resolution_scale)
        fx_scaled = fx / resolution_scale
        fy_scaled = fy / resolution_scale
        
        FoVx = focal2fov(fx_scaled, width)
        FoVy = focal2fov(fy_scaled, height)
        
        R = np.transpose(qvec2rotmat(img_info.qvec))
        T = np.array(img_info.tvec)
        
        # åŠ è½½å›¾åƒ
        image_path = os.path.join(images_path, img_info.name)
        image = Image.open(image_path)
        if resolution_scale != 1.0:
            image = image.resize((width, height), Image.LANCZOS)
        
        camera = Camera(
            resolution=(width, height),
            colmap_id=img_id,
            R=R,
            T=T,
            FoVx=FoVx,
            FoVy=FoVy,
            depth_params=None,
            image=image,
            invdepthmap=None,
            image_name=img_info.name,
            uid=idx,
            data_device="cuda",
            train_test_exp=False,
            is_test_dataset=False,
            is_test_view=False
        )
        
        cameras.append(camera)
        print(f"âœ… ç›¸æœº {idx}: {img_info.name}")
    
    return cameras

def render_ply_file(ply_path, camera, pipe, background):
    """æ¸²æŸ“å•ä¸ªPLYæ–‡ä»¶"""
    if not os.path.exists(ply_path):
        return None, {"error": "File not found"}
    
    try:
        # åŠ è½½é«˜æ–¯çƒ
        gaussians = GaussianModel(3)
        gaussians.load_ply(ply_path, use_train_test_exp=False)
        
        # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
        try:
            from diff_gaussian_rasterization import SparseGaussianAdam
            SPARSE_ADAM_AVAILABLE = True
        except:
            SPARSE_ADAM_AVAILABLE = False
        
        # æ¸²æŸ“
        render_result = render(camera, gaussians, pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, False)
        rendered_image = torch.clamp(render_result["render"], 0.0, 1.0)
        
        # GTå›¾åƒ
        gt_image = torch.clamp(camera.original_image.to("cuda"), 0.0, 1.0)
        
        # è®¡ç®—æŒ‡æ ‡
        psnr_val = psnr(rendered_image, gt_image).mean().item()
        l1_val = l1_loss(rendered_image, gt_image).mean().item()
        
        # è½¬æ¢ä¸ºnumpyç”¨äºå¯è§†åŒ–
        rendered_np = rendered_image.detach().cpu().numpy().transpose(1, 2, 0)
        gt_np = gt_image.detach().cpu().numpy().transpose(1, 2, 0)
        
        return (rendered_np, gt_np), {
            "psnr": psnr_val,
            "l1_loss": l1_val,
            "gaussian_count": gaussians.get_xyz.shape[0]
        }
        
    except Exception as e:
        return None, {"error": str(e)}

def create_layer_comparison_grid(camera_idx, camera_name, layer_files, progressive_files, layer_info, camera, pipe, background, output_dir):
    """ä¸ºå•ä¸ªç›¸æœºåˆ›å»ºåˆ†å±‚å¯¹æ¯”ç½‘æ ¼"""
    print(f"ğŸ¨ æ¸²æŸ“ç›¸æœº {camera_idx}: {camera_name}")
    
    # æ¸²æŸ“æ‰€æœ‰æ–‡ä»¶
    single_layer_results = []
    progressive_results = []
    
    # æ¸²æŸ“å•å±‚æ–‡ä»¶
    for i, layer_file in enumerate(layer_files):
        print(f"  æ¸²æŸ“å±‚ {i}...")
        images, metrics = render_ply_file(layer_file, camera, pipe, background)
        single_layer_results.append((images, metrics, i))
    
    # æ¸²æŸ“æ¸è¿›å¼æ–‡ä»¶
    for i, prog_file in enumerate(progressive_files):
        print(f"  æ¸²æŸ“ç´¯ç§¯ L0-L{i}...")
        images, metrics = render_ply_file(prog_file, camera, pipe, background)
        progressive_results.append((images, metrics, i))
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig = plt.figure(figsize=(20, 16))
    
    # ä½¿ç”¨GridSpecè¿›è¡Œå¸ƒå±€
    gs = gridspec.GridSpec(3, 6, height_ratios=[1, 1, 1], width_ratios=[1, 1, 1, 1, 1, 1])
    
    # ç¬¬ä¸€è¡Œï¼šå•å±‚æ¸²æŸ“ç»“æœ
    fig.text(0.02, 0.85, f'å•å±‚æ¸²æŸ“ - Camera {camera_idx} ({camera_name})', fontsize=16, fontweight='bold')
    for i, (images, metrics, layer_id) in enumerate(single_layer_results):
        ax = fig.add_subplot(gs[0, i])
        if images is not None:
            ax.imshow(images[0])  # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
            title = f"å±‚{layer_id}\n{metrics['gaussian_count']:,}çƒ\nPSNR: {metrics['psnr']:.2f}dB"
        else:
            ax.text(0.5, 0.5, f"å±‚{layer_id}\næ¸²æŸ“å¤±è´¥", ha='center', va='center', transform=ax.transAxes)
            title = f"å±‚{layer_id}\né”™è¯¯"
        
        ax.set_title(title, fontsize=10)
        ax.axis('off')
    
    # ç¬¬äºŒè¡Œï¼šæ¸è¿›å¼ç´¯ç§¯ç»“æœ
    fig.text(0.02, 0.55, 'æ¸è¿›å¼ç´¯ç§¯æ¸²æŸ“', fontsize=16, fontweight='bold')
    for i, (images, metrics, prog_id) in enumerate(progressive_results):
        ax = fig.add_subplot(gs[1, i])
        if images is not None:
            ax.imshow(images[0])  # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
            layers_str = f"L0-L{prog_id}" if prog_id > 0 else "L0"
            title = f"{layers_str}\n{metrics['gaussian_count']:,}çƒ\nPSNR: {metrics['psnr']:.2f}dB"
        else:
            layers_str = f"L0-L{prog_id}" if prog_id > 0 else "L0"
            ax.text(0.5, 0.5, f"{layers_str}\næ¸²æŸ“å¤±è´¥", ha='center', va='center', transform=ax.transAxes)
            title = f"{layers_str}\né”™è¯¯"
        
        ax.set_title(title, fontsize=10)
        ax.axis('off')
    
    # ç¬¬ä¸‰è¡Œï¼šå…³é”®å¯¹æ¯”ï¼ˆGT, å±‚3, å®Œæ•´æ¨¡å‹, å·®å¼‚å›¾ï¼‰
    fig.text(0.02, 0.25, 'å…³é”®å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
    
    # GTå›¾åƒ
    ax_gt = fig.add_subplot(gs[2, 0])
    if progressive_results[0][0] is not None:
        ax_gt.imshow(progressive_results[0][0][1])  # GTå›¾åƒ
    ax_gt.set_title('Ground Truth', fontsize=12, fontweight='bold')
    ax_gt.axis('off')
    
    # å±‚3ï¼ˆæ ¸å¿ƒå±‚ï¼‰
    ax_core = fig.add_subplot(gs[2, 1])
    if len(progressive_results) > 3 and progressive_results[3][0] is not None:
        ax_core.imshow(progressive_results[3][0][0])
        ax_core.set_title(f'å±‚3 æ ¸å¿ƒ\n{progressive_results[3][1]["psnr"]:.2f}dB', fontsize=12, fontweight='bold')
    ax_core.axis('off')
    
    # å®Œæ•´æ¨¡å‹
    ax_full = fig.add_subplot(gs[2, 2])
    if progressive_results[-1][0] is not None:
        ax_full.imshow(progressive_results[-1][0][0])
        ax_full.set_title(f'å®Œæ•´æ¨¡å‹\n{progressive_results[-1][1]["psnr"]:.2f}dB', fontsize=12, fontweight='bold')
    ax_full.axis('off')
    
    # å±‚4å•ç‹¬ï¼ˆå‰æ™¯ç»†èŠ‚ï¼‰
    ax_layer4 = fig.add_subplot(gs[2, 3])
    if len(single_layer_results) > 4 and single_layer_results[4][0] is not None:
        ax_layer4.imshow(single_layer_results[4][0][0])
        ax_layer4.set_title(f'å±‚4 ç»†èŠ‚\n{single_layer_results[4][1]["psnr"]:.2f}dB', fontsize=12, fontweight='bold')
    ax_layer4.axis('off')
    
    # PSNRè¿›åŒ–æ›²çº¿
    ax_curve = fig.add_subplot(gs[2, 4:])
    psnr_values = [res[1]['psnr'] for res in progressive_results if res[0] is not None]
    gaussian_counts = [res[1]['gaussian_count'] for res in progressive_results if res[0] is not None]
    
    ax_curve.plot(range(len(psnr_values)), psnr_values, 'bo-', linewidth=2, markersize=8)
    ax_curve.set_xlabel('ç´¯ç§¯å±‚æ•°')
    ax_curve.set_ylabel('PSNR (dB)')
    ax_curve.set_title('PSNRéšå±‚æ•°ç´¯ç§¯çš„å˜åŒ–', fontsize=12, fontweight='bold')
    ax_curve.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡æ³¨
    for i, (psnr_val, count) in enumerate(zip(psnr_values, gaussian_counts)):
        ax_curve.annotate(f'{psnr_val:.1f}dB\n{count//1000}kçƒ', 
                         (i, psnr_val), textcoords="offset points", 
                         xytext=(0,10), ha='center', fontsize=9)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_file = os.path.join(output_dir, f'layer_comparison_camera_{camera_idx}_{camera_name.replace(".jpg", "")}.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ä¿å­˜å¯¹æ¯”å›¾: {output_file}")
    
    return output_file

def main():
    parser = argparse.ArgumentParser(description='åˆ†å±‚æ¸²æŸ“å¯è§†åŒ–å¯¹æ¯”')
    parser.add_argument('--layer-dir', type=str, default='layer_progressive_analysis', help='åˆ†å±‚æ–‡ä»¶ç›®å½•')
    parser.add_argument('--num-cameras', type=int, default=3, help='é€‰æ‹©ç›¸æœºæ•°é‡')
    parser.add_argument('--resolution-scale', type=float, default=2.0, help='åˆ†è¾¨ç‡ç¼©æ”¾')
    parser.add_argument('--output-dir', type=str, default='layer_visual_comparison', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("ğŸ¨ åˆ†å±‚æ¸²æŸ“å¯è§†åŒ–å¯¹æ¯”")
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # æ‰¾åˆ°åˆ†å±‚æ–‡ä»¶
    layer_files = []
    progressive_files = []
    
    for i in range(5):  # å‡è®¾5å±‚
        layer_file = os.path.join(args.layer_dir, f"layer_{i}_z*.ply")
        import glob
        matches = glob.glob(layer_file)
        if matches:
            layer_files.append(matches[0])
    
    for i in range(5):  # 5ä¸ªæ¸è¿›æ–‡ä»¶
        if i == 0:
            prog_file = os.path.join(args.layer_dir, "progressive_L0_*.ply")
        else:
            prog_file = os.path.join(args.layer_dir, f"progressive_L0_L{i}_*.ply")
        
        matches = glob.glob(prog_file)
        if matches:
            progressive_files.append(matches[0])
    
    print(f"ğŸ“ æ‰¾åˆ°åˆ†å±‚æ–‡ä»¶: {len(layer_files)}ä¸ª")
    print(f"ğŸ“ˆ æ‰¾åˆ°æ¸è¿›æ–‡ä»¶: {len(progressive_files)}ä¸ª")
    
    if len(layer_files) == 0:
        print("âŒ æœªæ‰¾åˆ°åˆ†å±‚æ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œlayer_progressive_evaluation.py")
        return
    
    # è¯»å–å±‚çº§ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    layer_info = []
    results_file = os.path.join(args.layer_dir, 'layer_progressive_results.json')
    if os.path.exists(results_file):
        try:
            with open(results_file, 'r') as f:
                data = json.load(f)
                layer_info = data.get('layer_info', [])
        except:
            pass
    
    # è®¾ç½®æ¸²æŸ“ç¯å¢ƒ
    print(f"\nâš™ï¸ è®¾ç½®æ¸²æŸ“ç¯å¢ƒ...")
    
    # Pipelineå‚æ•°
    pipeline_parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(pipeline_parser)
    pipe_args = pipeline_parser.parse_args([])
    pipe = pipe_parser.extract(pipe_args)
    
    # èƒŒæ™¯
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # åŠ è½½ç›¸æœº
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    cameras = load_cameras_sample(colmap_path, images_path, args.resolution_scale, args.num_cameras)
    
    print(f"âœ… åŠ è½½äº† {len(cameras)} ä¸ªç›¸æœº")
    
    # ä¸ºæ¯ä¸ªç›¸æœºåˆ›å»ºå¯¹æ¯”å›¾
    print(f"\nğŸ¨ å¼€å§‹æ¸²æŸ“å¯¹æ¯”...")
    
    comparison_files = []
    for i, camera in enumerate(cameras):
        comparison_file = create_layer_comparison_grid(
            i, camera.image_name, layer_files, progressive_files, 
            layer_info, camera, pipe, background, args.output_dir
        )
        comparison_files.append(comparison_file)
    
    print(f"\nğŸ‰ æ¸²æŸ“å¯¹æ¯”å®Œæˆ!")
    print(f"ğŸ“Š ç”Ÿæˆäº† {len(comparison_files)} ä¸ªå¯¹æ¯”å›¾")
    print(f"ğŸ“ ä¿å­˜åœ¨: {args.output_dir}/")
    
    for file in comparison_files:
        print(f"  ğŸ“¸ {file}")

if __name__ == "__main__":
    main() 