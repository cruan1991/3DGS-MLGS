import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import json
from pathlib import Path

# ---- ä¸­æ–‡å­—ä½“è®¾ç½®ï¼ˆä»»é€‰å…¶ä¸€/å°±è¿‘ç³»ç»Ÿï¼‰----
import matplotlib
from matplotlib import rcParams

# Windows å¸¸è§ä¸­æ–‡å­—ä½“
# rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']

# macOS å¸¸è§ä¸­æ–‡å­—ä½“
rcParams['font.sans-serif'] = ['PingFang SC', 'Heiti TC', 'Hiragino Sans GB']

# Linux å¸¸è§ä¸­æ–‡å­—ä½“ï¼ˆè‹¥å·²å®‰è£…ï¼‰
# rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'WenQuanYi Zen Hei']

rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·å˜æ–¹å—


# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel

def analyze_gaussian_scales(ply_path, output_dir='scale_analysis'):
    """åˆ†æé«˜æ–¯çƒçš„å°ºå¯¸åˆ†å¸ƒ"""
    print("ğŸ” åˆ†æé«˜æ–¯çƒå°ºå¯¸åˆ†å¸ƒ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½é«˜æ–¯çƒ
    gaussians = GaussianModel(3)
    gaussians.load_ply(ply_path, use_train_test_exp=False)
    
    # è·å–ç¼©æ”¾å‚æ•° (scaling)
    scaling = gaussians.get_scaling.detach().cpu().numpy()  # [N, 3]
    print(f"ğŸ“Š é«˜æ–¯çƒæ•°é‡: {scaling.shape[0]:,}")
    print(f"ğŸ“ ç¼©æ”¾å‚æ•°å½¢çŠ¶: {scaling.shape}")
    
    # è®¡ç®—å„ç§å°ºå¯¸æŒ‡æ ‡
    # 1. å¹³å‡å°ºå¯¸ (3ä¸ªè½´çš„å¹³å‡)
    avg_scale = np.mean(scaling, axis=1)
    
    # 2. æœ€å¤§å°ºå¯¸ (3ä¸ªè½´çš„æœ€å¤§å€¼)
    max_scale = np.max(scaling, axis=1)
    
    # 3. æœ€å°å°ºå¯¸ (3ä¸ªè½´çš„æœ€å°å€¼)
    min_scale = np.min(scaling, axis=1)
    
    # 4. ä½“ç§¯ (3ä¸ªè½´çš„ä¹˜ç§¯)
    volume = np.prod(scaling, axis=1)
    
    # 5. å„è½´ç‹¬ç«‹åˆ†æ
    scale_x, scale_y, scale_z = scaling[:, 0], scaling[:, 1], scaling[:, 2]
    
    print("\nğŸ“ˆ å°ºå¯¸ç»Ÿè®¡:")
    metrics = {
        'avg_scale': avg_scale,
        'max_scale': max_scale, 
        'min_scale': min_scale,
        'volume': volume,
        'scale_x': scale_x,
        'scale_y': scale_y,
        'scale_z': scale_z
    }
    
    results = {}
    for name, data in metrics.items():
        stats = {
            'min': float(np.min(data)),
            'max': float(np.max(data)),
            'mean': float(np.mean(data)),
            'median': float(np.median(data)),
            'std': float(np.std(data)),
            'q25': float(np.percentile(data, 25)),
            'q75': float(np.percentile(data, 75)),
            'q90': float(np.percentile(data, 90)),
            'q95': float(np.percentile(data, 95)),
            'q99': float(np.percentile(data, 99))
        }
        results[name] = stats
        
        print(f"\n{name}:")
        print(f"  èŒƒå›´: [{stats['min']:.6f}, {stats['max']:.6f}]")
        print(f"  å‡å€¼: {stats['mean']:.6f}, ä¸­ä½æ•°: {stats['median']:.6f}")
        print(f"  æ ‡å‡†å·®: {stats['std']:.6f}")
        print(f"  åˆ†ä½æ•°: Q25={stats['q25']:.6f}, Q75={stats['q75']:.6f}, Q95={stats['q95']:.6f}")
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(3, 3, figsize=(20, 15))
    fig.suptitle('é«˜æ–¯çƒå°ºå¯¸åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
    
    # 1. å¹³å‡å°ºå¯¸åˆ†å¸ƒ
    ax = axes[0, 0]
    ax.hist(avg_scale, bins=100, alpha=0.7, color='blue', edgecolor='black')
    ax.set_title('å¹³å‡å°ºå¯¸åˆ†å¸ƒ')
    ax.set_xlabel('å¹³å‡å°ºå¯¸')
    ax.set_ylabel('æ•°é‡')
    ax.set_yscale('log')
    
    # 2. æœ€å¤§å°ºå¯¸åˆ†å¸ƒ
    ax = axes[0, 1]
    ax.hist(max_scale, bins=100, alpha=0.7, color='red', edgecolor='black')
    ax.set_title('æœ€å¤§å°ºå¯¸åˆ†å¸ƒ')
    ax.set_xlabel('æœ€å¤§å°ºå¯¸')
    ax.set_ylabel('æ•°é‡')
    ax.set_yscale('log')
    
    # 3. ä½“ç§¯åˆ†å¸ƒ
    ax = axes[0, 2]
    ax.hist(volume, bins=100, alpha=0.7, color='green', edgecolor='black')
    ax.set_title('ä½“ç§¯åˆ†å¸ƒ')
    ax.set_xlabel('ä½“ç§¯')
    ax.set_ylabel('æ•°é‡')
    ax.set_yscale('log')
    
    # 4. Xè½´å°ºå¯¸
    ax = axes[1, 0]
    ax.hist(scale_x, bins=100, alpha=0.7, color='orange', edgecolor='black')
    ax.set_title('Xè½´å°ºå¯¸åˆ†å¸ƒ')
    ax.set_xlabel('Xè½´å°ºå¯¸')
    ax.set_ylabel('æ•°é‡')
    ax.set_yscale('log')
    
    # 5. Yè½´å°ºå¯¸
    ax = axes[1, 1]
    ax.hist(scale_y, bins=100, alpha=0.7, color='purple', edgecolor='black')
    ax.set_title('Yè½´å°ºå¯¸åˆ†å¸ƒ')
    ax.set_xlabel('Yè½´å°ºå¯¸')
    ax.set_ylabel('æ•°é‡')
    ax.set_yscale('log')
    
    # 6. Zè½´å°ºå¯¸
    ax = axes[1, 2]
    ax.hist(scale_z, bins=100, alpha=0.7, color='brown', edgecolor='black')
    ax.set_title('Zè½´å°ºå¯¸åˆ†å¸ƒ')
    ax.set_xlabel('Zè½´å°ºå¯¸')
    ax.set_ylabel('æ•°é‡')
    ax.set_yscale('log')
    
    # 7. ç®±çº¿å›¾å¯¹æ¯”
    ax = axes[2, 0]
    data_for_box = [avg_scale, max_scale, min_scale]
    labels = ['å¹³å‡å°ºå¯¸', 'æœ€å¤§å°ºå¯¸', 'æœ€å°å°ºå¯¸']
    ax.boxplot(data_for_box, labels=labels)
    ax.set_title('å°ºå¯¸æŒ‡æ ‡å¯¹æ¯”')
    ax.set_ylabel('å°ºå¯¸å€¼')
    ax.set_yscale('log')
    
    # 8. ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
    ax = axes[2, 1]
    sorted_avg = np.sort(avg_scale)
    p = np.arange(len(sorted_avg)) / len(sorted_avg)
    ax.plot(sorted_avg, p, linewidth=2, label='å¹³å‡å°ºå¯¸')
    
    sorted_max = np.sort(max_scale)
    ax.plot(sorted_max, p, linewidth=2, label='æœ€å¤§å°ºå¯¸')
    
    ax.set_title('ç´¯ç§¯åˆ†å¸ƒå‡½æ•°')
    ax.set_xlabel('å°ºå¯¸')
    ax.set_ylabel('ç´¯ç§¯æ¦‚ç‡')
    ax.set_xscale('log')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 9. æ•£ç‚¹å›¾ï¼šå¹³å‡å°ºå¯¸ vs ä½“ç§¯
    ax = axes[2, 2]
    # é‡‡æ ·æ˜¾ç¤ºï¼ˆé¿å…ç‚¹å¤ªå¤šï¼‰
    sample_indices = np.random.choice(len(avg_scale), size=min(10000, len(avg_scale)), replace=False)
    ax.scatter(avg_scale[sample_indices], volume[sample_indices], alpha=0.5, s=1)
    ax.set_title('å¹³å‡å°ºå¯¸ vs ä½“ç§¯')
    ax.set_xlabel('å¹³å‡å°ºå¯¸')
    ax.set_ylabel('ä½“ç§¯')
    ax.set_xscale('log')
    ax.set_yscale('log')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_file = os.path.join(output_dir, 'scale_distribution_analysis.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å¯è§†åŒ–ä¿å­˜åˆ°: {plot_file}")
    
    # å»ºè®®åˆ†å±‚æ–¹æ¡ˆ
    print("\nğŸ¯ å»ºè®®çš„å°ºå¯¸åˆ†å±‚æ–¹æ¡ˆ:")
    
    # åŸºäºåˆ†ä½æ•°çš„åˆ†å±‚
    avg_thresholds = [
        np.percentile(avg_scale, 20),   # è¶…å°çƒ (0-20%)
        np.percentile(avg_scale, 50),   # å°çƒ (20-50%)
        np.percentile(avg_scale, 80),   # ä¸­çƒ (50-80%)
        np.percentile(avg_scale, 95),   # å¤§çƒ (80-95%)
        # è¶…å¤§çƒ (95-100%)
    ]
    
    layer_names = ['è¶…å°çƒ', 'å°çƒ', 'ä¸­çƒ', 'å¤§çƒ', 'è¶…å¤§çƒ']
    layer_info = []
    
    for i, name in enumerate(layer_names):
        if i == 0:
            mask = avg_scale <= avg_thresholds[0]
            range_str = f"â‰¤{avg_thresholds[0]:.6f}"
        elif i == len(layer_names) - 1:
            mask = avg_scale > avg_thresholds[-1]
            range_str = f">{avg_thresholds[-1]:.6f}"
        else:
            mask = (avg_scale > avg_thresholds[i-1]) & (avg_scale <= avg_thresholds[i])
            range_str = f"{avg_thresholds[i-1]:.6f}~{avg_thresholds[i]:.6f}"
        
        count = np.sum(mask)
        percentage = count / len(avg_scale) * 100
        
        layer_info.append({
            'layer_id': i,
            'name': name,
            'threshold_range': range_str,
            'count': int(count),
            'percentage': percentage,
            'avg_scale_range': range_str,
            'mask': mask.tolist()  # ç”¨äºåç»­ç”ŸæˆPLYæ–‡ä»¶
        })
        
        print(f"  å±‚{i} ({name}): {range_str}, {count:,}çƒ ({percentage:.1f}%)")
    
    # ä¿å­˜ç»“æœ
    results['layer_suggestions'] = layer_info
    results['thresholds'] = [float(t) for t in avg_thresholds]
    
    results_file = os.path.join(output_dir, 'scale_analysis_results.json')
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"âœ… åˆ†æç»“æœä¿å­˜åˆ°: {results_file}")
    
    return results, avg_thresholds

def main():
    print("ğŸ” é«˜æ–¯çƒå°ºå¯¸åˆ†å¸ƒåˆ†æ")
    print("=" * 50)
    
    # PLYæ–‡ä»¶è·¯å¾„
    ply_path = "./output/truck-150w/gaussian_ball/iteration_994230_best_psnr/gaussian_ball.ply"
    
    if not os.path.exists(ply_path):
        print(f"âŒ PLYæ–‡ä»¶ä¸å­˜åœ¨: {ply_path}")
        return
    
    # åˆ†æå°ºå¯¸åˆ†å¸ƒ
    results, thresholds = analyze_gaussian_scales(ply_path)
    
    print(f"\nğŸ‰ å°ºå¯¸åˆ†æå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: scale_analysis/")
    print(f"ğŸ“Š å»ºè®®çš„5å±‚åˆ†å±‚æ–¹æ¡ˆåŸºäºå¹³å‡å°ºå¯¸åˆ†ä½æ•°")
    print(f"ğŸ“ˆ å¯æŸ¥çœ‹ scale_analysis/scale_distribution_analysis.png äº†è§£åˆ†å¸ƒè¯¦æƒ…")

if __name__ == "__main__":
    main() 