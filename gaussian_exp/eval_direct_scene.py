#!/usr/bin/env python3
# ç›´æ¥ä½¿ç”¨SceneåŠ è½½æœ€ä½³iterationè¿›è¡Œè¯„ä¼°
import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import torch
import os
import argparse
from scene import Scene, GaussianModel
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render

# Set CUDA device
torch.cuda.set_device(1)

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def eval_direct_scene(model_path):
    print("ğŸš€ Direct Scene evaluation")
    print(f"ğŸ“ Model path: {model_path}")
    
    # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
    try:
        from diff_gaussian_rasterization import SparseGaussianAdam
        SPARSE_ADAM_AVAILABLE = True
    except:
        SPARSE_ADAM_AVAILABLE = False
    
    print(f"ğŸ”§ SPARSE_ADAM_AVAILABLE: {SPARSE_ADAM_AVAILABLE}")
    
    # åˆ›å»ºç¬¦å·é“¾æ¥åˆ°åŸå§‹å›¾ç‰‡
    original_images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    model_images_path = os.path.join(model_path, "images")
    
    if not os.path.exists(model_images_path):
        print(f"ğŸ”— Creating symlink for images")
        os.symlink(original_images_path, model_images_path)
    
    # è®¾ç½®å‚æ•°
    parser = argparse.ArgumentParser()
    dataset_parser = ModelParams(parser)
    pipeline_parser = PipelineParams(parser)
    args = parser.parse_args([])
    
    args.source_path = model_path
    args.model_path = model_path
    args.images = "images"
    args.resolution = 2  # ğŸ” å°è¯•ä½¿ç”¨2å€ä¸‹é‡‡æ ·ï¼Œå¯èƒ½æ›´æ¥è¿‘è®­ç»ƒæ—¶çš„è®¾ç½®
    args.white_background = False
    args.data_device = "cuda"
    args.eval = False
    args.train_test_exp = False  # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè®­ç»ƒæ—¶æ²¡æœ‰ä½¿ç”¨train_test_expï¼
    
    dataset = dataset_parser.extract(args)
    pipe = pipeline_parser.extract(args)
    
    print(f"ğŸ¨ Dataset train_test_exp: {dataset.train_test_exp}")
    
    # åˆ›å»ºé«˜æ–¯æ¨¡å‹
    gaussians = GaussianModel(dataset.sh_degree)
    
    # ğŸ”¥ å…³é”®ï¼šè®©Sceneç›´æ¥åŠ è½½æœ€ä½³PSNRçš„iteration
    # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°å®é™…çš„iterationå·
    best_psnr_iteration = 994230  # ä»ä¹‹å‰çš„æ—¥å¿—ä¸­çŸ¥é“
    
    scene = Scene(dataset, gaussians, load_iteration=best_psnr_iteration)
    
    # æ£€æŸ¥æ›å…‰å‚æ•°
    print(f"ğŸ” Checking exposure parameters...")
    print(f"  - hasattr(gaussians, 'pretrained_exposures'): {hasattr(gaussians, 'pretrained_exposures')}")
    if hasattr(gaussians, 'pretrained_exposures'):
        print(f"  - gaussians.pretrained_exposures is None: {gaussians.pretrained_exposures is None}")
        if gaussians.pretrained_exposures is not None:
            print(f"  - Number of pretrained exposures: {len(gaussians.pretrained_exposures)}")
    
    print(f"  - hasattr(gaussians, '_exposure'): {hasattr(gaussians, '_exposure')}")
    print(f"  - hasattr(gaussians, 'exposure_mapping'): {hasattr(gaussians, 'exposure_mapping')}")
    
    if hasattr(gaussians, 'pretrained_exposures') and gaussians.pretrained_exposures is not None:
        print(f"âœ… Loaded exposure parameters for {len(gaussians.pretrained_exposures)} images")
    else:
        print("âš ï¸ No exposure parameters loaded")
    
    # è·å–ç›¸æœº
    test_cameras = scene.getTestCameras()
    train_cameras = scene.getTrainCameras()
    
    print(f"ğŸ“· Test cameras: {len(test_cameras)}")
    print(f"ğŸ“· Train cameras: {len(train_cameras)}")
    
    # è®¾ç½®èƒŒæ™¯
    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")
    
    # é€‰æ‹©è¯„ä¼°ç›¸æœº
    if len(test_cameras) == 0:
        print("âš ï¸ No test cameras, using train camera subset")
        eval_cameras = [train_cameras[idx % len(train_cameras)] for idx in range(5, min(30, len(train_cameras)), 5)]
    else:
        eval_cameras = test_cameras
    
    # æ¸²æŸ“å‚æ•°
    renderArgs = (pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, dataset.train_test_exp)
    
    # è¯„ä¼°
    total_psnr = 0.0
    for i, viewpoint in enumerate(eval_cameras[:5]):
        # æŒ‰ç…§train.pyçš„æ¸²æŸ“æ–¹å¼
        image = torch.clamp(render(viewpoint, gaussians, *renderArgs)["render"], 0.0, 1.0)
        gt_image = torch.clamp(viewpoint.original_image.to("cuda"), 0.0, 1.0)
        
        # å¤„ç†train_test_exp
        if dataset.train_test_exp:
            image = image[..., image.shape[-1] // 2:]
            gt_image = gt_image[..., gt_image.shape[-1] // 2:]
        
        # è®¡ç®—PSNR
        psnr_val = psnr(image, gt_image).mean().item()
        total_psnr += psnr_val
        
        print(f"ğŸ“· Camera {i} ({viewpoint.image_name}): PSNR = {psnr_val:.2f} dB")
        
        # ä¿å­˜å›¾åƒ
        if i < 3:
            from torchvision.utils import save_image
            os.makedirs("direct_renders", exist_ok=True)
            save_image(image, f"direct_renders/{viewpoint.image_name}_render.png")
            save_image(gt_image, f"direct_renders/{viewpoint.image_name}_gt.png")
    
    avg_psnr = total_psnr / min(5, len(eval_cameras))
    print(f"\nğŸ‰ Average PSNR: {avg_psnr:.2f} dB")
    print(f"ğŸ“Š Expected from training: ~33.83 dB")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', required=True)
    args = parser.parse_args()
    
    eval_direct_scene(args.model_path)

if __name__ == "__main__":
    main() 