import os
import sys
import torch
import numpy as np
import argparse
import json
import glob
from PIL import Image
import matplotlib.pyplot as plt

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel
from scene.cameras import Camera
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render
from utils.general_utils import PILtoTorch
from utils.graphics_utils import focal2fov
from utils.loss_utils import l1_loss

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def load_test_camera(colmap_path, images_path, camera_name="000001.jpg", resolution_scale=2.0):
    """åŠ è½½æµ‹è¯•ç›¸æœºï¼Œä¿æŒåˆç†åˆ†è¾¨ç‡"""
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    # æ‰¾åˆ°æŒ‡å®šç›¸æœº
    target_img_id = None
    for img_id, img_info in cam_extrinsics.items():
        if img_info.name == camera_name:
            target_img_id = img_id
            break
    
    if target_img_id is None:
        print(f"âŒ æœªæ‰¾åˆ°ç›¸æœº: {camera_name}")
        return None
    
    img_info = cam_extrinsics[target_img_id]
    intrinsic = cam_intrinsics[img_info.camera_id]
    
    # è§£æå‚æ•°
    fx, fy, cx, cy = intrinsic.params
    width = int(intrinsic.width / resolution_scale)
    height = int(intrinsic.height / resolution_scale)
    fx_scaled = fx / resolution_scale
    fy_scaled = fy / resolution_scale
    
    FoVx = focal2fov(fx_scaled, width)
    FoVy = focal2fov(fy_scaled, height)
    
    R = np.transpose(qvec2rotmat(img_info.qvec))
    T = np.array(img_info.tvec)
    
    # åŠ è½½å›¾åƒ
    image_path = os.path.join(images_path, img_info.name)
    image = Image.open(image_path)
    if resolution_scale != 1.0:
        image = image.resize((width, height), Image.LANCZOS)
    
    camera = Camera(
        resolution=(width, height),
        colmap_id=target_img_id,
        R=R,
        T=T,
        FoVx=FoVx,
        FoVy=FoVy,
        depth_params=None,
        image=image,
        invdepthmap=None,
        image_name=img_info.name,
        uid=0,
        data_device="cuda",
        train_test_exp=False,
        is_test_dataset=False,
        is_test_view=False
    )
    
    return camera

def create_tile_camera(base_camera, tile_x, tile_y, tiles_w, tiles_h):
    """åˆ›å»ºç“¦ç‰‡ç›¸æœºï¼Œåªæ¸²æŸ“å›¾åƒçš„ä¸€éƒ¨åˆ†"""
    width = base_camera.image_width
    height = base_camera.image_height
    
    tile_width = width // tiles_w
    tile_height = height // tiles_h
    
    # è®¡ç®—ç“¦ç‰‡çš„èµ·å§‹ä½ç½®
    start_x = tile_x * tile_width
    start_y = tile_y * tile_height
    
    # ç¡®ä¿æœ€åä¸€ä¸ªç“¦ç‰‡åŒ…å«å‰©ä½™åƒç´ 
    if tile_x == tiles_w - 1:
        tile_width = width - start_x
    if tile_y == tiles_h - 1:
        tile_height = height - start_y
    
    # è£å‰ªGTå›¾åƒ
    gt_image = base_camera.original_image
    if len(gt_image.shape) == 3 and gt_image.shape[0] == 3:  # CHWæ ¼å¼
        tile_gt = gt_image[:, start_y:start_y+tile_height, start_x:start_x+tile_width]
    else:  # HWCæ ¼å¼
        tile_gt = gt_image[start_y:start_y+tile_height, start_x:start_x+tile_width]
        if len(tile_gt.shape) == 3:
            tile_gt = tile_gt.permute(2, 0, 1)  # è½¬æ¢ä¸ºCHW
    
    # è½¬æ¢ä¸ºPILå›¾åƒç”¨äºCameraæ„é€ 
    if isinstance(tile_gt, torch.Tensor):
        tile_gt_np = tile_gt.cpu().numpy()
        if tile_gt_np.shape[0] == 3:  # CHW -> HWC
            tile_gt_np = tile_gt_np.transpose(1, 2, 0)
        tile_gt_pil = Image.fromarray((tile_gt_np * 255).astype(np.uint8))
    else:
        tile_gt_pil = tile_gt
    
    # è®¡ç®—è°ƒæ•´åçš„ç›¸æœºå‚æ•°
    # ä¸»ç‚¹åç§»
    fx = focal2fov(base_camera.FoVx, width) * width / 2  # è¿˜åŸfx
    fy = focal2fov(base_camera.FoVy, height) * height / 2  # è¿˜åŸfy
    
    cx_new = fx - start_x  # è°ƒæ•´ä¸»ç‚¹
    cy_new = fy - start_y
    
    fx_tile = fx  # ç„¦è·ä¿æŒä¸å˜
    fy_tile = fy
    
    # é‡æ–°è®¡ç®—FoV
    FoVx_tile = focal2fov(fx_tile, tile_width)
    FoVy_tile = focal2fov(fy_tile, tile_height)
    
    # åˆ›å»ºç“¦ç‰‡ç›¸æœº
    tile_camera = Camera(
        resolution=(tile_width, tile_height),
        colmap_id=base_camera.colmap_id,
        R=base_camera.R,
        T=base_camera.T,
        FoVx=FoVx_tile,
        FoVy=FoVy_tile,
        depth_params=None,
        image=tile_gt_pil,
        invdepthmap=None,
        image_name=f"{base_camera.image_name}_tile_{tile_x}_{tile_y}",
        uid=base_camera.uid,
        data_device="cuda",
        train_test_exp=False,
        is_test_dataset=False,
        is_test_view=False
    )
    
    return tile_camera, (start_x, start_y, tile_width, tile_height)

def render_ply_tiled(ply_path, base_camera, pipe, background, tiles_w=2, tiles_h=2):
    """åˆ†å—æ¸²æŸ“PLYæ–‡ä»¶ï¼Œä¸è¿›è¡Œé‡‡æ ·"""
    if not os.path.exists(ply_path):
        return None, {"error": "File not found"}
    
    try:
        print(f"    ğŸ§© åˆ†å—æ¸²æŸ“ ({tiles_w}x{tiles_h} = {tiles_w*tiles_h}å—)", end="")
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        
        # åŠ è½½é«˜æ–¯çƒï¼ˆå®Œæ•´ç‰ˆï¼Œä¸é‡‡æ ·ï¼‰
        gaussians = GaussianModel(3)
        gaussians.load_ply(ply_path, use_train_test_exp=False)
        
        gaussian_count = gaussians.get_xyz.shape[0]
        print(f" - {gaussian_count:,}çƒ(å®Œæ•´)")
        
        # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
        try:
            from diff_gaussian_rasterization import SparseGaussianAdam
            SPARSE_ADAM_AVAILABLE = True
        except:
            SPARSE_ADAM_AVAILABLE = False
        
        # åˆå§‹åŒ–å®Œæ•´å›¾åƒ
        full_width = base_camera.image_width
        full_height = base_camera.image_height
        rendered_full = torch.zeros((3, full_height, full_width), device="cuda")
        gt_full = base_camera.original_image.to("cuda")
        
        tile_results = []
        
        # é€å—æ¸²æŸ“
        for tile_y in range(tiles_h):
            for tile_x in range(tiles_w):
                print(f"      æ¸²æŸ“ç“¦ç‰‡ ({tile_x}, {tile_y})", end="")
                
                try:
                    # åˆ›å»ºç“¦ç‰‡ç›¸æœº
                    tile_camera, (start_x, start_y, tile_w, tile_h) = create_tile_camera(
                        base_camera, tile_x, tile_y, tiles_w, tiles_h
                    )
                    
                    # æ¸²æŸ“ç“¦ç‰‡
                    render_result = render(tile_camera, gaussians, pipe, background, 1., 
                                         SPARSE_ADAM_AVAILABLE, None, False)
                    rendered_tile = torch.clamp(render_result["render"], 0.0, 1.0)
                    
                    # å°†ç“¦ç‰‡æ”¾å›å®Œæ•´å›¾åƒ
                    rendered_full[:, start_y:start_y+tile_h, start_x:start_x+tile_w] = rendered_tile
                    
                    # è®¡ç®—ç“¦ç‰‡PSNR
                    gt_tile = gt_full[:, start_y:start_y+tile_h, start_x:start_x+tile_w]
                    tile_psnr = psnr(rendered_tile, gt_tile).mean().item()
                    
                    tile_results.append({
                        'tile_x': tile_x,
                        'tile_y': tile_y,
                        'psnr': tile_psnr,
                        'start_x': start_x,
                        'start_y': start_y,
                        'width': tile_w,
                        'height': tile_h
                    })
                    
                    print(f" âœ… PSNR: {tile_psnr:.2f}dB")
                    
                    # æ¸…ç†ç“¦ç‰‡èµ„æº
                    del render_result, rendered_tile, tile_camera
                    torch.cuda.empty_cache()
                    
                except torch.cuda.OutOfMemoryError as e:
                    print(f" âŒ ç“¦ç‰‡OOM")
                    torch.cuda.empty_cache()
                    # è®°å½•å¤±è´¥çš„ç“¦ç‰‡
                    tile_results.append({
                        'tile_x': tile_x,
                        'tile_y': tile_y,
                        'psnr': 0.0,
                        'error': 'OOM'
                    })
                    continue
        
        # è®¡ç®—æ•´ä½“æŒ‡æ ‡
        overall_psnr = psnr(rendered_full, gt_full).mean().item()
        overall_l1 = l1_loss(rendered_full, gt_full).mean().item()
        
        # è½¬æ¢ä¸ºnumpyç”¨äºå¯è§†åŒ–
        rendered_np = rendered_full.detach().cpu().numpy().transpose(1, 2, 0)
        gt_np = gt_full.detach().cpu().numpy().transpose(1, 2, 0)
        
        # æ¸…ç†å†…å­˜
        del gaussians, rendered_full, gt_full
        torch.cuda.empty_cache()
        
        return (rendered_np, gt_np), {
            "psnr": overall_psnr,
            "l1_loss": overall_l1,
            "gaussian_count": gaussian_count,
            "tiles_w": tiles_w,
            "tiles_h": tiles_h,
            "tile_results": tile_results,
            "avg_tile_psnr": np.mean([t['psnr'] for t in tile_results if 'error' not in t]),
            "successful_tiles": len([t for t in tile_results if 'error' not in t])
        }
        
    except Exception as e:
        print(f"    âŒ æ¸²æŸ“å¤±è´¥: {str(e)}")
        torch.cuda.empty_cache()
        return None, {"error": str(e)}

def evaluate_size_progressive_tiled(layers_dir, output_dir='size_progressive_tiled'):
    """åˆ†å—æ¸²æŸ“ç‰ˆæ¸è¿›å¼è¯„ä¼°"""
    print("ğŸ“ˆ åˆ†å—æ¸²æŸ“å°ºå¯¸åˆ†å±‚æ¸è¿›å¼è¯„ä¼°")
    print("=" * 60)
    print("ğŸ”§ ä¸»è¦ç‰¹ç‚¹:")
    print("  - ä¿ç•™æ‰€æœ‰é«˜æ–¯çƒï¼Œä¸è¿›è¡Œé‡‡æ ·")
    print("  - ä½¿ç”¨2x2åˆ†å—æ¸²æŸ“è§£å†³æ˜¾å­˜é—®é¢˜")
    print("  - ç“¦ç‰‡ç‹¬ç«‹æ¸²æŸ“åæ‹¼æ¥æˆå®Œæ•´å›¾åƒ")
    print("  - ä¿è¯PSNRå•è°ƒé€’å¢ç‰¹æ€§")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¾ç½®æ¸²æŸ“ç¯å¢ƒ
    pipeline_parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(pipeline_parser)
    pipe_args = pipeline_parser.parse_args([])
    pipe = pipe_parser.extract(pipe_args)
    
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # åŠ è½½ç›¸æœº
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    camera = load_test_camera(colmap_path, images_path, "000001.jpg", 2.0)  # 2xç¼©æ”¾å¹³è¡¡è´¨é‡å’Œæ€§èƒ½
    
    if camera is None:
        return
    
    print(f"\nâœ… åŠ è½½æµ‹è¯•ç›¸æœº: 000001.jpg (åˆ†è¾¨ç‡: {camera.image_width}x{camera.image_height})")
    
    # æŸ¥æ‰¾æ¸è¿›å¼PLYæ–‡ä»¶
    progressive_files = sorted(glob.glob(os.path.join(layers_dir, "size_progressive_*.ply")))
    
    print(f"ğŸ“ˆ æ‰¾åˆ°æ¸è¿›æ–‡ä»¶: {len(progressive_files)}ä¸ª")
    
    # æ¸²æŸ“æ¸è¿›å¼æ–‡ä»¶
    progressive_results = []
    layer_names = ['S0', 'S0+S1', 'S0+S1+S2', 'S0+S1+S2+S3', 'S0+S1+S2+S3+S4']
    layer_descriptions = [
        'è¶…å°çƒ',
        'è¶…å°çƒ+å°çƒ', 
        'è¶…å°çƒ+å°çƒ+ä¸­çƒ',
        'è¶…å°çƒ+å°çƒ+ä¸­çƒ+å¤§çƒ',
        'è¶…å°çƒ+å°çƒ+ä¸­çƒ+å¤§çƒ+è¶…å¤§çƒ'
    ]
    
    print(f"\nğŸ¯ å¼€å§‹åˆ†å—æ¸²æŸ“æ¸è¿›å¼è¯„ä¼°...")
    
    for i, prog_file in enumerate(progressive_files):
        layer_name = layer_names[i] if i < len(layer_names) else f"Stage{i}"
        layer_desc = layer_descriptions[i] if i < len(layer_descriptions) else f"é˜¶æ®µ{i}"
        
        print(f"\nğŸ¨ æ¸²æŸ“é˜¶æ®µ{i} ({layer_name}): {layer_desc}")
        print(f"   æ–‡ä»¶: {os.path.basename(prog_file)}")
        
        # æ ¹æ®æ–‡ä»¶å¤§å°è‡ªé€‚åº”è°ƒæ•´åˆ†å—ç­–ç•¥
        file_size_mb = os.path.getsize(prog_file) / (1024 * 1024)
        if file_size_mb > 500:  # å¤§äº500MBç”¨3x3åˆ†å—
            tiles_w, tiles_h = 3, 3
        elif file_size_mb > 200:  # å¤§äº200MBç”¨2x2åˆ†å—
            tiles_w, tiles_h = 2, 2
        else:  # å°æ–‡ä»¶ç”¨2x2æˆ–ç›´æ¥æ¸²æŸ“
            tiles_w, tiles_h = 2, 2
        
        print(f"   ğŸ“ æ–‡ä»¶å¤§å°: {file_size_mb:.1f}MB, ä½¿ç”¨{tiles_w}x{tiles_h}åˆ†å—")
        
        images, metrics = render_ply_tiled(prog_file, camera, pipe, background, tiles_w, tiles_h)
        
        progressive_results.append({
            'stage': i,
            'layer_name': layer_name,
            'layer_description': layer_desc,
            'images': images,
            'metrics': metrics,
            'file': os.path.basename(prog_file),
            'file_size_mb': file_size_mb
        })
        
        if images is not None:
            print(f"   âœ… æ•´ä½“PSNR: {metrics['psnr']:.2f}dB, é«˜æ–¯çƒæ•°: {metrics['gaussian_count']:,}")
            print(f"      æˆåŠŸç“¦ç‰‡: {metrics['successful_tiles']}/{tiles_w*tiles_h}, å¹³å‡ç“¦ç‰‡PSNR: {metrics['avg_tile_psnr']:.2f}dB")
        else:
            print(f"   âŒ æ¸²æŸ“å¤±è´¥: {metrics.get('error', 'Unknown')}")
    
    # åˆ†æPSNRè¿›åŒ–
    print(f"\nğŸ“Š åˆ†æPSNRè¿›åŒ–...")
    
    successful_results = [r for r in progressive_results if r['images'] is not None]
    
    if len(successful_results) == 0:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„æ¸²æŸ“ç»“æœ")
        return
    
    # è®¡ç®—è´¡çŒ®åˆ†æ
    contribution_analysis = []
    for i, result in enumerate(successful_results):
        current_psnr = result['metrics']['psnr']
        
        if i == 0:
            contribution = current_psnr
        else:
            prev_psnr = successful_results[i-1]['metrics']['psnr']
            contribution = current_psnr - prev_psnr
        
        contribution_analysis.append({
            'stage': result['stage'],
            'layer_name': result['layer_name'],
            'layer_description': result['layer_description'],
            'cumulative_psnr': current_psnr,
            'psnr_contribution': contribution,
            'gaussian_count': result['metrics']['gaussian_count'],
            'file_size_mb': result['file_size_mb']
        })
        
        print(f"  é˜¶æ®µ{result['stage']} ({result['layer_name']}): {current_psnr:.2f}dB (+{contribution:.2f}), {result['metrics']['gaussian_count']:,}çƒ")
    
    # æ£€æŸ¥å•è°ƒé€’å¢ç‰¹æ€§
    negative_contributions = [ca for ca in contribution_analysis[1:] if ca['psnr_contribution'] < -0.01]
    if negative_contributions:
        print(f"\nâš ï¸  å‘ç° {len(negative_contributions)} ä¸ªè½»å¾®è´Ÿè´¡çŒ®é˜¶æ®µ(å¯èƒ½æ˜¯æ•°å€¼è¯¯å·®):")
        for ca in negative_contributions:
            print(f"     {ca['layer_name']}: {ca['psnr_contribution']:.3f}dB")
    else:
        print(f"\nâœ… å®Œç¾ï¼æ‰€æœ‰é˜¶æ®µPSNRä¸¥æ ¼å•è°ƒé€’å¢")
    
    # åˆ›å»ºå¯è§†åŒ–å¯¹æ¯”
    print(f"\nğŸ¨ ç”Ÿæˆåˆ†å—æ¸²æŸ“å¯¹æ¯”å›¾...")
    
    # åˆ›å»º2x3çš„å¸ƒå±€
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('åˆ†å—æ¸²æŸ“å°ºå¯¸åˆ†å±‚æ¸è¿›å¼ç´¯ç§¯æ•ˆæœ - æ— é‡‡æ ·å®Œæ•´ç‰ˆ', fontsize=16, fontweight='bold')
    
    # ç»˜åˆ¶5ä¸ªé˜¶æ®µçš„æ¸²æŸ“ç»“æœ
    for i in range(min(5, len(successful_results))):
        row = i // 3
        col = i % 3
        ax = axes[row, col]
        
        result = successful_results[i]
        ax.imshow(result['images'][0])  # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
        
        title = f"{result['layer_name']}\n{result['metrics']['gaussian_count']:,}çƒ ({result['file_size_mb']:.0f}MB)"
        title += f"\nPSNR: {result['metrics']['psnr']:.2f}dB"
        
        ax.set_title(title, fontsize=11)
        ax.axis('off')
    
    # æœ€åä¸€ä¸ªå­å›¾æ˜¾ç¤ºPSNRè¿›åŒ–æ›²çº¿
    ax = axes[1, 2]
    if len(contribution_analysis) > 1:
        stages = [ca['stage'] for ca in contribution_analysis]
        psnr_values = [ca['cumulative_psnr'] for ca in contribution_analysis]
        contributions = [ca['psnr_contribution'] for ca in contribution_analysis]
        
        # ä¸»æ›²çº¿
        ax.plot(stages, psnr_values, 'bo-', linewidth=3, markersize=8, label='ç´¯ç§¯PSNR')
        
        # è´¡çŒ®æ¡å½¢å›¾ï¼ˆå³è½´ï¼‰
        ax2 = ax.twinx()
        colors = ['green' if c >= 0 else 'red' for c in contributions]
        ax2.bar(stages, contributions, alpha=0.3, color=colors, label='å¢é‡')
        
        ax.set_xlabel('ç´¯ç§¯é˜¶æ®µ')
        ax.set_ylabel('ç´¯ç§¯PSNR (dB)', color='blue')
        ax2.set_ylabel('PSNRå¢é‡ (dB)', color='gray')
        ax.set_title('PSNRè¿›åŒ–æ›²çº¿\n(åˆ†å—æ¸²æŸ“ - æ— é‡‡æ ·)', fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # æ ‡æ³¨æ•°å€¼
        for stage, psnr_val in zip(stages, psnr_values):
            ax.annotate(f'{psnr_val:.2f}', (stage, psnr_val),
                       textcoords="offset points", xytext=(0,10), 
                       ha='center', fontsize=9)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    comparison_file = os.path.join(output_dir, 'tiled_progressive_comparison.png')
    plt.savefig(comparison_file, dpi=200, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… åˆ†å—æ¸²æŸ“å¯¹æ¯”å›¾ä¿å­˜: {comparison_file}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    evaluation_results = {
        'test_camera': '000001.jpg',
        'resolution_scale': 2.0,
        'rendering_method': 'tiled_rendering',
        'sampling': False,
        'progressive_results': [
            {
                'stage': r['stage'],
                'layer_name': r['layer_name'],
                'layer_description': r['layer_description'],
                'file': r['file'],
                'file_size_mb': r['file_size_mb'],
                'success': r['images'] is not None,
                'psnr': r['metrics'].get('psnr', 0) if r['images'] is not None else None,
                'gaussian_count': r['metrics'].get('gaussian_count', 0) if r['images'] is not None else None,
                'tiles_used': f"{r['metrics'].get('tiles_w', 0)}x{r['metrics'].get('tiles_h', 0)}" if r['images'] is not None else None,
                'successful_tiles': r['metrics'].get('successful_tiles', 0) if r['images'] is not None else None,
                'avg_tile_psnr': r['metrics'].get('avg_tile_psnr', 0) if r['images'] is not None else None,
                'error': r['metrics'].get('error') if r['images'] is None else None
            }
            for r in progressive_results
        ],
        'contribution_analysis': contribution_analysis,
        'quality_check': {
            'has_negative_contributions': len(negative_contributions) > 0,
            'negative_contribution_stages': [ca['layer_name'] for ca in negative_contributions],
            'strictly_monotonic': all(ca['psnr_contribution'] >= -0.01 for ca in contribution_analysis[1:]),
            'max_negative_contribution': min([ca['psnr_contribution'] for ca in contribution_analysis[1:]], default=0)
        }
    }
    
    results_file = os.path.join(output_dir, 'tiled_progressive_evaluation.json')
    with open(results_file, 'w') as f:
        json.dump(evaluation_results, f, indent=2)
    
    print(f"âœ… è¯¦ç»†ç»“æœä¿å­˜: {results_file}")
    
    # æ‰“å°æ€»ç»“
    print(f"\nğŸ“Š åˆ†å—æ¸²æŸ“è¯„ä¼°æ€»ç»“:")
    print(f"  æ€»é˜¶æ®µæ•°: {len(progressive_results)}")
    print(f"  æˆåŠŸæ¸²æŸ“: {len(successful_results)}/{len(progressive_results)}")
    if successful_results:
        print(f"  æœ€ç»ˆPSNR: {successful_results[-1]['metrics']['psnr']:.2f}dB")
        if len(successful_results) > 1:
            total_gain = successful_results[-1]['metrics']['psnr'] - successful_results[0]['metrics']['psnr']
            print(f"  æ€»ä½“æå‡: {total_gain:.2f}dB")
            
            if contribution_analysis:
                best_contrib = max(contribution_analysis, key=lambda x: x['psnr_contribution'])
                print(f"  æœ€å¤§è´¡çŒ®é˜¶æ®µ: {best_contrib['layer_name']} (+{best_contrib['psnr_contribution']:.2f}dB)")
                
                print(f"  è´¨é‡æ£€æŸ¥: {'âœ… ä¸¥æ ¼å•è°ƒé€’å¢' if evaluation_results['quality_check']['strictly_monotonic'] else 'âš ï¸ æœ‰è½»å¾®æ³¢åŠ¨'}")
    
    return evaluation_results

def main():
    print("ğŸ“ˆ åˆ†å—æ¸²æŸ“å°ºå¯¸åˆ†å±‚æ¸è¿›å¼è¯„ä¼°")
    print("=" * 50)
    
    layers_dir = "size_based_layers"
    
    if not os.path.exists(layers_dir):
        print(f"âŒ åˆ†å±‚ç›®å½•ä¸å­˜åœ¨: {layers_dir}")
        print("è¯·å…ˆè¿è¡Œ create_size_based_layers.py")
        return
    
    # æ‰§è¡Œåˆ†å—æ¸²æŸ“è¯„ä¼°
    results = evaluate_size_progressive_tiled(layers_dir)
    
    if results:
        print(f"\nğŸ‰ åˆ†å—æ¸²æŸ“è¯„ä¼°å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: size_progressive_tiled/")

if __name__ == "__main__":
    main() 