#!/usr/bin/env python3
# åˆ†æé«˜æ–¯çƒç»Ÿè®¡ä¿¡æ¯
import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import torch
import numpy as np
from scene import GaussianModel

def analyze_gaussians(ply_path):
    print(f"ğŸ” åˆ†æé«˜æ–¯çƒ: {ply_path}")
    
    # åŠ è½½é«˜æ–¯çƒ
    gaussians = GaussianModel(3)  # å‡è®¾sh_degree=3
    gaussians.load_ply(ply_path)
    
    # è·å–åŸºæœ¬ä¿¡æ¯
    positions = gaussians.get_xyz.detach().cpu().numpy()
    opacities = gaussians.get_opacity.detach().cpu().numpy()
    scales = gaussians.get_scaling.detach().cpu().numpy()
    
    print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    print(f"  é«˜æ–¯çƒæ•°é‡: {len(positions)}")
    print(f"  ä½ç½®èŒƒå›´: X[{positions[:, 0].min():.2f}, {positions[:, 0].max():.2f}]")
    print(f"             Y[{positions[:, 1].min():.2f}, {positions[:, 1].max():.2f}]")
    print(f"             Z[{positions[:, 2].min():.2f}, {positions[:, 2].max():.2f}]")
    
    print(f"  ä¸é€æ˜åº¦: å¹³å‡={opacities.mean():.4f}, æ ‡å‡†å·®={opacities.std():.4f}")
    print(f"           æœ€å°={opacities.min():.4f}, æœ€å¤§={opacities.max():.4f}")
    
    print(f"  ç¼©æ”¾: å¹³å‡={scales.mean():.4f}, æ ‡å‡†å·®={scales.std():.4f}")
    print(f"        æœ€å°={scales.min():.4f}, æœ€å¤§={scales.max():.4f}")
    
    # æ£€æŸ¥å¼‚å¸¸å€¼
    print(f"\nğŸš¨ å¼‚å¸¸å€¼æ£€æµ‹:")
    
    # æ£€æŸ¥æå¤§çš„é«˜æ–¯çƒ
    large_scales = scales.max(axis=1) > 1.0  # ç¼©æ”¾è¶…è¿‡1.0çš„
    print(f"  ç¼©æ”¾ > 1.0: {large_scales.sum()} ä¸ª ({large_scales.sum()/len(scales)*100:.1f}%)")
    
    # æ£€æŸ¥æå°çš„ä¸é€æ˜åº¦
    low_opacity = opacities < 0.01
    print(f"  ä¸é€æ˜åº¦ < 0.01: {low_opacity.sum()} ä¸ª ({low_opacity.sum()/len(opacities)*100:.1f}%)")
    
    # æ£€æŸ¥æè¿œçš„ä½ç½®
    far_positions = np.abs(positions).max(axis=1) > 10.0
    print(f"  ä½ç½® > 10.0: {far_positions.sum()} ä¸ª ({far_positions.sum()/len(positions)*100:.1f}%)")
    
    # å»ºè®®è¿‡æ»¤
    suggested_filter = large_scales | low_opacity.flatten() | far_positions
    print(f"  å»ºè®®è¿‡æ»¤: {suggested_filter.sum()} ä¸ª ({suggested_filter.sum()/len(positions)*100:.1f}%)")
    
    return suggested_filter

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--ply-path', required=True)
    args = parser.parse_args()
    
    analyze_gaussians(args.ply_path) 
# åˆ†æé«˜æ–¯çƒç»Ÿè®¡ä¿¡æ¯
import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import torch
import numpy as np
from scene import GaussianModel

def analyze_gaussians(ply_path):
    print(f"ğŸ” åˆ†æé«˜æ–¯çƒ: {ply_path}")
    
    # åŠ è½½é«˜æ–¯çƒ
    gaussians = GaussianModel(3)  # å‡è®¾sh_degree=3
    gaussians.load_ply(ply_path)
    
    # è·å–åŸºæœ¬ä¿¡æ¯
    positions = gaussians.get_xyz.detach().cpu().numpy()
    opacities = gaussians.get_opacity.detach().cpu().numpy()
    scales = gaussians.get_scaling.detach().cpu().numpy()
    
    print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    print(f"  é«˜æ–¯çƒæ•°é‡: {len(positions)}")
    print(f"  ä½ç½®èŒƒå›´: X[{positions[:, 0].min():.2f}, {positions[:, 0].max():.2f}]")
    print(f"             Y[{positions[:, 1].min():.2f}, {positions[:, 1].max():.2f}]")
    print(f"             Z[{positions[:, 2].min():.2f}, {positions[:, 2].max():.2f}]")
    
    print(f"  ä¸é€æ˜åº¦: å¹³å‡={opacities.mean():.4f}, æ ‡å‡†å·®={opacities.std():.4f}")
    print(f"           æœ€å°={opacities.min():.4f}, æœ€å¤§={opacities.max():.4f}")
    
    print(f"  ç¼©æ”¾: å¹³å‡={scales.mean():.4f}, æ ‡å‡†å·®={scales.std():.4f}")
    print(f"        æœ€å°={scales.min():.4f}, æœ€å¤§={scales.max():.4f}")
    
    # æ£€æŸ¥å¼‚å¸¸å€¼
    print(f"\nğŸš¨ å¼‚å¸¸å€¼æ£€æµ‹:")
    
    # æ£€æŸ¥æå¤§çš„é«˜æ–¯çƒ
    large_scales = scales.max(axis=1) > 1.0  # ç¼©æ”¾è¶…è¿‡1.0çš„
    print(f"  ç¼©æ”¾ > 1.0: {large_scales.sum()} ä¸ª ({large_scales.sum()/len(scales)*100:.1f}%)")
    
    # æ£€æŸ¥æå°çš„ä¸é€æ˜åº¦
    low_opacity = opacities < 0.01
    print(f"  ä¸é€æ˜åº¦ < 0.01: {low_opacity.sum()} ä¸ª ({low_opacity.sum()/len(opacities)*100:.1f}%)")
    
    # æ£€æŸ¥æè¿œçš„ä½ç½®
    far_positions = np.abs(positions).max(axis=1) > 10.0
    print(f"  ä½ç½® > 10.0: {far_positions.sum()} ä¸ª ({far_positions.sum()/len(positions)*100:.1f}%)")
    
    # å»ºè®®è¿‡æ»¤
    suggested_filter = large_scales | low_opacity.flatten() | far_positions
    print(f"  å»ºè®®è¿‡æ»¤: {suggested_filter.sum()} ä¸ª ({suggested_filter.sum()/len(positions)*100:.1f}%)")
    
    return suggested_filter

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--ply-path', required=True)
    args = parser.parse_args()
    
    analyze_gaussians(args.ply_path) 