import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import argparse
import json
from collections import defaultdict

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel

def load_gaussians(ply_path):
    """åŠ è½½é«˜æ–¯çƒæ¨¡åž‹"""
    print(f"ðŸŽ¯ åŠ è½½é«˜æ–¯çƒ: {ply_path}")
    gaussians = GaussianModel(3)
    gaussians.load_ply(ply_path, use_train_test_exp=False)
    return gaussians

def analyze_by_position_layers(gaussians, num_layers=10):
    """æŒ‰ä½ç½®åˆ†å±‚åˆ†æž"""
    print(f"\nðŸ“ æŒ‰ä½ç½®åˆ†å±‚åˆ†æž ({num_layers}å±‚)")
    
    xyz = gaussians.get_xyz.detach().cpu().numpy()
    opacity = gaussians.get_opacity.detach().cpu().numpy().squeeze()  # ç¡®ä¿æ˜¯1ç»´
    scaling = gaussians.get_scaling.detach().cpu().numpy()
    
    # è¿‡æ»¤æŽ‰NaNå€¼ - ä¿®å¤ï¼šopacityæ˜¯1ç»´çš„
    valid_mask = ~np.isnan(xyz).any(axis=1) & ~np.isnan(opacity)
    xyz = xyz[valid_mask]
    opacity = opacity[valid_mask]
    scaling = scaling[valid_mask]
    
    print(f"  æœ‰æ•ˆé«˜æ–¯çƒæ•°é‡: {len(xyz)}")
    
    layers_data = []
    
    # æŒ‰Zè½´åˆ†å±‚ï¼ˆæ·±åº¦ï¼‰
    z_min, z_max = xyz[:, 2].min(), xyz[:, 2].max()
    z_step = (z_max - z_min) / num_layers
    
    print(f"  Zè½´èŒƒå›´: [{z_min:.3f}, {z_max:.3f}]")
    print(f"  æ¯å±‚åŽšåº¦: {z_step:.3f}")
    
    for i in range(num_layers):
        z_start = z_min + i * z_step
        z_end = z_min + (i + 1) * z_step
        
        # æœ€åŽä¸€å±‚åŒ…å«è¾¹ç•Œ
        if i == num_layers - 1:
            layer_mask = (xyz[:, 2] >= z_start) & (xyz[:, 2] <= z_end)
        else:
            layer_mask = (xyz[:, 2] >= z_start) & (xyz[:, 2] < z_end)
        
        layer_xyz = xyz[layer_mask]
        layer_opacity = opacity[layer_mask]
        layer_scaling = scaling[layer_mask]
        
        if len(layer_xyz) == 0:
            continue
        
        # ç»Ÿè®¡ä¿¡æ¯
        layer_info = {
            'layer_id': i,
            'z_range': [z_start, z_end],
            'count': len(layer_xyz),
            'opacity_stats': {
                'mean': layer_opacity.mean(),
                'std': layer_opacity.std(),
                'min': layer_opacity.min(),
                'max': layer_opacity.max()
            },
            'scale_stats': {
                'mean': layer_scaling.mean(axis=0),
                'std': layer_scaling.std(axis=0),
                'volume_mean': np.prod(layer_scaling, axis=1).mean()
            },
            'position_stats': {
                'x_range': [layer_xyz[:, 0].min(), layer_xyz[:, 0].max()],
                'y_range': [layer_xyz[:, 1].min(), layer_xyz[:, 1].max()],
                'density': len(layer_xyz) / ((layer_xyz[:, 0].max() - layer_xyz[:, 0].min() + 1e-6) * 
                                           (layer_xyz[:, 1].max() - layer_xyz[:, 1].min() + 1e-6))
            }
        }
        
        layers_data.append(layer_info)
        
        print(f"  å±‚ {i:2d} [{z_start:7.2f}, {z_end:7.2f}]: "
              f"{len(layer_xyz):6d}ä¸ªé«˜æ–¯çƒ, "
              f"å¹³å‡é€æ˜Žåº¦={layer_opacity.mean():.3f}, "
              f"å¹³å‡ä½“ç§¯={np.prod(layer_scaling, axis=1).mean():.6f}")
    
    return layers_data

def analyze_by_opacity_layers(gaussians, num_layers=5):
    """æŒ‰é€æ˜Žåº¦åˆ†å±‚åˆ†æž"""
    print(f"\nðŸ‘» æŒ‰é€æ˜Žåº¦åˆ†å±‚åˆ†æž ({num_layers}å±‚)")
    
    xyz = gaussians.get_xyz.detach().cpu().numpy()
    opacity = gaussians.get_opacity.detach().cpu().numpy().squeeze()  # ç¡®ä¿æ˜¯1ç»´
    scaling = gaussians.get_scaling.detach().cpu().numpy()
    
    # è¿‡æ»¤æŽ‰NaNå€¼ - ä¿®å¤ï¼šopacityæ˜¯1ç»´çš„
    valid_mask = ~np.isnan(xyz).any(axis=1) & ~np.isnan(opacity)
    xyz = xyz[valid_mask]
    opacity = opacity[valid_mask]
    scaling = scaling[valid_mask]
    
    # æŒ‰é€æ˜Žåº¦åˆ†å±‚
    opacity_thresholds = np.linspace(0, 1, num_layers + 1)
    layers_data = []
    
    print(f"  é€æ˜Žåº¦èŒƒå›´: [{opacity.min():.3f}, {opacity.max():.3f}]")
    
    for i in range(num_layers):
        opacity_start = opacity_thresholds[i]
        opacity_end = opacity_thresholds[i + 1]
        
        if i == num_layers - 1:
            layer_mask = (opacity >= opacity_start) & (opacity <= opacity_end)
        else:
            layer_mask = (opacity >= opacity_start) & (opacity < opacity_end)
        
        layer_xyz = xyz[layer_mask]
        layer_opacity = opacity[layer_mask]
        layer_scaling = scaling[layer_mask]
        
        if len(layer_xyz) == 0:
            continue
        
        layer_info = {
            'layer_id': i,
            'opacity_range': [opacity_start, opacity_end],
            'count': len(layer_xyz),
            'position_spread': {
                'x_std': layer_xyz[:, 0].std(),
                'y_std': layer_xyz[:, 1].std(),
                'z_std': layer_xyz[:, 2].std(),
                'z_range': [layer_xyz[:, 2].min(), layer_xyz[:, 2].max()]
            },
            'scale_stats': {
                'mean': layer_scaling.mean(axis=0),
                'volume_mean': np.prod(layer_scaling, axis=1).mean()
            }
        }
        
        layers_data.append(layer_info)
        
        print(f"  é€æ˜Žåº¦ [{opacity_start:.2f}, {opacity_end:.2f}]: "
              f"{len(layer_xyz):6d}ä¸ªé«˜æ–¯çƒ, "
              f"ZèŒƒå›´=[{layer_xyz[:, 2].min():6.2f}, {layer_xyz[:, 2].max():6.2f}], "
              f"å¹³å‡ä½“ç§¯={np.prod(layer_scaling, axis=1).mean():.6f}")
    
    return layers_data

def analyze_by_scale_layers(gaussians, num_layers=5):
    """æŒ‰å¤§å°åˆ†å±‚åˆ†æž"""
    print(f"\nðŸ“ æŒ‰å¤§å°åˆ†å±‚åˆ†æž ({num_layers}å±‚)")
    
    xyz = gaussians.get_xyz.detach().cpu().numpy()
    opacity = gaussians.get_opacity.detach().cpu().numpy().squeeze()  # ç¡®ä¿æ˜¯1ç»´
    scaling = gaussians.get_scaling.detach().cpu().numpy()
    
    # è¿‡æ»¤æŽ‰NaNå€¼ - ä¿®å¤ï¼šopacityæ˜¯1ç»´çš„
    valid_mask = ~np.isnan(xyz).any(axis=1) & ~np.isnan(opacity)
    xyz = xyz[valid_mask]
    opacity = opacity[valid_mask]
    scaling = scaling[valid_mask]
    
    # è®¡ç®—ä½“ç§¯ï¼ˆè¿‘ä¼¼ï¼‰
    volumes = np.prod(scaling, axis=1)
    
    # æŒ‰ä½“ç§¯åˆ†å±‚ï¼ˆä½¿ç”¨å¯¹æ•°å°ºåº¦ï¼Œå› ä¸ºä½“ç§¯å·®å¼‚å¯èƒ½å¾ˆå¤§ï¼‰
    log_volumes = np.log10(volumes + 1e-10)
    volume_thresholds = np.linspace(log_volumes.min(), log_volumes.max(), num_layers + 1)
    layers_data = []
    
    print(f"  ä½“ç§¯èŒƒå›´: [{volumes.min():.2e}, {volumes.max():.2e}]")
    
    for i in range(num_layers):
        vol_start = 10 ** volume_thresholds[i]
        vol_end = 10 ** volume_thresholds[i + 1]
        
        if i == num_layers - 1:
            layer_mask = (volumes >= vol_start) & (volumes <= vol_end)
        else:
            layer_mask = (volumes >= vol_start) & (volumes < vol_end)
        
        layer_xyz = xyz[layer_mask]
        layer_opacity = opacity[layer_mask]
        layer_scaling = scaling[layer_mask]
        layer_volumes = volumes[layer_mask]
        
        if len(layer_xyz) == 0:
            continue
        
        layer_info = {
            'layer_id': i,
            'volume_range': [vol_start, vol_end],
            'count': len(layer_xyz),
            'opacity_stats': {
                'mean': layer_opacity.mean(),
                'std': layer_opacity.std()
            },
            'position_spread': {
                'z_range': [layer_xyz[:, 2].min(), layer_xyz[:, 2].max()],
                'z_std': layer_xyz[:, 2].std()
            },
            'scale_details': {
                'x_scale_mean': layer_scaling[:, 0].mean(),
                'y_scale_mean': layer_scaling[:, 1].mean(),
                'z_scale_mean': layer_scaling[:, 2].mean(),
                'aspect_ratio': (layer_scaling.max(axis=1) / layer_scaling.min(axis=1)).mean()
            }
        }
        
        layers_data.append(layer_info)
        
        print(f"  ä½“ç§¯ [{vol_start:.2e}, {vol_end:.2e}]: "
              f"{len(layer_xyz):6d}ä¸ªé«˜æ–¯çƒ, "
              f"å¹³å‡é€æ˜Žåº¦={layer_opacity.mean():.3f}, "
              f"ZèŒƒå›´=[{layer_xyz[:, 2].min():6.2f}, {layer_xyz[:, 2].max():6.2f}]")
    
    return layers_data

def create_layer_visualizations(position_layers, opacity_layers, scale_layers, output_dir="layer_analysis"):
    """åˆ›å»ºåˆ†å±‚å¯è§†åŒ–"""
    print(f"\nðŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ä½ç½®åˆ†å±‚ç»Ÿè®¡å›¾
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # æ¯å±‚é«˜æ–¯çƒæ•°é‡
    layer_ids = [layer['layer_id'] for layer in position_layers]
    counts = [layer['count'] for layer in position_layers]
    ax1.bar(layer_ids, counts)
    ax1.set_title('æ¯å±‚é«˜æ–¯çƒæ•°é‡ (æŒ‰Zè½´)')
    ax1.set_xlabel('å±‚ID')
    ax1.set_ylabel('é«˜æ–¯çƒæ•°é‡')
    
    # æ¯å±‚å¹³å‡é€æ˜Žåº¦
    avg_opacities = [layer['opacity_stats']['mean'] for layer in position_layers]
    ax2.plot(layer_ids, avg_opacities, 'o-')
    ax2.set_title('æ¯å±‚å¹³å‡é€æ˜Žåº¦')
    ax2.set_xlabel('å±‚ID')
    ax2.set_ylabel('å¹³å‡é€æ˜Žåº¦')
    
    # æ¯å±‚å¹³å‡ä½“ç§¯
    avg_volumes = [layer['scale_stats']['volume_mean'] for layer in position_layers]
    ax3.semilogy(layer_ids, avg_volumes, 's-')
    ax3.set_title('æ¯å±‚å¹³å‡ä½“ç§¯ (å¯¹æ•°å°ºåº¦)')
    ax3.set_xlabel('å±‚ID')
    ax3.set_ylabel('å¹³å‡ä½“ç§¯')
    
    # æ¯å±‚å¯†åº¦
    densities = [layer['position_stats']['density'] for layer in position_layers]
    ax4.plot(layer_ids, densities, '^-')
    ax4.set_title('æ¯å±‚ç©ºé—´å¯†åº¦')
    ax4.set_xlabel('å±‚ID')
    ax4.set_ylabel('å¯†åº¦ (ä¸ª/å•ä½é¢ç§¯)')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'position_layers_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. é€æ˜Žåº¦åˆ†å±‚åˆ†æž
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))
    
    opacity_ranges = [f"{layer['opacity_range'][0]:.2f}-{layer['opacity_range'][1]:.2f}" 
                     for layer in opacity_layers]
    opacity_counts = [layer['count'] for layer in opacity_layers]
    
    ax1.bar(range(len(opacity_layers)), opacity_counts)
    ax1.set_title('ä¸åŒé€æ˜Žåº¦å±‚çš„é«˜æ–¯çƒæ•°é‡')
    ax1.set_xticks(range(len(opacity_layers)))
    ax1.set_xticklabels(opacity_ranges, rotation=45)
    ax1.set_ylabel('é«˜æ–¯çƒæ•°é‡')
    
    # Zè½´åˆ†å¸ƒ
    z_spreads = [layer['position_spread']['z_std'] for layer in opacity_layers]
    ax2.plot(range(len(opacity_layers)), z_spreads, 'o-')
    ax2.set_title('ä¸åŒé€æ˜Žåº¦å±‚çš„Zè½´åˆ†æ•£åº¦')
    ax2.set_xticks(range(len(opacity_layers)))
    ax2.set_xticklabels(opacity_ranges, rotation=45)
    ax2.set_ylabel('Zè½´æ ‡å‡†å·®')
    
    # å¹³å‡ä½“ç§¯
    opacity_volumes = [layer['scale_stats']['volume_mean'] for layer in opacity_layers]
    ax3.semilogy(range(len(opacity_layers)), opacity_volumes, 's-')
    ax3.set_title('ä¸åŒé€æ˜Žåº¦å±‚çš„å¹³å‡ä½“ç§¯')
    ax3.set_xticks(range(len(opacity_layers)))
    ax3.set_xticklabels(opacity_ranges, rotation=45)
    ax3.set_ylabel('å¹³å‡ä½“ç§¯')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'opacity_layers_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. å¤§å°åˆ†å±‚åˆ†æž
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    scale_ranges = [f"{layer['volume_range'][0]:.1e}-{layer['volume_range'][1]:.1e}" 
                   for layer in scale_layers]
    scale_counts = [layer['count'] for layer in scale_layers]
    
    ax1.bar(range(len(scale_layers)), scale_counts)
    ax1.set_title('ä¸åŒå¤§å°å±‚çš„é«˜æ–¯çƒæ•°é‡')
    ax1.set_xticks(range(len(scale_layers)))
    ax1.set_xticklabels(scale_ranges, rotation=45)
    ax1.set_ylabel('é«˜æ–¯çƒæ•°é‡')
    
    # é€æ˜Žåº¦åˆ†å¸ƒ
    scale_opacities = [layer['opacity_stats']['mean'] for layer in scale_layers]
    ax2.plot(range(len(scale_layers)), scale_opacities, 'o-')
    ax2.set_title('ä¸åŒå¤§å°å±‚çš„å¹³å‡é€æ˜Žåº¦')
    ax2.set_xticks(range(len(scale_layers)))
    ax2.set_xticklabels(scale_ranges, rotation=45)
    ax2.set_ylabel('å¹³å‡é€æ˜Žåº¦')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'scale_layers_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ° {output_dir}/")

def save_layer_analysis(position_layers, opacity_layers, scale_layers, output_dir="layer_analysis"):
    """ä¿å­˜åˆ†å±‚åˆ†æžç»“æžœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    analysis_data = {
        'position_layers': position_layers,
        'opacity_layers': opacity_layers,
        'scale_layers': scale_layers,
        'summary': {
            'total_position_layers': len(position_layers),
            'total_opacity_layers': len(opacity_layers),
            'total_scale_layers': len(scale_layers),
            'analysis_date': str(np.datetime64('now'))
        }
    }
    
    output_file = os.path.join(output_dir, 'layer_analysis.json')
    with open(output_file, 'w') as f:
        json.dump(analysis_data, f, indent=2, default=str)
    
    print(f"âœ… åˆ†æžæ•°æ®å·²ä¿å­˜åˆ° {output_file}")

def main():
    parser = argparse.ArgumentParser(description='é«˜æ–¯çƒåˆ†å±‚åˆ†æžå·¥å…·')
    parser.add_argument('--ply-path', type=str, required=True, help='PLYæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--position-layers', type=int, default=10, help='ä½ç½®åˆ†å±‚æ•°é‡')
    parser.add_argument('--opacity-layers', type=int, default=5, help='é€æ˜Žåº¦åˆ†å±‚æ•°é‡')
    parser.add_argument('--scale-layers', type=int, default=5, help='å¤§å°åˆ†å±‚æ•°é‡')
    parser.add_argument('--output-dir', type=str, default='layer_analysis', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("ðŸ” é«˜æ–¯çƒåˆ†å±‚åˆ†æžå·¥å…·")
    print("=" * 60)
    
    # åŠ è½½é«˜æ–¯çƒ
    gaussians = load_gaussians(args.ply_path)
    
    # æŒ‰ä½ç½®åˆ†å±‚
    position_layers = analyze_by_position_layers(gaussians, args.position_layers)
    
    # æŒ‰é€æ˜Žåº¦åˆ†å±‚
    opacity_layers = analyze_by_opacity_layers(gaussians, args.opacity_layers)
    
    # æŒ‰å¤§å°åˆ†å±‚
    scale_layers = analyze_by_scale_layers(gaussians, args.scale_layers)
    
    # åˆ›å»ºå¯è§†åŒ–
    create_layer_visualizations(position_layers, opacity_layers, scale_layers, args.output_dir)
    
    # ä¿å­˜åˆ†æžç»“æžœ
    save_layer_analysis(position_layers, opacity_layers, scale_layers, args.output_dir)
    
    print("\nðŸŽ‰ åˆ†å±‚åˆ†æžå®Œæˆ!")
    print(f"ðŸ“Š ç»“æžœä¿å­˜åœ¨: {args.output_dir}/")

if __name__ == "__main__":
    main() 