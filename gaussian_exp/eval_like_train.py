# eval_like_train.py - å®Œå…¨æŒ‰ç…§train.pyçš„é€»è¾‘
import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import torch
import os
import argparse
from scene import Scene, GaussianModel
from arguments import ModelParams, PipelineParams, OptimizationParams
from gaussian_renderer import render
from utils.image_utils import cal_psnr
import csv
from utils.loss_utils import l1_loss

# Set CUDA device
torch.cuda.set_device(1)

# æ·»åŠ ä¸train.pyå®Œå…¨ä¸€è‡´çš„psnrå‡½æ•°
def psnr(img1, img2):
    """å®Œå…¨æŒ‰ç…§train.pyä¸­åŸå§‹psnrå‡½æ•°çš„å®ç°"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def evaluate_like_train(model_path, ply_file_path):
    print(f"ğŸš€ Loading model from: {model_path}")
    print(f"ğŸ¯ Using gaussian ball: {ply_file_path}")
    
    # ===== ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿model_pathä¸‹æœ‰å›¾ç‰‡æ–‡ä»¶ =====
    original_images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    model_images_path = os.path.join(model_path, "images")
    
    # å¦‚æœmodel_pathä¸‹æ²¡æœ‰å›¾ç‰‡ï¼Œåˆ›å»ºç¬¦å·é“¾æ¥
    if not os.path.exists(model_images_path) or len(os.listdir(model_images_path)) == 0:
        print(f"ğŸ”— Creating symlink for images from {original_images_path} to {model_images_path}")
        if os.path.exists(model_images_path):
            os.rmdir(model_images_path)  # åˆ é™¤ç©ºç›®å½•
        os.symlink(original_images_path, model_images_path)
    
    # ===== å®Œå…¨æŒ‰ç…§train.pyçš„æ–¹å¼åŠ è½½æ•°æ®é›† =====
    parser = argparse.ArgumentParser()
    dataset_parser = ModelParams(parser)
    pipeline_parser = PipelineParams(parser)  # æ·»åŠ Pipelineå‚æ•°
    args = parser.parse_args([])  # ç©ºå‚æ•°
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨è®­ç»ƒæ—¶çš„æ¨¡å‹è·¯å¾„ä½œä¸ºsource_pathï¼Œè¿™æ ·ä¼šåŠ è½½è®­ç»ƒæ—¶ä¿å­˜çš„ç›¸æœºå‚æ•°
    # è€Œä¸æ˜¯é‡æ–°ä»åŸå§‹æ•°æ®é›†åŠ è½½ï¼Œé¿å…ç›¸æœºå‚æ•°ä¸åŒ¹é…çš„é—®é¢˜
    args.source_path = model_path  # ä½¿ç”¨model_pathè€Œä¸æ˜¯åŸå§‹æ•°æ®é›†è·¯å¾„ï¼
    args.model_path = model_path
    args.images = "images"
    args.resolution = -1
    args.white_background = False  # MipNeRF-360 é€šå¸¸ç”¨é»‘èƒŒæ™¯
    args.data_device = "cuda"
    args.eval = False
    
    # æå–å‚æ•°
    dataset = dataset_parser.extract(args)
    pipe = pipeline_parser.extract(args)  # ä½¿ç”¨çœŸæ­£çš„Pipelineå‚æ•°
    
    # ===== æŒ‰ç…§train.pyåŠ è½½é«˜æ–¯æ¨¡å‹ =====
    gaussians = GaussianModel(dataset.sh_degree)
    
    # ç›´æ¥åŠ è½½æŒ‡å®šçš„PLYæ–‡ä»¶
    print(f"Loading gaussians from: {ply_file_path}")
    gaussians.load_ply(ply_file_path)
    print(f"Loaded {gaussians.get_xyz.shape[0]} gaussians")
    
    # ===== æŒ‰ç…§train.pyåŠ è½½åœºæ™¯ï¼ˆä½†ä¸åŠ è½½é«˜æ–¯çƒï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æ‰‹åŠ¨åŠ è½½äº†ï¼‰=====
    # ğŸ”¥ å…³é”®ï¼šç°åœ¨Sceneä¼šä»model_pathåŠ è½½è®­ç»ƒæ—¶ä¿å­˜çš„ç›¸æœºå‚æ•°
    # ä½¿ç”¨load_iteration=1æ¥é¿å…Sceneè°ƒç”¨create_from_pcdï¼Œä½†å®é™…ä¸ä¼šåŠ è½½PLYå› ä¸ºæˆ‘ä»¬å·²ç»åŠ è½½äº†
    scene = Scene(dataset, gaussians, load_iteration=1)  # ä½¿ç”¨è™šæ‹Ÿiterationé¿å…é‡å¤åˆå§‹åŒ–
    
    print(f"Scene loaded successfully")
    
    # ===== æŒ‰ç…§train.pyçš„æµ‹è¯•æ–¹å¼ =====
    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")
    
    # è·å–æµ‹è¯•ç›¸æœºï¼ˆå’Œtrain.pyå®Œå…¨ä¸€è‡´ï¼‰
    test_cameras = scene.getTestCameras()
    train_cameras = scene.getTrainCameras()
    
    print(f"Found {len(test_cameras)} test cameras")
    print(f"Found {len(train_cameras)} train cameras")
    
    # ===== è¯„ä¼°æµ‹è¯•é›† =====
    print("\nğŸ¨ Evaluating test cameras...")
    if len(test_cameras) == 0:
        print("âš ï¸ Warning: No test cameras found! This dataset might not have a separate test split.")
        print("ğŸ”„ Using a subset of training cameras for evaluation instead...")
        # ä½¿ç”¨è®­ç»ƒç›¸æœºçš„ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•
        test_subset = [train_cameras[idx] for idx in range(0, min(len(train_cameras), 10), 2)]
        test_metrics = evaluate_camera_set(test_subset, gaussians, pipe, background, "test_from_train", dataset)
    else:
        test_metrics = evaluate_camera_set(test_cameras, gaussians, pipe, background, "test", dataset)
    
    # ===== è¯„ä¼°è®­ç»ƒé›†ï¼ˆéƒ¨åˆ†ï¼‰ =====
    print("\nğŸ¨ Evaluating train cameras...")
    # æŒ‰ç…§train.pyçš„æ–¹å¼é€‰æ‹©è®­ç»ƒç›¸æœº
    train_subset = [train_cameras[idx % len(train_cameras)] for idx in range(5, min(30, len(train_cameras)), 5)]
    train_metrics = evaluate_camera_set(train_subset, gaussians, pipe, background, "train", dataset)
    
    print(f"\nâœ… Results:")
    print(f"Test PSNR: {test_metrics['psnr']:.2f} dB")
    print(f"Train PSNR: {train_metrics['psnr']:.2f} dB")
    
    return test_metrics, train_metrics

def evaluate_camera_set(cameras, gaussians, pipe, background, name, dataset):
    """è¯„ä¼°ç›¸æœºé›†åˆï¼Œå®Œå…¨æŒ‰ç…§train.pyçš„æ–¹å¼"""
    # æ£€æŸ¥ç›¸æœºé›†åˆæ˜¯å¦ä¸ºç©º
    if len(cameras) == 0:
        print(f"âš ï¸ Warning: No {name} cameras found, skipping evaluation")
        return {'psnr': 0.0, 'loss': 0.0}
    
    all_metrics = {'psnr': [], 'loss': []}
    
    for idx, viewpoint in enumerate(cameras):
        # ===== å®Œå…¨æŒ‰ç…§train.pyçš„æ¸²æŸ“æ–¹å¼ =====
        # ä½¿ç”¨ä¸train.pyå®Œå…¨ç›¸åŒçš„å‚æ•°: (pipe, background, scaling_modifier, separate_sh, override_color, use_trained_exp)
        image = torch.clamp(render(viewpoint, gaussians, pipe, background, 1., False, None, dataset.train_test_exp)["render"], 0.0, 1.0)
        gt_image = torch.clamp(viewpoint.original_image.to("cuda"), 0.0, 1.0)
        
        # ===== æŒ‰ç…§train.pyå¤„ç†train_test_exp =====
        if dataset.train_test_exp:
            image = image[..., image.shape[-1] // 2:]
            gt_image = gt_image[..., gt_image.shape[-1] // 2:]
        
        # ===== æŒ‰ç…§train.pyè®¡ç®—æŒ‡æ ‡ =====
        psnr_val = psnr(image, gt_image).mean().item()
        loss = l1_loss(image, gt_image).mean().item()
        
        all_metrics['psnr'].append(psnr_val)
        all_metrics['loss'].append(loss)
        
        print(f"{name} view {idx} ({viewpoint.image_name}): PSNR = {psnr_val:.2f} dB")
        
        # ä¿å­˜å‰å‡ å¼ å›¾åƒç”¨äºæ£€æŸ¥
        if idx < 3:
            from torchvision.utils import save_image
            os.makedirs(f"renders/{name}", exist_ok=True)
            save_image(image, f"renders/{name}/{viewpoint.image_name.replace('.jpg', '_render.png')}")
            save_image(gt_image, f"renders/{name}/{viewpoint.image_name.replace('.jpg', '_gt.png')}")
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    avg_metrics = {key: sum(values) / len(values) for key, values in all_metrics.items()}
    return avg_metrics

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', required=True, help='Path to the model directory')
    parser.add_argument('--ply-path', required=True, help='Path to the gaussian ball PLY file')
    args = parser.parse_args()
    
    evaluate_like_train(args.model_path, args.ply_path)

if __name__ == '__main__':
    main()