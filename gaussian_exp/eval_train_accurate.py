#!/usr/bin/env python3
"""
å‡†ç¡®æ¨¡æ‹Ÿè®­ç»ƒæ—¶å‚æ•°çš„è¯„ä¼°è„šæœ¬
åŸºäºutils/camera_utils.pyçš„é€»è¾‘
"""

import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import os
import torch
from tqdm import tqdm
from gaussian_renderer import render
from scene.gaussian_model import GaussianModel
from scene.cameras import Camera
from utils.graphics_utils import focal2fov
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary
import numpy as np
from PIL import Image
import torchvision.transforms.functional as TF

class DummyRenderPipe:
    """å®Œå…¨æ¨¡æ‹Ÿtrain.pyçš„PipelineParams"""
    def __init__(self):
        # ä¸train.pyä¿æŒä¸€è‡´çš„æ¸²æŸ“ç®¡é“å‚æ•°
        self.convert_SHs_python = False
        self.compute_cov3D_python = False
        self.antialiasing = False  # é™¤éç‰¹åˆ«æŒ‡å®š
        self.debug = False
        
        # ç¡®ä¿ä¸è®­ç»ƒæ—¶çš„èƒŒæ™¯è®¾ç½®ä¸€è‡´
        self.SPARSE_ADAM_AVAILABLE = False

class DummyArgs:
    """å®Œå…¨æ¨¡æ‹Ÿtrain.pyçš„å‚æ•°"""
    def __init__(self):
        # å…³é”®å‚æ•°ï¼šä¸train.pyä¿æŒå®Œå…¨ä¸€è‡´
        self.resolution = -1  # è¡¨ç¤ºè‡ªåŠ¨ç¼©æ”¾
        self.train_test_exp = False  # cfg_argsç¡®è®¤ 
        self.eval = False  # æ‰€ä»¥æ²¡æœ‰test set
        self.white_background = False
        self.data_device = "cuda"
        
        # ç¡®ä¿sparse adamè®¾ç½®ä¸€è‡´
        self.SPARSE_ADAM_AVAILABLE = False

def create_camera_like_training(image_info, intrinsics, images_dir, resolution_scale=1.0):
    """å®Œå…¨æŒ‰ç…§è®­ç»ƒæ—¶çš„é€»è¾‘åˆ›å»ºCameraå¯¹è±¡"""
    
    args = DummyArgs()
    
    # åŠ è½½å›¾ç‰‡
    image_path = os.path.join(images_dir, image_info.name)
    pil_image = Image.open(image_path)
    if pil_image.mode != 'RGB':
        pil_image = pil_image.convert('RGB')
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„åˆ†è¾¨ç‡å¤„ç†é€»è¾‘ (æ¥è‡ªcamera_utils.py)
    orig_w, orig_h = pil_image.size
    print(f"åŸå§‹å°ºå¯¸: {orig_w}x{orig_h}")
    
    if args.resolution in [1, 2, 4, 8]:
        resolution = round(orig_w/(resolution_scale * args.resolution)), round(orig_h/(resolution_scale * args.resolution))
    else:  # args.resolution == -1
        if orig_w > 1600:
            print("[ INFO ] å›¾ç‰‡å®½åº¦>1600, ç¼©æ”¾åˆ°1600")
            global_down = orig_w / 1600
        else:
            global_down = 1
            print(f"[ INFO ] å›¾ç‰‡å®½åº¦<1600, global_down = {global_down}")
        
        scale = float(global_down) * float(resolution_scale)
        resolution = (int(orig_w / scale), int(orig_h / scale))
    
    print(f"è®¡ç®—çš„åˆ†è¾¨ç‡: {resolution}, global_down={global_down if 'global_down' in locals() else 'N/A'}, scale={scale if 'scale' in locals() else 'N/A'}")
    
    # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
    if resolution != (orig_w, orig_h):
        pil_image = pil_image.resize(resolution, Image.LANCZOS)
        print(f"è°ƒæ•´åå°ºå¯¸: {resolution}")
    
    # è½¬æ¢ä¸ºtensor
    image_tensor = TF.to_tensor(pil_image)
    
    # è®¡ç®—ç›¸æœºå‚æ•°
    width, height = resolution
    
    # è·å–å†…å‚å¹¶æ ¹æ®åˆ†è¾¨ç‡è°ƒæ•´
    fx, fy = intrinsics.params[0], intrinsics.params[1]
    cx, cy = intrinsics.params[2], intrinsics.params[3]
    
    # è°ƒæ•´å†…å‚ä»¥åŒ¹é…æ–°åˆ†è¾¨ç‡
    if resolution != (orig_w, orig_h):
        scale_x = width / orig_w
        scale_y = height / orig_h
        fx *= scale_x
        fy *= scale_y
        cx *= scale_x
        cy *= scale_y
    
    # è®¡ç®—FoV
    FoVx = focal2fov(fx, width)
    FoVy = focal2fov(fy, height)
    
    print(f"è°ƒæ•´åå†…å‚: fx={fx:.1f}, fy={fy:.1f}, cx={cx:.1f}, cy={cy:.1f}")
    print(f"FoV: {FoVx*180/np.pi:.1f}Â° x {FoVy*180/np.pi:.1f}Â°")
    
    # ç›¸æœºå¤–å‚ - å…³é”®ï¼šä¸train.pyä¿æŒä¸€è‡´ï¼
    # åœ¨dataset_readers.pyç¬¬85è¡Œ: R = np.transpose(qvec2rotmat(extr.qvec))
    R = np.transpose(image_info.qvec2rotmat())  # ğŸ”¥ è¿™æ˜¯å…³é”®ä¿®å¤ï¼
    T = np.array(image_info.tvec)
    
    # åˆ›å»ºCameraå¯¹è±¡ (å®Œå…¨æŒ‰ç…§è®­ç»ƒæ—¶çš„æ–¹å¼)
    camera = Camera(
        resolution=resolution,
        colmap_id=image_info.id,
        R=R,
        T=T,
        FoVx=FoVx,
        FoVy=FoVy,
        depth_params=None,
        image=image_tensor,
        invdepthmap=None,
        image_name=image_info.name,
        uid=image_info.id,
        data_device=args.data_device,
        train_test_exp=args.train_test_exp,
        is_test_dataset=True,
        is_test_view=True
    )
    
    return camera

def test_training_accurate(ply_path, colmap_sparse_dir, images_dir):
    print("ğŸ¯ ä½¿ç”¨è®­ç»ƒç²¾ç¡®å‚æ•°æµ‹è¯•")
    
    # åŠ è½½é«˜æ–¯çƒ
    gaussians = GaussianModel(sh_degree=3)
    gaussians.load_ply(ply_path)
    
    # è¯»å–COLMAPæ•°æ®
    cameras_intrinsic_file = os.path.join(colmap_sparse_dir, "cameras.bin")
    cameras_extrinsic_file = os.path.join(colmap_sparse_dir, "images.bin")
    
    cam_intrinsics = read_intrinsics_binary(cameras_intrinsic_file)
    cam_extrinsics = read_extrinsics_binary(cameras_extrinsic_file)
    
    # æµ‹è¯•å¤šä¸ªä¸åŒçš„resolution_scale
    scales_to_test = [1.0, 2.0, 4.0]
    
    for resolution_scale in scales_to_test:
        print(f"\n{'='*50}")
        print(f"ğŸ” æµ‹è¯• resolution_scale = {resolution_scale}")
        print(f"{'='*50}")
        
        # åªæµ‹è¯•ç¬¬ä¸€ä¸ªç›¸æœº
        image_id, image_info = list(cam_extrinsics.items())[0]
        camera_id = image_info.camera_id
        intrinsics = cam_intrinsics[camera_id]
        
        try:
            camera = create_camera_like_training(image_info, intrinsics, images_dir, resolution_scale)
            
            # æ¸²æŸ“ - ä½¿ç”¨ä¸train.pyä¸€è‡´çš„èƒŒæ™¯
            pipe = DummyRenderPipe()
            args = DummyArgs()
            # ä¸train.pyç¬¬229è¡Œä¿æŒä¸€è‡´: bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
            bg_color = torch.tensor([1.0, 1.0, 1.0] if args.white_background else [0.0, 0.0, 0.0], 
                                  dtype=torch.float32, device='cuda')
            render_pkg = render(camera, gaussians, pipe=pipe, bg_color=bg_color)
            rendered = torch.clamp(render_pkg['render'], 0.0, 1.0)
            gt = torch.clamp(camera.original_image.to(rendered.device), 0.0, 1.0)
            
            print(f"æ¸²æŸ“å°ºå¯¸: {rendered.shape}")
            print(f"GTå°ºå¯¸: {gt.shape}")
            
            # è®¡ç®—PSNR
            mse = torch.mean((rendered - gt) ** 2)
            if mse > 0:
                psnr_val = 20 * torch.log10(1.0 / torch.sqrt(mse)).item()
            else:
                psnr_val = 100.0
            print(f"PSNR: {psnr_val:.2f} dB")
            
            # ä¿å­˜æ ·æœ¬å›¾ç‰‡
            def tensor_to_image(tensor):
                if tensor.is_cuda:
                    tensor = tensor.detach().cpu()
                else:
                    tensor = tensor.detach()
                tensor = tensor.permute(1, 2, 0).numpy()
                tensor = (tensor * 255).clip(0, 255).astype(np.uint8)
                return Image.fromarray(tensor)
            
            rendered_img = tensor_to_image(rendered)
            gt_img = tensor_to_image(gt)
            
            rendered_img.save(f"train_accurate_scale_{resolution_scale}_rendered.png")
            gt_img.save(f"train_accurate_scale_{resolution_scale}_gt.png")
            print(f"ä¿å­˜æ ·æœ¬: train_accurate_scale_{resolution_scale}_*.png")
            
        except Exception as e:
            print(f"âŒ resolution_scale {resolution_scale} å¤±è´¥: {e}")

def main():
    ply_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/output/truck-150w/gaussian_ball/iteration_994230_best_psnr/gaussian_ball.ply"
    colmap_sparse_dir = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/truck/sparse/0"
    images_dir = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/truck/images"
    
    test_training_accurate(ply_path, colmap_sparse_dir, images_dir)

if __name__ == '__main__':
    main() 