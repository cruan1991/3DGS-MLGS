import os
import sys
import torch
import numpy as np
import argparse
import json
import glob
from PIL import Image
import matplotlib.pyplot as plt
from plyfile import PlyData, PlyElement

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel
from scene.cameras import Camera
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render
from utils.graphics_utils import focal2fov
from utils.loss_utils import l1_loss

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def load_multi_cameras(colmap_path, images_path, resolution_scale=6.0):
    """åŠ è½½å¤šä¸ªæµ‹è¯•ç›¸æœº"""
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    # é€‰æ‹©å‡ ä¸ªä¸åŒè§’åº¦çš„ç›¸æœº
    test_cameras = []
    camera_names = ["000001.jpg", "000030.jpg", "000060.jpg", "000090.jpg"]  # ä¸åŒè§’åº¦
    
    for camera_name in camera_names:
        # æ‰¾åˆ°æŒ‡å®šç›¸æœº
        target_img_id = None
        for img_id, img_info in cam_extrinsics.items():
            if img_info.name == camera_name:
                target_img_id = img_id
                break
        
        if target_img_id is None:
            print(f"âš ï¸ æœªæ‰¾åˆ°ç›¸æœº: {camera_name}")
            continue
        
        img_info = cam_extrinsics[target_img_id]
        intrinsic = cam_intrinsics[img_info.camera_id]
        
        # è§£æå‚æ•°
        fx, fy, cx, cy = intrinsic.params
        width = int(intrinsic.width / resolution_scale)
        height = int(intrinsic.height / resolution_scale)
        fx_scaled = fx / resolution_scale
        fy_scaled = fy / resolution_scale
        
        FoVx = focal2fov(fx_scaled, width)
        FoVy = focal2fov(fy_scaled, height)
        
        R = np.transpose(qvec2rotmat(img_info.qvec))
        T = np.array(img_info.tvec)
        
        # åŠ è½½å›¾åƒ
        image_path = os.path.join(images_path, img_info.name)
        if not os.path.exists(image_path):
            print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {camera_name}")
            continue
            
        image = Image.open(image_path)
        if resolution_scale != 1.0:
            image = image.resize((width, height), Image.LANCZOS)
        
        camera = Camera(
            resolution=(width, height),
            colmap_id=target_img_id,
            R=R,
            T=T,
            FoVx=FoVx,
            FoVy=FoVy,
            depth_params=None,
            image=image,
            invdepthmap=None,
            image_name=img_info.name,
            uid=len(test_cameras),
            data_device="cuda",
            train_test_exp=False,
            is_test_dataset=False,
            is_test_view=False
        )
        
        test_cameras.append({
            'camera': camera,
            'name': camera_name,
            'position': T,
            'rotation': R
        })
        
        print(f"âœ… åŠ è½½ç›¸æœº: {camera_name} ä½ç½®: [{T[0]:.2f}, {T[1]:.2f}, {T[2]:.2f}]")
    
    return test_cameras

def save_gaussians_like_original(xyz_data, normals_data, f_dc_data, f_rest_data, 
                               opacity_data, scale_data, rotation_data, output_path):
    """ä½¿ç”¨ä¸åŸå§‹save_plyå®Œå…¨ç›¸åŒçš„é€»è¾‘ä¿å­˜"""
    
    # æ„é€ å±æ€§åˆ—è¡¨ (ä¸åŸå§‹é€»è¾‘ç›¸åŒ)
    def construct_list_of_attributes():
        l = ['x', 'y', 'z', 'nx', 'ny', 'nz']
        # DCç‰¹å¾
        for i in range(f_dc_data.shape[1]):
            l.append('f_dc_{}'.format(i))
        # Restç‰¹å¾  
        for i in range(f_rest_data.shape[1]):
            l.append('f_rest_{}'.format(i))
        l.append('opacity')
        for i in range(scale_data.shape[1]):
            l.append('scale_{}'.format(i))
        for i in range(rotation_data.shape[1]):
            l.append('rot_{}'.format(i))
        return l
    
    # ç»„åˆæ‰€æœ‰å±æ€§ (ä¸åŸå§‹å®Œå…¨ç›¸åŒ)
    dtype_full = [(attribute, 'f4') for attribute in construct_list_of_attributes()]
    elements = np.empty(xyz_data.shape[0], dtype=dtype_full)
    attributes = np.concatenate((xyz_data, normals_data, f_dc_data, f_rest_data, 
                               opacity_data, scale_data, rotation_data), axis=1)
    elements[:] = list(map(tuple, attributes))
    
    # ä¿å­˜æ–‡ä»¶
    el = PlyElement.describe(elements, 'vertex')
    PlyData([el]).write(output_path)

def create_alternative_layering_strategies():
    """åˆ›å»ºå¤šç§åˆ†å±‚ç­–ç•¥"""
    print("ğŸ”„ åˆ›å»ºå¤šç§åˆ†å±‚ç­–ç•¥")
    print("=" * 50)
    
    # åŠ è½½åŸå§‹æ¨¡å‹
    ply_path = "./output/truck-150w/gaussian_ball/iteration_994230_best_psnr/gaussian_ball.ply"
    gaussians = GaussianModel(3)
    gaussians.load_ply(ply_path, use_train_test_exp=False)
    
    # ä½¿ç”¨ä¸åŸå§‹save_plyå®Œå…¨ç›¸åŒçš„é€»è¾‘æå–æ•°æ®
    xyz = gaussians._xyz.detach().cpu().numpy()
    normals = np.zeros_like(xyz)
    f_dc = gaussians._features_dc.detach().transpose(1, 2).flatten(start_dim=1).contiguous().cpu().numpy()
    f_rest = gaussians._features_rest.detach().transpose(1, 2).flatten(start_dim=1).contiguous().cpu().numpy()
    opacity = gaussians._opacity.detach().cpu().numpy()
    scaling = gaussians._scaling.detach().cpu().numpy()
    rotation = gaussians._rotation.detach().cpu().numpy()
    
    # æ£€æŸ¥å¹¶å¤„ç†NaNå€¼
    nan_mask = np.isnan(xyz)
    nan_positions = np.any(nan_mask, axis=1)
    nan_count = np.sum(nan_positions)
    
    if nan_count > 0:
        print(f"âš ï¸ å‘ç° {nan_count} ä¸ªNaNä½ç½®ï¼Œå°†è¢«æ’é™¤")
        valid_mask = ~nan_positions
        xyz = xyz[valid_mask]
        normals = normals[valid_mask]
        f_dc = f_dc[valid_mask]
        f_rest = f_rest[valid_mask]
        opacity = opacity[valid_mask]
        scaling = scaling[valid_mask]
        rotation = rotation[valid_mask]
        print(f"ğŸ“Š æœ‰æ•ˆé«˜æ–¯çƒæ•°: {len(xyz):,}")
    
    # è®¡ç®—åœºæ™¯ä¸­å¿ƒ
    scene_center = np.mean(xyz, axis=0)
    print(f"ğŸ“ åœºæ™¯ä¸­å¿ƒ: [{scene_center[0]:.3f}, {scene_center[1]:.3f}, {scene_center[2]:.3f}]")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "alternative_layering"
    os.makedirs(output_dir, exist_ok=True)
    
    layering_strategies = []
    
    # ç­–ç•¥1: æŒ‰è·ç¦»åœºæ™¯ä¸­å¿ƒçš„è·ç¦»åˆ†å±‚
    print(f"\nğŸ¯ ç­–ç•¥1: æŒ‰è·ç¦»åœºæ™¯ä¸­å¿ƒåˆ†å±‚")
    distances_to_center = np.linalg.norm(xyz - scene_center, axis=1)
    distance_percentiles = np.percentile(distances_to_center, [20, 40, 60, 80])
    
    for i in range(5):
        if i == 0:
            mask = distances_to_center <= distance_percentiles[0]
            layer_name = "center_core"
            layer_desc = "æ ¸å¿ƒåŒºåŸŸ"
        elif i == 4:
            mask = distances_to_center > distance_percentiles[3]
            layer_name = "center_outer"
            layer_desc = "å¤–å›´åŒºåŸŸ"
        else:
            mask = (distances_to_center > distance_percentiles[i-1]) & (distances_to_center <= distance_percentiles[i])
            layer_name = f"center_ring{i}"
            layer_desc = f"ç¯å¸¦{i}"
        
        count = np.sum(mask)
        print(f"  å±‚{i} ({layer_desc}): {count:,}çƒ è·ç¦»èŒƒå›´: {distances_to_center[mask].min():.3f}~{distances_to_center[mask].max():.3f}")
        
        # ä¿å­˜å•å±‚æ–‡ä»¶
        filename = f"center_layer_{i}_{layer_name}_{count}balls.ply"
        layer_path = os.path.join(output_dir, filename)
        save_gaussians_like_original(
            xyz[mask], normals[mask], f_dc[mask], f_rest[mask],
            opacity[mask], scaling[mask], rotation[mask], layer_path
        )
    
    layering_strategies.append({
        'name': 'center_distance',
        'description': 'æŒ‰è·ç¦»åœºæ™¯ä¸­å¿ƒåˆ†å±‚',
        'thresholds': distance_percentiles.tolist(),
        'metric': 'distance_to_center'
    })
    
    # ç­–ç•¥2: æŒ‰é€æ˜åº¦åˆ†å±‚
    print(f"\nğŸ¯ ç­–ç•¥2: æŒ‰é€æ˜åº¦åˆ†å±‚")
    opacity_flat = opacity.flatten()
    opacity_percentiles = np.percentile(opacity_flat, [20, 40, 60, 80])
    
    for i in range(5):
        if i == 0:
            mask = opacity_flat <= opacity_percentiles[0]
            layer_name = "opacity_low"
            layer_desc = "ä½é€æ˜åº¦"
        elif i == 4:
            mask = opacity_flat > opacity_percentiles[3]
            layer_name = "opacity_high"
            layer_desc = "é«˜é€æ˜åº¦"
        else:
            mask = (opacity_flat > opacity_percentiles[i-1]) & (opacity_flat <= opacity_percentiles[i])
            layer_name = f"opacity_mid{i}"
            layer_desc = f"ä¸­ç­‰é€æ˜åº¦{i}"
        
        count = np.sum(mask)
        print(f"  å±‚{i} ({layer_desc}): {count:,}çƒ é€æ˜åº¦èŒƒå›´: {opacity_flat[mask].min():.3f}~{opacity_flat[mask].max():.3f}")
        
        # ä¿å­˜å•å±‚æ–‡ä»¶
        filename = f"opacity_layer_{i}_{layer_name}_{count}balls.ply"
        layer_path = os.path.join(output_dir, filename)
        save_gaussians_like_original(
            xyz[mask], normals[mask], f_dc[mask], f_rest[mask],
            opacity[mask], scaling[mask], rotation[mask], layer_path
        )
    
    layering_strategies.append({
        'name': 'opacity',
        'description': 'æŒ‰é€æ˜åº¦åˆ†å±‚',
        'thresholds': opacity_percentiles.tolist(),
        'metric': 'opacity'
    })
    
    # ç­–ç•¥3: æŒ‰æŸä¸ªå›ºå®šè§†è§’çš„Zæ·±åº¦åˆ†å±‚ (000001.jpgè§†è§’)
    print(f"\nğŸ¯ ç­–ç•¥3: æŒ‰è§†è§’000001.jpgçš„Zæ·±åº¦åˆ†å±‚")
    # éœ€è¦åŠ è½½ç›¸æœºå‚æ•°æ¥è®¡ç®—Zæ·±åº¦
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    # æ‰¾åˆ°000001.jpgçš„ç›¸æœºå‚æ•°
    ref_camera_info = None
    for img_id, img_info in cam_extrinsics.items():
        if img_info.name == "000001.jpg":
            ref_camera_info = img_info
            break
    
    if ref_camera_info:
        ref_R = np.transpose(qvec2rotmat(ref_camera_info.qvec))
        ref_T = np.array(ref_camera_info.tvec)
        
        # è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»è®¡ç®—Zæ·±åº¦
        xyz_cam = np.dot(xyz - ref_T, ref_R.T)  # å˜æ¢åˆ°ç›¸æœºåæ ‡ç³»
        z_depths = xyz_cam[:, 2]  # Zæ·±åº¦
        
        z_percentiles = np.percentile(z_depths, [20, 40, 60, 80])
        
        for i in range(5):
            if i == 0:
                mask = z_depths <= z_percentiles[0]
                layer_name = "zdepth_near"
                layer_desc = "è¿‘æ™¯"
            elif i == 4:
                mask = z_depths > z_percentiles[3]
                layer_name = "zdepth_far"
                layer_desc = "è¿œæ™¯"
            else:
                mask = (z_depths > z_percentiles[i-1]) & (z_depths <= z_percentiles[i])
                layer_name = f"zdepth_mid{i}"
                layer_desc = f"ä¸­æ™¯{i}"
            
            count = np.sum(mask)
            print(f"  å±‚{i} ({layer_desc}): {count:,}çƒ Zæ·±åº¦èŒƒå›´: {z_depths[mask].min():.3f}~{z_depths[mask].max():.3f}")
            
            # ä¿å­˜å•å±‚æ–‡ä»¶
            filename = f"zdepth_layer_{i}_{layer_name}_{count}balls.ply"
            layer_path = os.path.join(output_dir, filename)
            save_gaussians_like_original(
                xyz[mask], normals[mask], f_dc[mask], f_rest[mask],
                opacity[mask], scaling[mask], rotation[mask], layer_path
            )
        
        layering_strategies.append({
            'name': 'zdepth_000001',
            'description': 'æŒ‰000001.jpgè§†è§’Zæ·±åº¦åˆ†å±‚',
            'thresholds': z_percentiles.tolist(),
            'metric': 'z_depth_from_000001',
            'reference_camera': {
                'name': '000001.jpg',
                'position': ref_T.tolist(),
                'rotation': ref_R.tolist()
            }
        })
    
    # ä¿å­˜ç­–ç•¥ä¿¡æ¯
    strategies_info = {
        'strategies': layering_strategies,
        'scene_center': scene_center.tolist(),
        'total_gaussians': len(xyz),
        'created_files': len(layering_strategies) * 5
    }
    
    info_path = os.path.join(output_dir, 'layering_strategies_info.json')
    with open(info_path, 'w') as f:
        json.dump(strategies_info, f, indent=2)
    
    print(f"\nâœ… åˆ›å»ºäº† {len(layering_strategies)} ç§åˆ†å±‚ç­–ç•¥ï¼Œå…± {len(layering_strategies) * 5} ä¸ªå±‚æ–‡ä»¶")
    print(f"ğŸ“ ä¿å­˜åˆ°ç›®å½•: {output_dir}")
    print(f"ğŸ“‹ ç­–ç•¥ä¿¡æ¯ä¿å­˜: {info_path}")
    
    return layering_strategies

def evaluate_strategy_across_views(strategy_name, test_cameras):
    """è¯„ä¼°æŸä¸ªåˆ†å±‚ç­–ç•¥åœ¨å¤šä¸ªè§†è§’ä¸‹çš„è¡¨ç°"""
    print(f"\nğŸ” è¯„ä¼°ç­–ç•¥ '{strategy_name}' åœ¨å¤šè§†è§’ä¸‹çš„è¡¨ç°")
    
    # è®¾ç½®æ¸²æŸ“ç¯å¢ƒ
    pipeline_parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(pipeline_parser)
    pipe_args = pipeline_parser.parse_args([])
    pipe = pipe_parser.extract(pipe_args)
    
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # æŸ¥æ‰¾è¯¥ç­–ç•¥çš„å±‚æ–‡ä»¶
    if strategy_name == "center_distance":
        layer_files = glob.glob(f"alternative_layering/center_layer_*.ply")
    elif strategy_name == "opacity":
        layer_files = glob.glob(f"alternative_layering/opacity_layer_*.ply")
    elif strategy_name == "zdepth_000001":
        layer_files = glob.glob(f"alternative_layering/zdepth_layer_*.ply")
    else:
        layer_files = glob.glob(f"alternative_layering/{strategy_name}_layer_*.ply")
    layer_files.sort()
    
    if len(layer_files) == 0:
        print(f"âŒ æœªæ‰¾åˆ°ç­–ç•¥ {strategy_name} çš„å±‚æ–‡ä»¶")
        return None
    
    print(f"ğŸ“ æ‰¾åˆ° {len(layer_files)} ä¸ªå±‚æ–‡ä»¶")
    
    # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
    try:
        from diff_gaussian_rasterization import SparseGaussianAdam
        SPARSE_ADAM_AVAILABLE = True
    except:
        SPARSE_ADAM_AVAILABLE = False
    
    results = {}
    
    # å¯¹æ¯ä¸ªè§†è§’æµ‹è¯•æ¯ä¸ªå±‚
    for camera_info in test_cameras:
        camera = camera_info['camera']
        camera_name = camera_info['name']
        
        print(f"\nğŸ“· æµ‹è¯•è§†è§’: {camera_name}")
        
        camera_results = []
        
        for i, layer_file in enumerate(layer_files):
            layer_name = os.path.basename(layer_file).replace('.ply', '')
            
            try:
                # æ¸…ç†GPUç¼“å­˜
                torch.cuda.empty_cache()
                
                # åŠ è½½é«˜æ–¯çƒ
                gaussians = GaussianModel(3)
                gaussians.load_ply(layer_file, use_train_test_exp=False)
                
                gaussian_count = gaussians.get_xyz.shape[0]
                
                # æ¸²æŸ“
                render_result = render(camera, gaussians, pipe, background, 1., 
                                     SPARSE_ADAM_AVAILABLE, None, False)
                rendered_image = torch.clamp(render_result["render"], 0.0, 1.0)
                
                # GTå›¾åƒ
                gt_image = torch.clamp(camera.original_image.to("cuda"), 0.0, 1.0)
                
                # è®¡ç®—æŒ‡æ ‡
                psnr_val = psnr(rendered_image, gt_image).mean().item()
                l1_val = l1_loss(rendered_image, gt_image).mean().item()
                
                camera_results.append({
                    'layer_id': i,
                    'layer_name': layer_name,
                    'gaussian_count': gaussian_count,
                    'psnr': psnr_val,
                    'l1_loss': l1_val
                })
                
                print(f"  å±‚{i}: {gaussian_count:,}çƒ PSNR: {psnr_val:.3f}dB")
                
                # æ¸…ç†å†…å­˜
                del gaussians, render_result, rendered_image, gt_image
                torch.cuda.empty_cache()
                
            except Exception as e:
                print(f"  å±‚{i}: âŒ æ¸²æŸ“å¤±è´¥ - {str(e)[:50]}...")
                camera_results.append({
                    'layer_id': i,
                    'layer_name': layer_name,
                    'gaussian_count': 0,
                    'psnr': 0.0,
                    'l1_loss': 1.0,
                    'error': str(e)
                })
        
        results[camera_name] = camera_results
    
    return results

def analyze_view_consistency():
    """åˆ†æä¸åŒåˆ†å±‚ç­–ç•¥åœ¨å¤šè§†è§’ä¸‹çš„ä¸€è‡´æ€§"""
    print("ğŸ¯ å¤šè§†è§’åˆ†å±‚ä¸€è‡´æ€§åˆ†æ")
    print("=" * 60)
    
    # 1. åˆ›å»ºå¤šç§åˆ†å±‚ç­–ç•¥
    print("æ­¥éª¤1: åˆ›å»ºå¤šç§åˆ†å±‚ç­–ç•¥")
    strategies = create_alternative_layering_strategies()
    
    # 2. åŠ è½½å¤šä¸ªæµ‹è¯•ç›¸æœº
    print("\næ­¥éª¤2: åŠ è½½å¤šä¸ªæµ‹è¯•ç›¸æœº")
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    test_cameras = load_multi_cameras(colmap_path, images_path, 6.0)
    
    if len(test_cameras) == 0:
        print("âŒ æœªèƒ½åŠ è½½ä»»ä½•æµ‹è¯•ç›¸æœº")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(test_cameras)} ä¸ªæµ‹è¯•ç›¸æœº")
    
    # 3. è¯„ä¼°æ¯ç§ç­–ç•¥åœ¨å¤šè§†è§’ä¸‹çš„è¡¨ç°
    print("\næ­¥éª¤3: è¯„ä¼°å¤šè§†è§’è¡¨ç°")
    
    all_results = {}
    
    for strategy in strategies:
        strategy_name = strategy['name']
        print(f"\n{'='*20} è¯„ä¼°ç­–ç•¥: {strategy['description']} {'='*20}")
        
        strategy_results = evaluate_strategy_across_views(strategy_name, test_cameras)
        if strategy_results:
            all_results[strategy_name] = strategy_results
    
    # 4. åˆ†æç»“æœ
    print(f"\nğŸ“Š å¤šè§†è§’ä¸€è‡´æ€§åˆ†æç»“æœ")
    print("=" * 50)
    
    if len(all_results) == 0:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯„ä¼°ç»“æœ")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "multi_view_analysis"
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ†ææ¯ç§ç­–ç•¥çš„è§†è§’ä¸€è‡´æ€§
    consistency_analysis = {}
    
    for strategy_name, strategy_results in all_results.items():
        print(f"\nğŸ” ç­–ç•¥: {strategy_name}")
        
        # è®¡ç®—æ¯å±‚åœ¨ä¸åŒè§†è§’çš„PSNRæ–¹å·®ï¼ˆä¸€è‡´æ€§æŒ‡æ ‡ï¼‰
        layer_consistency = []
        
        for layer_id in range(5):  # å‡è®¾æ¯ä¸ªç­–ç•¥éƒ½æœ‰5å±‚
            layer_psnrs = []
            layer_counts = []
            
            for camera_name, camera_results in strategy_results.items():
                if layer_id < len(camera_results):
                    layer_result = camera_results[layer_id]
                    if 'error' not in layer_result:
                        layer_psnrs.append(layer_result['psnr'])
                        layer_counts.append(layer_result['gaussian_count'])
            
            if len(layer_psnrs) > 0:
                psnr_mean = np.mean(layer_psnrs)
                psnr_std = np.std(layer_psnrs)
                consistency_score = psnr_mean / (psnr_std + 1e-6)  # é¿å…é™¤é›¶
                
                layer_consistency.append({
                    'layer_id': layer_id,
                    'psnr_mean': psnr_mean,
                    'psnr_std': psnr_std,
                    'consistency_score': consistency_score,
                    'gaussian_count': layer_counts[0] if layer_counts else 0,
                    'view_count': len(layer_psnrs)
                })
                
                print(f"  å±‚{layer_id}: PSNR={psnr_mean:.3f}Â±{psnr_std:.3f}dB ä¸€è‡´æ€§={consistency_score:.2f} ({layer_counts[0] if layer_counts else 0:,}çƒ)")
        
        consistency_analysis[strategy_name] = layer_consistency
        
        # è®¡ç®—ç­–ç•¥çš„æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†
        if layer_consistency:
            overall_consistency = np.mean([layer['consistency_score'] for layer in layer_consistency])
            print(f"  ğŸ“ˆ æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†: {overall_consistency:.3f}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    analysis_results = {
        'strategies_evaluated': list(all_results.keys()),
        'test_cameras': [cam['name'] for cam in test_cameras],
        'detailed_results': all_results,
        'consistency_analysis': consistency_analysis,
        'summary': {
            'best_strategy_by_consistency': max(consistency_analysis.keys(), 
                                              key=lambda k: np.mean([layer['consistency_score'] for layer in consistency_analysis[k]]) if consistency_analysis[k] else 0),
            'analysis_notes': [
                "consistency_score = psnr_mean / psnr_std: è¶Šé«˜è¡¨ç¤ºåœ¨ä¸åŒè§†è§’ä¸‹è¡¨ç°è¶Šä¸€è‡´",
                "center_distanceç­–ç•¥: åŸºäºè·ç¦»åœºæ™¯ä¸­å¿ƒçš„è·ç¦»ï¼Œè§†è§’æ— å…³",
                "opacityç­–ç•¥: åŸºäºé€æ˜åº¦ï¼Œè§†è§’æ— å…³",  
                "zdepth_000001ç­–ç•¥: åŸºäºç‰¹å®šè§†è§’çš„æ·±åº¦ï¼Œè§†è§’ç›¸å…³"
            ]
        }
    }
    
    results_file = os.path.join(output_dir, 'multi_view_consistency_analysis.json')
    with open(results_file, 'w') as f:
        json.dump(analysis_results, f, indent=2)
    
    print(f"\nâœ… å¤šè§†è§’ä¸€è‡´æ€§åˆ†æå®Œæˆ")
    print(f"ğŸ“ è¯¦ç»†ç»“æœä¿å­˜: {results_file}")
    
    # æ¨èæœ€ä½³ç­–ç•¥
    if consistency_analysis:
        best_strategy = analysis_results['summary']['best_strategy_by_consistency']
        print(f"ğŸ† æ¨èç­–ç•¥: {best_strategy}")
        print(f"   åŸå› : åœ¨å¤šä¸ªè§†è§’ä¸‹è¡¨ç°æœ€ä¸€è‡´")
    
    return analysis_results

def main():
    analyze_view_consistency()

if __name__ == "__main__":
    main() 