import os
import sys
import torch
import numpy as np
import argparse
import json
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import glob

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel
from scene.cameras import Camera
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render
from utils.general_utils import PILtoTorch
from utils.graphics_utils import focal2fov
from utils.loss_utils import l1_loss

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def load_cameras_sample(colmap_path, images_path, resolution_scale=2.0, num_cameras=3):
    """åŠ è½½å‡ ä¸ªé‡‡æ ·ç›¸æœºç”¨äºå¯¹æ¯”"""
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    # é€‰æ‹©å‡ ä¸ªæœ‰ä»£è¡¨æ€§çš„ç›¸æœºï¼ˆå‡åŒ€é‡‡æ ·ï¼‰
    img_ids = list(cam_extrinsics.keys())
    selected_ids = [img_ids[i] for i in np.linspace(0, len(img_ids)-1, num_cameras, dtype=int)]
    
    cameras = []
    
    for idx, img_id in enumerate(selected_ids):
        img_info = cam_extrinsics[img_id]
        intrinsic = cam_intrinsics[img_info.camera_id]
        
        # è§£æå‚æ•°
        fx, fy, cx, cy = intrinsic.params
        width = int(intrinsic.width / resolution_scale)
        height = int(intrinsic.height / resolution_scale)
        fx_scaled = fx / resolution_scale
        fy_scaled = fy / resolution_scale
        
        FoVx = focal2fov(fx_scaled, width)
        FoVy = focal2fov(fy_scaled, height)
        
        R = np.transpose(qvec2rotmat(img_info.qvec))
        T = np.array(img_info.tvec)
        
        # åŠ è½½å›¾åƒ
        image_path = os.path.join(images_path, img_info.name)
        image = Image.open(image_path)
        if resolution_scale != 1.0:
            image = image.resize((width, height), Image.LANCZOS)
        
        camera = Camera(
            resolution=(width, height),
            colmap_id=img_id,
            R=R,
            T=T,
            FoVx=FoVx,
            FoVy=FoVy,
            depth_params=None,
            image=image,
            invdepthmap=None,
            image_name=img_info.name,
            uid=idx,
            data_device="cuda",
            train_test_exp=False,
            is_test_dataset=False,
            is_test_view=False
        )
        
        cameras.append(camera)
        print(f"âœ… ç›¸æœº {idx}: {img_info.name}")
    
    return cameras

def render_ply_file(ply_path, camera, pipe, background):
    """æ¸²æŸ“å•ä¸ªPLYæ–‡ä»¶"""
    if not os.path.exists(ply_path):
        return None, {"error": "File not found"}
    
    try:
        # åŠ è½½é«˜æ–¯çƒ
        gaussians = GaussianModel(3)
        gaussians.load_ply(ply_path, use_train_test_exp=False)
        
        # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
        try:
            from diff_gaussian_rasterization import SparseGaussianAdam
            SPARSE_ADAM_AVAILABLE = True
        except:
            SPARSE_ADAM_AVAILABLE = False
        
        # æ¸²æŸ“
        render_result = render(camera, gaussians, pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, False)
        rendered_image = torch.clamp(render_result["render"], 0.0, 1.0)
        
        # GTå›¾åƒ
        gt_image = torch.clamp(camera.original_image.to("cuda"), 0.0, 1.0)
        
        # è®¡ç®—æŒ‡æ ‡
        psnr_val = psnr(rendered_image, gt_image).mean().item()
        l1_val = l1_loss(rendered_image, gt_image).mean().item()
        
        # è½¬æ¢ä¸ºnumpyç”¨äºå¯è§†åŒ–
        rendered_np = rendered_image.detach().cpu().numpy().transpose(1, 2, 0)
        gt_np = gt_image.detach().cpu().numpy().transpose(1, 2, 0)
        
        return (rendered_np, gt_np), {
            "psnr": psnr_val,
            "l1_loss": l1_val,
            "gaussian_count": gaussians.get_xyz.shape[0]
        }
        
    except Exception as e:
        return None, {"error": str(e)}

def create_comprehensive_comparison(camera_idx, camera_name, layer_files, progressive_files, camera, pipe, background, output_dir):
    """åˆ›å»ºç»¼åˆå¯¹æ¯”å›¾"""
    print(f"ğŸ¨ æ¸²æŸ“ç›¸æœº {camera_idx}: {camera_name}")
    
    # æ¸²æŸ“æ‰€æœ‰æ–‡ä»¶
    single_layer_results = []
    progressive_results = []
    
    # æ¸²æŸ“å•å±‚æ–‡ä»¶
    for i, layer_file in enumerate(layer_files):
        print(f"  æ¸²æŸ“å±‚ {i}...")
        images, metrics = render_ply_file(layer_file, camera, pipe, background)
        single_layer_results.append((images, metrics, i))
    
    # æ¸²æŸ“æ¸è¿›å¼æ–‡ä»¶
    for i, prog_file in enumerate(progressive_files):
        print(f"  æ¸²æŸ“ç´¯ç§¯æ–‡ä»¶ {i+1}/5...")
        images, metrics = render_ply_file(prog_file, camera, pipe, background)
        progressive_results.append((images, metrics, i))
    
    # åˆ›å»ºå¤§çš„å¯¹æ¯”å›¾
    fig, axes = plt.subplots(4, 5, figsize=(25, 20))
    fig.suptitle(f'é«˜æ–¯çƒåˆ†å±‚æ¸²æŸ“å¯¹æ¯” - Camera {camera_idx} ({camera_name})', fontsize=20, fontweight='bold')
    
    # ç¬¬ä¸€è¡Œï¼šå•å±‚æ¸²æŸ“ç»“æœ
    for i in range(5):
        ax = axes[0, i]
        if i < len(single_layer_results) and single_layer_results[i][0] is not None:
            images, metrics, layer_id = single_layer_results[i]
            ax.imshow(images[0])  # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
            title = f"å±‚{layer_id}\n{metrics['gaussian_count']:,}çƒ\nPSNR: {metrics['psnr']:.2f}dB"
        else:
            ax.text(0.5, 0.5, f"å±‚{i}\næ— æ•°æ®", ha='center', va='center', transform=ax.transAxes, fontsize=12)
            title = f"å±‚{i}"
        
        ax.set_title(title, fontsize=12)
        ax.axis('off')
    
    # ç¬¬äºŒè¡Œï¼šæ¸è¿›å¼ç´¯ç§¯ç»“æœ
    for i in range(5):
        ax = axes[1, i]
        if i < len(progressive_results) and progressive_results[i][0] is not None:
            images, metrics, prog_id = progressive_results[i]
            ax.imshow(images[0])  # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
            if i == 0:
                layers_str = "L0"
            else:
                layers_str = f"L0-L{i}"
            title = f"{layers_str}\n{metrics['gaussian_count']:,}çƒ\nPSNR: {metrics['psnr']:.2f}dB"
        else:
            ax.text(0.5, 0.5, f"ç´¯ç§¯{i+1}\næ— æ•°æ®", ha='center', va='center', transform=ax.transAxes, fontsize=12)
            title = f"ç´¯ç§¯{i+1}"
        
        ax.set_title(title, fontsize=12)
        ax.axis('off')
    
    # ç¬¬ä¸‰è¡Œï¼šå…³é”®å¯¹æ¯”
    # GT
    ax = axes[2, 0]
    if progressive_results and progressive_results[0][0] is not None:
        ax.imshow(progressive_results[0][0][1])
    ax.set_title('Ground Truth', fontsize=14, fontweight='bold')
    ax.axis('off')
    
    # å±‚3æ ¸å¿ƒ
    ax = axes[2, 1]
    if len(progressive_results) > 3 and progressive_results[3][0] is not None:
        ax.imshow(progressive_results[3][0][0])
        ax.set_title(f'å±‚3æ ¸å¿ƒ\n{progressive_results[3][1]["psnr"]:.2f}dB', fontsize=14, fontweight='bold')
    ax.axis('off')
    
    # å®Œæ•´æ¨¡å‹
    ax = axes[2, 2]
    if progressive_results and progressive_results[-1][0] is not None:
        ax.imshow(progressive_results[-1][0][0])
        ax.set_title(f'å®Œæ•´æ¨¡å‹\n{progressive_results[-1][1]["psnr"]:.2f}dB', fontsize=14, fontweight='bold')
    ax.axis('off')
    
    # å·®å¼‚å›¾ï¼šå®Œæ•´-GT
    ax = axes[2, 3]
    if progressive_results and progressive_results[-1][0] is not None:
        rendered = progressive_results[-1][0][0]
        gt = progressive_results[-1][0][1]
        diff = np.abs(rendered - gt)
        ax.imshow(diff)
        ax.set_title('å·®å¼‚å›¾\n(å®Œæ•´-GT)', fontsize=14, fontweight='bold')
    ax.axis('off')
    
    # PSNRæ›²çº¿
    ax = axes[2, 4]
    if progressive_results:
        psnr_values = [res[1]['psnr'] for res in progressive_results if res[0] is not None]
        counts = [res[1]['gaussian_count'] for res in progressive_results if res[0] is not None]
        
        x_labels = ['L0', 'L0-L1', 'L0-L2', 'L0-L3', 'L0-L4'][:len(psnr_values)]
        
        ax.plot(range(len(psnr_values)), psnr_values, 'bo-', linewidth=3, markersize=8)
        ax.set_xticks(range(len(psnr_values)))
        ax.set_xticklabels(x_labels, rotation=45)
        ax.set_ylabel('PSNR (dB)', fontsize=12)
        ax.set_title('PSNR Evolution', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # æ ‡æ³¨æ•°å€¼
        for i, (psnr_val, count) in enumerate(zip(psnr_values, counts)):
            ax.annotate(f'{psnr_val:.1f}', (i, psnr_val), 
                       textcoords="offset points", xytext=(0,10), 
                       ha='center', fontsize=10, fontweight='bold')
    
    # ç¬¬å››è¡Œï¼šè´¡çŒ®åˆ†æ
    ax = axes[3, 0]
    if progressive_results:
        # ç»˜åˆ¶æ¯å±‚çš„è´¡çŒ®
        contributions = []
        for i in range(len(progressive_results)):
            if i == 0:
                contrib = progressive_results[i][1]['psnr'] if progressive_results[i][0] else 0
            else:
                prev_psnr = progressive_results[i-1][1]['psnr'] if progressive_results[i-1][0] else 0
                curr_psnr = progressive_results[i][1]['psnr'] if progressive_results[i][0] else 0
                contrib = curr_psnr - prev_psnr
            contributions.append(contrib)
        
        bars = ax.bar(range(len(contributions)), contributions, 
                     color=['red', 'orange', 'yellow', 'green', 'blue'][:len(contributions)])
        ax.set_xticks(range(len(contributions)))
        ax.set_xticklabels([f'L{i}' for i in range(len(contributions))])
        ax.set_ylabel('PSNR Contribution (dB)')
        ax.set_title('Layer Contributions', fontsize=14, fontweight='bold')
        
        # æ ‡æ³¨æ•°å€¼
        for i, (bar, contrib) in enumerate(zip(bars, contributions)):
            height = bar.get_height()
            ax.annotate(f'{contrib:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),
                       xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
    
    # é«˜æ–¯çƒæ•°é‡åˆ†å¸ƒ
    ax = axes[3, 1]
    if single_layer_results:
        counts = [res[1]['gaussian_count'] for res in single_layer_results if res[0] is not None]
        labels = [f'L{i}' for i in range(len(counts))]
        
        ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)
        ax.set_title('Gaussian Distribution', fontsize=14, fontweight='bold')
    
    # æ¸…ç©ºå‰©ä½™å­å›¾
    for i in range(2, 5):
        axes[3, i].axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_file = os.path.join(output_dir, f'comprehensive_comparison_camera_{camera_idx}_{camera_name.replace(".jpg", "")}.png')
    plt.savefig(output_file, dpi=200, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ä¿å­˜ç»¼åˆå¯¹æ¯”å›¾: {output_file}")
    
    return output_file

def main():
    print("ğŸ¨ åˆ†å±‚æ¸²æŸ“ç»¼åˆå¯è§†åŒ–å¯¹æ¯”")
    print("=" * 60)
    
    # å‚æ•°
    layer_dir = 'layer_progressive_analysis'
    output_dir = 'layer_comprehensive_comparison'
    num_cameras = 3
    resolution_scale = 2.0
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰¾åˆ°æ‰€æœ‰æ–‡ä»¶
    layer_files = sorted(glob.glob(os.path.join(layer_dir, "layer_*.ply")))
    progressive_files = sorted(glob.glob(os.path.join(layer_dir, "progressive_*.ply")))
    
    print(f"ğŸ“ æ‰¾åˆ°åˆ†å±‚æ–‡ä»¶: {len(layer_files)}ä¸ª")
    for f in layer_files:
        print(f"  {os.path.basename(f)}")
    
    print(f"ğŸ“ˆ æ‰¾åˆ°æ¸è¿›æ–‡ä»¶: {len(progressive_files)}ä¸ª")
    for f in progressive_files:
        print(f"  {os.path.basename(f)}")
    
    if len(layer_files) == 0:
        print("âŒ æœªæ‰¾åˆ°åˆ†å±‚æ–‡ä»¶ï¼")
        return
    
    # è®¾ç½®æ¸²æŸ“ç¯å¢ƒ
    print(f"\nâš™ï¸ è®¾ç½®æ¸²æŸ“ç¯å¢ƒ...")
    
    # Pipelineå‚æ•°
    pipeline_parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(pipeline_parser)
    pipe_args = pipeline_parser.parse_args([])
    pipe = pipe_parser.extract(pipe_args)
    
    # èƒŒæ™¯
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # åŠ è½½ç›¸æœº
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    cameras = load_cameras_sample(colmap_path, images_path, resolution_scale, num_cameras)
    
    print(f"âœ… åŠ è½½äº† {len(cameras)} ä¸ªç›¸æœº")
    
    # ä¸ºæ¯ä¸ªç›¸æœºåˆ›å»ºç»¼åˆå¯¹æ¯”å›¾
    print(f"\nğŸ¨ å¼€å§‹ç»¼åˆæ¸²æŸ“å¯¹æ¯”...")
    
    comparison_files = []
    for i, camera in enumerate(cameras):
        comparison_file = create_comprehensive_comparison(
            i, camera.image_name, layer_files, progressive_files,
            camera, pipe, background, output_dir
        )
        comparison_files.append(comparison_file)
    
    print(f"\nğŸ‰ ç»¼åˆå¯¹æ¯”å®Œæˆ!")
    print(f"ğŸ“Š ç”Ÿæˆäº† {len(comparison_files)} ä¸ªç»¼åˆå¯¹æ¯”å›¾")
    print(f"ğŸ“ ä¿å­˜åœ¨: {output_dir}/")
    
    for file in comparison_files:
        print(f"  ğŸ“¸ {file}")

if __name__ == "__main__":
    main() 