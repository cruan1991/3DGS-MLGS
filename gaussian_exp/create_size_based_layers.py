import os
import sys
import torch
import numpy as np
import json
from pathlib import Path

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel
from plyfile import PlyData, PlyElement

def create_size_based_layers(ply_path, analysis_results_path, output_dir='size_based_layers'):
    """æ ¹æ®å°ºå¯¸åˆ†æç»“æœåˆ›å»ºåˆ†å±‚PLYæ–‡ä»¶"""
    print("ğŸ”„ åˆ›å»ºæŒ‰å°ºå¯¸åˆ†å±‚çš„PLYæ–‡ä»¶...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½åˆ†æç»“æœ
    with open(analysis_results_path, 'r') as f:
        analysis_results = json.load(f)
    
    layer_suggestions = analysis_results['layer_suggestions']
    thresholds = analysis_results['thresholds']
    
    print(f"ğŸ“Š åŠ è½½åˆ†å±‚æ–¹æ¡ˆ: {len(layer_suggestions)} å±‚")
    for layer in layer_suggestions:
        print(f"  å±‚{layer['layer_id']} ({layer['name']}): {layer['count']:,}çƒ ({layer['percentage']:.1f}%)")
    
    # åŠ è½½åŸå§‹é«˜æ–¯çƒ
    gaussians = GaussianModel(3)
    gaussians.load_ply(ply_path, use_train_test_exp=False)
    
    # è·å–æ‰€æœ‰å‚æ•°
    xyz = gaussians.get_xyz.detach().cpu().numpy()
    features_dc = gaussians._features_dc.detach().cpu().numpy()
    features_rest = gaussians._features_rest.detach().cpu().numpy()
    scaling = gaussians.get_scaling.detach().cpu().numpy()
    rotation = gaussians.get_rotation.detach().cpu().numpy()
    opacity = gaussians.get_opacity.detach().cpu().numpy()
    
    # è®¡ç®—å¹³å‡å°ºå¯¸
    avg_scale = np.mean(scaling, axis=1)
    
    print(f"\nğŸ“ åŸå§‹æ¨¡å‹å‚æ•°:")
    print(f"  ä½ç½®: {xyz.shape}")
    print(f"  DCç‰¹å¾: {features_dc.shape}")
    print(f"  Restç‰¹å¾: {features_rest.shape}")
    print(f"  ç¼©æ”¾: {scaling.shape}")
    print(f"  æ—‹è½¬: {rotation.shape}")
    print(f"  é€æ˜åº¦: {opacity.shape}")
    
    # ä¸ºæ¯å±‚åˆ›å»ºPLYæ–‡ä»¶
    layer_files = []
    
    for layer in layer_suggestions:
        layer_id = layer['layer_id']
        layer_name = layer['name']
        print(f"\nğŸ¯ åˆ›å»ºå±‚{layer_id} ({layer_name})...")
        
        # æ ¹æ®é˜ˆå€¼åˆ›å»ºmask
        if layer_id == 0:
            mask = avg_scale <= thresholds[0]
        elif layer_id == len(layer_suggestions) - 1:
            mask = avg_scale > thresholds[-1]
        else:
            mask = (avg_scale > thresholds[layer_id-1]) & (avg_scale <= thresholds[layer_id])
        
        layer_count = np.sum(mask)
        print(f"  ç­›é€‰åˆ° {layer_count:,} ä¸ªé«˜æ–¯çƒ")
        
        if layer_count == 0:
            print(f"  âš ï¸ å±‚{layer_id}ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        # æå–è¯¥å±‚çš„å‚æ•°
        layer_xyz = xyz[mask]
        layer_features_dc = features_dc[mask]
        layer_features_rest = features_rest[mask]
        layer_scaling = scaling[mask]
        layer_rotation = rotation[mask]
        layer_opacity = opacity[mask]
        
        # æ„é€ PLYæ•°æ®
        def construct_list_of_attributes():
            l = ['x', 'y', 'z', 'nx', 'ny', 'nz']
            # DCç‰¹å¾
            for i in range(layer_features_dc.shape[1] * layer_features_dc.shape[2]):
                l.append('f_dc_{}'.format(i))
            # Restç‰¹å¾  
            for i in range(layer_features_rest.shape[1] * layer_features_rest.shape[2]):
                l.append('f_rest_{}'.format(i))
            l.append('opacity')
            for i in range(layer_scaling.shape[1]):
                l.append('scale_{}'.format(i))
            for i in range(layer_rotation.shape[1]):
                l.append('rot_{}'.format(i))
            return l
        
        # å‡†å¤‡æ•°æ®
        normals = np.zeros_like(layer_xyz)  # æ³•å‘é‡è®¾ä¸º0
        
        # DCç‰¹å¾reshape
        f_dc = layer_features_dc.reshape((layer_features_dc.shape[0], -1))
        f_rest = layer_features_rest.reshape((layer_features_rest.shape[0], -1))
        
        # ç»„åˆæ‰€æœ‰å±æ€§
        attributes = np.concatenate([
            layer_xyz, normals, f_dc, f_rest, 
            layer_opacity, layer_scaling, layer_rotation
        ], axis=1)
        
        # æ„é€ PLYå…ƒç´ 
        elements = np.empty(layer_count, dtype=[
            (attr, 'f4') for attr in construct_list_of_attributes()
        ])
        
        attr_names = construct_list_of_attributes()
        for i, attr_name in enumerate(attr_names):
            elements[attr_name] = attributes[:, i]
        
        # ä¿å­˜PLYæ–‡ä»¶
        scale_range = layer['threshold_range'].replace('â‰¤', 'le').replace('>', 'gt').replace('~', '_to_')
        avg_scale_in_layer = np.mean(avg_scale[mask])
        filename = f"size_layer_{layer_id}_{layer_name}_{scale_range}_{layer_count}balls_avg{avg_scale_in_layer:.6f}.ply"
        layer_file_path = os.path.join(output_dir, filename)
        
        el = PlyElement.describe(elements, 'vertex')
        PlyData([el]).write(layer_file_path)
        
        layer_files.append(layer_file_path)
        print(f"  âœ… ä¿å­˜: {filename}")
        print(f"     å¹³å‡å°ºå¯¸: {avg_scale_in_layer:.6f}")
        print(f"     å°ºå¯¸èŒƒå›´: {np.min(avg_scale[mask]):.6f} ~ {np.max(avg_scale[mask]):.6f}")
    
    print(f"\nğŸ“ å•å±‚æ–‡ä»¶åˆ›å»ºå®Œæˆ: {len(layer_files)} ä¸ª")
    
    # åˆ›å»ºæ¸è¿›å¼ç´¯ç§¯æ–‡ä»¶
    print(f"\nğŸ”„ åˆ›å»ºæ¸è¿›å¼ç´¯ç§¯æ–‡ä»¶...")
    progressive_files = []
    
    for end_layer in range(len(layer_suggestions)):
        print(f"\nğŸ¯ åˆ›å»ºç´¯ç§¯æ–‡ä»¶: å±‚0åˆ°å±‚{end_layer}...")
        
        # åˆå¹¶mask
        combined_mask = np.zeros(len(avg_scale), dtype=bool)
        total_count = 0
        
        for layer_id in range(end_layer + 1):
            layer = layer_suggestions[layer_id]
            
            # é‡æ–°è®¡ç®—è¯¥å±‚çš„mask
            if layer_id == 0:
                mask = avg_scale <= thresholds[0]
            elif layer_id == len(layer_suggestions) - 1:
                mask = avg_scale > thresholds[-1]
            else:
                mask = (avg_scale > thresholds[layer_id-1]) & (avg_scale <= thresholds[layer_id])
            
            combined_mask |= mask
            total_count += np.sum(mask)
        
        print(f"  ç´¯ç§¯é«˜æ–¯çƒæ•°: {np.sum(combined_mask):,}")
        
        if np.sum(combined_mask) == 0:
            print(f"  âš ï¸ ç´¯ç§¯å±‚ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        # æå–ç´¯ç§¯å‚æ•°
        prog_xyz = xyz[combined_mask]
        prog_features_dc = features_dc[combined_mask]
        prog_features_rest = features_rest[combined_mask]
        prog_scaling = scaling[combined_mask]
        prog_rotation = rotation[combined_mask]
        prog_opacity = opacity[combined_mask]
        
        # æ„é€ PLYæ•°æ® (æ­£ç¡®ç‰ˆæœ¬)
        def construct_progressive_attributes():
            l = ['x', 'y', 'z', 'nx', 'ny', 'nz']
            # DCç‰¹å¾
            for i in range(prog_features_dc.shape[1] * prog_features_dc.shape[2]):
                l.append('f_dc_{}'.format(i))
            # Restç‰¹å¾  
            for i in range(prog_features_rest.shape[1] * prog_features_rest.shape[2]):
                l.append('f_rest_{}'.format(i))
            l.append('opacity')
            for i in range(prog_scaling.shape[1]):
                l.append('scale_{}'.format(i))
            for i in range(prog_rotation.shape[1]):
                l.append('rot_{}'.format(i))
            return l
        
        normals = np.zeros_like(prog_xyz)
        f_dc = prog_features_dc.reshape((prog_features_dc.shape[0], -1))
        f_rest = prog_features_rest.reshape((prog_features_rest.shape[0], -1))
        
        attributes = np.concatenate([
            prog_xyz, normals, f_dc, f_rest, 
            prog_opacity, prog_scaling, prog_rotation
        ], axis=1)
        
        elements = np.empty(np.sum(combined_mask), dtype=[
            (attr, 'f4') for attr in construct_progressive_attributes()
        ])
        
        attr_names = construct_progressive_attributes()
        for i, attr_name in enumerate(attr_names):
            elements[attr_name] = attributes[:, i]
        
        # ä¿å­˜æ¸è¿›å¼æ–‡ä»¶
        if end_layer == 0:
            filename = f"size_progressive_S0_{np.sum(combined_mask)}balls.ply"
        else:
            # æ­£ç¡®çš„ç´¯ç§¯å‘½åï¼šS0_S1_S2...S{end_layer}
            layer_names = '_'.join([f"S{i}" for i in range(end_layer + 1)])
            filename = f"size_progressive_{layer_names}_{np.sum(combined_mask)}balls.ply"
        
        prog_file_path = os.path.join(output_dir, filename)
        
        el = PlyElement.describe(elements, 'vertex')
        PlyData([el]).write(prog_file_path)
        
        progressive_files.append(prog_file_path)
        print(f"  âœ… ä¿å­˜: {filename}")
    
    print(f"\nğŸ“ˆ æ¸è¿›å¼æ–‡ä»¶åˆ›å»ºå®Œæˆ: {len(progressive_files)} ä¸ª")
    
    # ä¿å­˜æ–‡ä»¶æ¸…å•
    file_manifest = {
        'single_layers': [os.path.basename(f) for f in layer_files],
        'progressive_layers': [os.path.basename(f) for f in progressive_files],
        'layer_info': layer_suggestions,
        'thresholds': thresholds,
        'total_gaussians': len(avg_scale)
    }
    
    manifest_path = os.path.join(output_dir, 'size_layers_manifest.json')
    with open(manifest_path, 'w') as f:
        json.dump(file_manifest, f, indent=2)
    
    print(f"âœ… æ–‡ä»¶æ¸…å•ä¿å­˜: {manifest_path}")
    
    return layer_files, progressive_files

def main():
    print("ğŸ”„ æŒ‰å°ºå¯¸åˆ›å»ºé«˜æ–¯çƒåˆ†å±‚æ–‡ä»¶")
    print("=" * 50)
    
    # æ–‡ä»¶è·¯å¾„
    ply_path = "./output/truck-150w/gaussian_ball/iteration_994230_best_psnr/gaussian_ball.ply"
    analysis_results_path = "./scale_analysis/scale_analysis_results.json"
    
    if not os.path.exists(ply_path):
        print(f"âŒ PLYæ–‡ä»¶ä¸å­˜åœ¨: {ply_path}")
        return
    
    if not os.path.exists(analysis_results_path):
        print(f"âŒ åˆ†æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {analysis_results_path}")
        print("è¯·å…ˆè¿è¡Œ analyze_scale_distribution.py")
        return
    
    # åˆ›å»ºåˆ†å±‚æ–‡ä»¶
    layer_files, progressive_files = create_size_based_layers(
        ply_path, analysis_results_path
    )
    
    print(f"\nğŸ‰ å°ºå¯¸åˆ†å±‚æ–‡ä»¶åˆ›å»ºå®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: size_based_layers/")
    print(f"ğŸ“Š å•å±‚æ–‡ä»¶: {len(layer_files)} ä¸ª")
    print(f"ğŸ“ˆ æ¸è¿›æ–‡ä»¶: {len(progressive_files)} ä¸ª")
    print(f"ğŸ“‹ æ€»è®¡: {len(layer_files) + len(progressive_files)} ä¸ªPLYæ–‡ä»¶")

if __name__ == "__main__":
    main() 