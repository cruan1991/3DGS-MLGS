import os
import sys
import torch
import numpy as np
import argparse
import json
import glob
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import GaussianModel
from scene.cameras import Camera
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render
from utils.general_utils import PILtoTorch
from utils.graphics_utils import focal2fov
from utils.loss_utils import l1_loss

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def load_test_camera(colmap_path, images_path, camera_name="000001.jpg", resolution_scale=4.0):
    """åŠ è½½æµ‹è¯•ç›¸æœºï¼Œä½¿ç”¨æ›´å¤§çš„ç¼©æ”¾ä»¥èŠ‚çœå†…å­˜"""
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    # æ‰¾åˆ°æŒ‡å®šç›¸æœº
    target_img_id = None
    for img_id, img_info in cam_extrinsics.items():
        if img_info.name == camera_name:
            target_img_id = img_id
            break
    
    if target_img_id is None:
        print(f"âŒ æœªæ‰¾åˆ°ç›¸æœº: {camera_name}")
        return None
    
    img_info = cam_extrinsics[target_img_id]
    intrinsic = cam_intrinsics[img_info.camera_id]
    
    # è§£æå‚æ•°
    fx, fy, cx, cy = intrinsic.params
    width = int(intrinsic.width / resolution_scale)
    height = int(intrinsic.height / resolution_scale)
    fx_scaled = fx / resolution_scale
    fy_scaled = fy / resolution_scale
    
    FoVx = focal2fov(fx_scaled, width)
    FoVy = focal2fov(fy_scaled, height)
    
    R = np.transpose(qvec2rotmat(img_info.qvec))
    T = np.array(img_info.tvec)
    
    # åŠ è½½å›¾åƒ
    image_path = os.path.join(images_path, img_info.name)
    image = Image.open(image_path)
    if resolution_scale != 1.0:
        image = image.resize((width, height), Image.LANCZOS)
    
    camera = Camera(
        resolution=(width, height),
        colmap_id=target_img_id,
        R=R,
        T=T,
        FoVx=FoVx,
        FoVy=FoVy,
        depth_params=None,
        image=image,
        invdepthmap=None,
        image_name=img_info.name,
        uid=0,
        data_device="cuda",
        train_test_exp=False,
        is_test_dataset=False,
        is_test_view=False
    )
    
    return camera

def render_ply_file_safe(ply_path, camera, pipe, background):
    """å®‰å…¨æ¸²æŸ“PLYæ–‡ä»¶ï¼Œå¤„ç†å†…å­˜ä¸è¶³çš„æƒ…å†µ"""
    if not os.path.exists(ply_path):
        return None, {"error": "File not found"}
    
    try:
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        
        # åŠ è½½é«˜æ–¯çƒ
        gaussians = GaussianModel(3)
        gaussians.load_ply(ply_path, use_train_test_exp=False)
        
        gaussian_count = gaussians.get_xyz.shape[0]
        print(f"    åŠ è½½äº† {gaussian_count:,} ä¸ªé«˜æ–¯çƒ")
        
        # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
        try:
            from diff_gaussian_rasterization import SparseGaussianAdam
            SPARSE_ADAM_AVAILABLE = True
        except:
            SPARSE_ADAM_AVAILABLE = False
        
        # æ¸²æŸ“
        render_result = render(camera, gaussians, pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, False)
        rendered_image = torch.clamp(render_result["render"], 0.0, 1.0)
        
        # GTå›¾åƒ
        gt_image = torch.clamp(camera.original_image.to("cuda"), 0.0, 1.0)
        
        # è®¡ç®—æŒ‡æ ‡
        psnr_val = psnr(rendered_image, gt_image).mean().item()
        l1_val = l1_loss(rendered_image, gt_image).mean().item()
        
        # è½¬æ¢ä¸ºnumpyç”¨äºå¯è§†åŒ–
        rendered_np = rendered_image.detach().cpu().numpy().transpose(1, 2, 0)
        gt_np = gt_image.detach().cpu().numpy().transpose(1, 2, 0)
        
        # æ¸…ç†å†…å­˜
        del gaussians, render_result, rendered_image, gt_image
        torch.cuda.empty_cache()
        
        return (rendered_np, gt_np), {
            "psnr": psnr_val,
            "l1_loss": l1_val,
            "gaussian_count": gaussian_count
        }
        
    except torch.cuda.OutOfMemoryError as e:
        print(f"    âš ï¸ GPUå†…å­˜ä¸è¶³: {str(e)[:100]}...")
        torch.cuda.empty_cache()
        return None, {"error": "CUDA OOM"}
    except Exception as e:
        print(f"    âŒ æ¸²æŸ“å¤±è´¥: {str(e)}")
        torch.cuda.empty_cache()
        return None, {"error": str(e)}

def create_size_comparison_visualization(layers_dir, output_dir='size_visual_comparison'):
    """åˆ›å»ºå°ºå¯¸åˆ†å±‚çš„å¯è§†åŒ–å¯¹æ¯”"""
    print("ğŸ¨ åˆ›å»ºå°ºå¯¸åˆ†å±‚å¯è§†åŒ–å¯¹æ¯”")
    print("=" * 50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¾ç½®æ¸²æŸ“ç¯å¢ƒ
    pipeline_parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(pipeline_parser)
    pipe_args = pipeline_parser.parse_args([])
    pipe = pipe_parser.extract(pipe_args)
    
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # åŠ è½½ç›¸æœº (ä½¿ç”¨4xç¼©æ”¾èŠ‚çœå†…å­˜)
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    camera = load_test_camera(colmap_path, images_path, "000001.jpg", 4.0)
    
    if camera is None:
        return
    
    print(f"âœ… åŠ è½½æµ‹è¯•ç›¸æœº: 000001.jpg (åˆ†è¾¨ç‡: {camera.image_width}x{camera.image_height})")
    
    # æŸ¥æ‰¾æ‰€æœ‰å•å±‚PLYæ–‡ä»¶
    single_layer_files = sorted(glob.glob(os.path.join(layers_dir, "size_layer_*.ply")))
    
    print(f"ğŸ“ æ‰¾åˆ°å•å±‚æ–‡ä»¶: {len(single_layer_files)}ä¸ª")
    
    # æ¸²æŸ“å•å±‚æ–‡ä»¶
    single_layer_results = []
    layer_names = ['è¶…å°çƒ', 'å°çƒ', 'ä¸­çƒ', 'å¤§çƒ', 'è¶…å¤§çƒ']
    
    for i, layer_file in enumerate(single_layer_files):
        filename = os.path.basename(layer_file)
        layer_name = layer_names[i] if i < len(layer_names) else f"å±‚{i}"
        print(f"\nğŸ¯ æ¸²æŸ“ {layer_name}: {filename}")
        
        images, metrics = render_ply_file_safe(layer_file, camera, pipe, background)
        single_layer_results.append((images, metrics, i, layer_name))
        
        if images is not None:
            print(f"    âœ… PSNR: {metrics['psnr']:.2f}dB, çƒæ•°: {metrics['gaussian_count']:,}")
        else:
            print(f"    âŒ æ¸²æŸ“å¤±è´¥: {metrics.get('error', 'Unknown')}")
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾...")
    
    # è®¡ç®—å¸ƒå±€
    num_layers = len(single_layer_results)
    cols = min(3, num_layers)  # æœ€å¤š3åˆ—
    rows = (num_layers + cols - 1) // cols  # è®¡ç®—éœ€è¦çš„è¡Œæ•°
    
    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))
    if rows == 1:
        axes = [axes] if num_layers == 1 else list(axes)
    else:
        axes = axes.flatten()
    
    fig.suptitle('å°ºå¯¸åˆ†å±‚æ¸²æŸ“å¯¹æ¯” - Camera 000001.jpg', fontsize=16, fontweight='bold')
    
    # ç»˜åˆ¶æ¯å±‚ç»“æœ
    for i, (images, metrics, layer_id, layer_name) in enumerate(single_layer_results):
        ax = axes[i]
        
        if images is not None:
            ax.imshow(images[0])  # æ˜¾ç¤ºæ¸²æŸ“å›¾åƒ
            title = f"{layer_name}\n{metrics['gaussian_count']:,}çƒ\nPSNR: {metrics['psnr']:.2f}dB"
        else:
            ax.text(0.5, 0.5, f"{layer_name}\næ¸²æŸ“å¤±è´¥\n{metrics.get('error', '')}", 
                   ha='center', va='center', transform=ax.transAxes, fontsize=10)
            title = f"{layer_name}\næ¸²æŸ“å¤±è´¥"
        
        ax.set_title(title, fontsize=12)
        ax.axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(num_layers, len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_file = os.path.join(output_dir, 'size_layers_comparison.png')
    plt.savefig(output_file, dpi=200, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å¯è§†åŒ–ä¿å­˜: {output_file}")
    
    # åˆ›å»ºç»Ÿè®¡åˆ†æå›¾
    print(f"\nğŸ“Š ç”Ÿæˆç»Ÿè®¡åˆ†æå›¾...")
    
    # æå–æˆåŠŸæ¸²æŸ“çš„æ•°æ®
    successful_results = [(images, metrics, layer_id, layer_name) 
                         for images, metrics, layer_id, layer_name in single_layer_results 
                         if images is not None]
    
    if len(successful_results) > 0:
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('å°ºå¯¸åˆ†å±‚ç»Ÿè®¡åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. PSNRå¯¹æ¯”
        ax = axes[0, 0]
        psnr_values = [metrics['psnr'] for _, metrics, _, _ in successful_results]
        layer_labels = [layer_name for _, _, _, layer_name in successful_results]
        
        bars = ax.bar(range(len(psnr_values)), psnr_values, 
                     color=['red', 'orange', 'yellow', 'green', 'blue'][:len(psnr_values)])
        ax.set_xticks(range(len(psnr_values)))
        ax.set_xticklabels(layer_labels, rotation=45)
        ax.set_ylabel('PSNR (dB)')
        ax.set_title('å„å±‚PSNRå¯¹æ¯”')
        
        # æ ‡æ³¨æ•°å€¼
        for i, (bar, psnr_val) in enumerate(zip(bars, psnr_values)):
            height = bar.get_height()
            ax.annotate(f'{psnr_val:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),
                       xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
        
        # 2. é«˜æ–¯çƒæ•°é‡åˆ†å¸ƒ
        ax = axes[0, 1]
        gaussian_counts = [metrics['gaussian_count'] for _, metrics, _, _ in successful_results]
        
        ax.pie(gaussian_counts, labels=layer_labels, autopct='%1.1f%%', startangle=90)
        ax.set_title('é«˜æ–¯çƒæ•°é‡åˆ†å¸ƒ')
        
        # 3. æ•ˆç‡åˆ†æ (PSNR/é«˜æ–¯çƒæ•°)
        ax = axes[1, 0]
        efficiency = [psnr / (count / 100000) for psnr, count in zip(psnr_values, gaussian_counts)]
        
        bars = ax.bar(range(len(efficiency)), efficiency,
                     color=['red', 'orange', 'yellow', 'green', 'blue'][:len(efficiency)])
        ax.set_xticks(range(len(efficiency)))
        ax.set_xticklabels(layer_labels, rotation=45)
        ax.set_ylabel('PSNR per 100k Gaussians')
        ax.set_title('æ¸²æŸ“æ•ˆç‡åˆ†æ')
        
        # 4. å°ºå¯¸èŒƒå›´è¯´æ˜
        ax = axes[1, 1]
        ax.axis('off')
        
        # è¯»å–åˆ†å±‚ä¿¡æ¯
        manifest_path = os.path.join(layers_dir, 'size_layers_manifest.json')
        if os.path.exists(manifest_path):
            with open(manifest_path, 'r') as f:
                manifest = json.load(f)
            
            layer_info = manifest.get('layer_info', [])
            
            info_text = "å°ºå¯¸åˆ†å±‚æ–¹æ¡ˆ:\n\n"
            for layer in layer_info:
                if layer['layer_id'] < len(successful_results):
                    info_text += f"å±‚{layer['layer_id']} ({layer['name']}):\n"
                    info_text += f"  å°ºå¯¸èŒƒå›´: {layer['threshold_range']}\n"
                    info_text += f"  é«˜æ–¯çƒæ•°: {layer['count']:,} ({layer['percentage']:.1f}%)\n\n"
            
            ax.text(0.05, 0.95, info_text, transform=ax.transAxes, fontsize=10,
                   verticalalignment='top', fontfamily='monospace')
        else:
            ax.text(0.5, 0.5, 'æœªæ‰¾åˆ°åˆ†å±‚ä¿¡æ¯', transform=ax.transAxes, ha='center', va='center')
        
        ax.set_title('åˆ†å±‚æ–¹æ¡ˆè¯¦æƒ…')
        
        plt.tight_layout()
        
        # ä¿å­˜ç»Ÿè®¡å›¾
        stats_file = os.path.join(output_dir, 'size_layers_statistics.png')
        plt.savefig(stats_file, dpi=200, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ç»Ÿè®¡å›¾ä¿å­˜: {stats_file}")
    
    # ä¿å­˜ç»“æœæ‘˜è¦
    summary = {
        'test_camera': '000001.jpg',
        'resolution_scale': 4.0,
        'total_layers': len(single_layer_results),
        'successful_renders': len(successful_results),
        'results': [
            {
                'layer_id': layer_id,
                'layer_name': layer_name,
                'success': images is not None,
                'psnr': metrics.get('psnr', 0) if images is not None else None,
                'gaussian_count': metrics.get('gaussian_count', 0) if images is not None else None,
                'error': metrics.get('error') if images is None else None
            }
            for images, metrics, layer_id, layer_name in single_layer_results
        ]
    }
    
    summary_file = os.path.join(output_dir, 'size_comparison_summary.json')
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"âœ… ç»“æœæ‘˜è¦: {summary_file}")
    
    return summary

def main():
    print("ğŸ¨ å°ºå¯¸åˆ†å±‚å¯è§†åŒ–å¯¹æ¯”")
    print("=" * 40)
    
    layers_dir = "size_based_layers"
    
    if not os.path.exists(layers_dir):
        print(f"âŒ åˆ†å±‚ç›®å½•ä¸å­˜åœ¨: {layers_dir}")
        print("è¯·å…ˆè¿è¡Œ create_size_based_layers.py")
        return
    
    # æ‰§è¡Œå¯è§†åŒ–
    summary = create_size_comparison_visualization(layers_dir)
    
    if summary:
        print(f"\nğŸ‰ å°ºå¯¸åˆ†å±‚å¯è§†åŒ–å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: size_visual_comparison/")
        print(f"âœ… æˆåŠŸæ¸²æŸ“: {summary['successful_renders']}/{summary['total_layers']} å±‚")
        
        # æ‰“å°æˆåŠŸçš„å±‚
        for result in summary['results']:
            if result['success']:
                print(f"  {result['layer_name']}: {result['psnr']:.2f}dB ({result['gaussian_count']:,}çƒ)")
            else:
                print(f"  {result['layer_name']}: å¤±è´¥ ({result['error']})")

if __name__ == "__main__":
    main() 