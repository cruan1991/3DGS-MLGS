import os
import sys
import torch
import numpy as np
from PIL import Image
import argparse
import json

# æ·»åŠ 3dgsæ ¹ç›®å½•åˆ°path
sys.path.append('/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs')

from scene import Scene, GaussianModel
from utils.general_utils import PILtoTorch
from utils.loss_utils import l1_loss, ssim
from utils.graphics_utils import focal2fov
from scene.cameras import Camera
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from arguments import ModelParams, PipelineParams
from gaussian_renderer import render

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def verify_colmap_loading():
    """éªŒè¯COLMAPæ•°æ®åŠ è½½çš„æ­£ç¡®æ€§"""
    print("ğŸ” éªŒè¯COLMAPæ•°æ®åŠ è½½...")
    
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    # åŠ è½½COLMAPæ•°æ®
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    print(f"âœ… ç›¸æœºå†…å‚æ•°é‡: {len(cam_intrinsics)}")
    print(f"âœ… ç›¸æœºå¤–å‚æ•°é‡: {len(cam_extrinsics)}")
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªç›¸æœºçš„è¯¦ç»†å‚æ•°
    first_img_id = list(cam_extrinsics.keys())[0]
    first_img = cam_extrinsics[first_img_id]
    first_cam = cam_intrinsics[first_img.camera_id]
    
    print(f"\nğŸ“· ç¬¬ä¸€ä¸ªç›¸æœºè¯¦ç»†ä¿¡æ¯:")
    print(f"  å›¾ç‰‡ID: {first_img_id}")
    print(f"  å›¾ç‰‡å: {first_img.name}")
    print(f"  ç›¸æœºæ¨¡å‹: {first_cam.model}")
    print(f"  åˆ†è¾¨ç‡: {first_cam.width}x{first_cam.height}")
    print(f"  å†…å‚: {first_cam.params}")
    print(f"  å››å…ƒæ•°: {first_img.qvec}")
    print(f"  å¹³ç§»: {first_img.tvec}")
    
    return cam_intrinsics, cam_extrinsics

def verify_camera_construction(cam_intrinsics, cam_extrinsics, resolution_scale=2.0):
    """éªŒè¯Cameraå¯¹è±¡æ„é€ çš„æ­£ç¡®æ€§"""
    print(f"\nğŸ—ï¸ éªŒè¯Cameraå¯¹è±¡æ„é€  (resolution_scale={resolution_scale})...")
    
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    
    # å–ç¬¬ä¸€ä¸ªç›¸æœºè¿›è¡Œè¯¦ç»†éªŒè¯
    first_img_id = list(cam_extrinsics.keys())[0]
    img_info = cam_extrinsics[first_img_id]
    intrinsic = cam_intrinsics[img_info.camera_id]
    
    # è§£æå†…å‚
    fx, fy, cx, cy = intrinsic.params
    
    # åº”ç”¨åˆ†è¾¨ç‡ç¼©æ”¾
    width = int(intrinsic.width / resolution_scale)
    height = int(intrinsic.height / resolution_scale)
    fx_scaled = fx / resolution_scale
    fy_scaled = fy / resolution_scale
    cx_scaled = cx / resolution_scale
    cy_scaled = cy / resolution_scale
    
    print(f"ğŸ“ åŸå§‹åˆ†è¾¨ç‡: {intrinsic.width}x{intrinsic.height}")
    print(f"ğŸ“ ç¼©æ”¾ååˆ†è¾¨ç‡: {width}x{height}")
    print(f"ğŸ“ åŸå§‹ç„¦è·: fx={fx:.2f}, fy={fy:.2f}")
    print(f"ğŸ“ ç¼©æ”¾åç„¦è·: fx={fx_scaled:.2f}, fy={fy_scaled:.2f}")
    
    # è®¡ç®—FoV
    FoVx = focal2fov(fx_scaled, width)
    FoVy = focal2fov(fy_scaled, height)
    
    print(f"ğŸ” FoVx: {np.degrees(FoVx):.3f}Â°")
    print(f"ğŸ” FoVy: {np.degrees(FoVy):.3f}Â°")
    
    # å¤–å‚
    R = np.transpose(qvec2rotmat(img_info.qvec))
    T = np.array(img_info.tvec)
    
    print(f"ğŸ”„ æ—‹è½¬çŸ©é˜µRå½¢çŠ¶: {R.shape}")
    print(f"ğŸ”„ å¹³ç§»å‘é‡T: {T}")
    
    # åŠ è½½å›¾åƒ
    image_path = os.path.join(images_path, img_info.name)
    print(f"ğŸ“¸ åŠ è½½å›¾åƒ: {image_path}")
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return None
    
    image = Image.open(image_path)
    original_size = image.size
    print(f"ğŸ“¸ åŸå§‹å›¾åƒå°ºå¯¸: {original_size}")
    
    # è°ƒæ•´å›¾åƒå°ºå¯¸
    if resolution_scale != 1.0:
        new_size = (width, height)
        image = image.resize(new_size, Image.LANCZOS)
        print(f"ğŸ“¸ è°ƒæ•´åå›¾åƒå°ºå¯¸: {image.size}")
    
    # è½¬æ¢ä¸ºtensor
    im_data = PILtoTorch(image, (width, height))
    print(f"ğŸ“¸ Tensorå½¢çŠ¶: {im_data.shape}")
    print(f"ğŸ“¸ Tensoræ•°å€¼èŒƒå›´: [{im_data.min():.3f}, {im_data.max():.3f}]")
    
    # åˆ›å»ºCameraå¯¹è±¡
    camera = Camera(
        resolution=(width, height),
        colmap_id=first_img_id,
        R=R,
        T=T,
        FoVx=FoVx,
        FoVy=FoVy,
        depth_params=None,
        image=image,
        invdepthmap=None,
        image_name=img_info.name,
        uid=0,
        data_device="cuda",
        train_test_exp=False,
        is_test_dataset=False,
        is_test_view=False
    )
    
    print(f"âœ… Cameraå¯¹è±¡åˆ›å»ºæˆåŠŸ")
    print(f"   - image_width: {camera.image_width}")
    print(f"   - image_height: {camera.image_height}")
    print(f"   - FoVx: {np.degrees(camera.FoVx):.3f}Â°")
    print(f"   - FoVy: {np.degrees(camera.FoVy):.3f}Â°")
    print(f"   - original_image shape: {camera.original_image.shape}")
    
    return camera

def verify_gaussian_loading(ply_path):
    """éªŒè¯é«˜æ–¯æ¨¡å‹åŠ è½½"""
    print(f"\nğŸ¯ éªŒè¯é«˜æ–¯æ¨¡å‹åŠ è½½...")
    print(f"PLYè·¯å¾„: {ply_path}")
    
    if not os.path.exists(ply_path):
        print(f"âŒ PLYæ–‡ä»¶ä¸å­˜åœ¨: {ply_path}")
        return None
    
    gaussians = GaussianModel(3)
    gaussians.load_ply(ply_path, use_train_test_exp=False)
    
    print(f"âœ… åŠ è½½äº† {gaussians.get_xyz.shape[0]} ä¸ªé«˜æ–¯çƒ")
    print(f"   - ä½ç½®èŒƒå›´: x[{gaussians.get_xyz[:, 0].min():.3f}, {gaussians.get_xyz[:, 0].max():.3f}]")
    print(f"   - ä½ç½®èŒƒå›´: y[{gaussians.get_xyz[:, 1].min():.3f}, {gaussians.get_xyz[:, 1].max():.3f}]")
    print(f"   - ä½ç½®èŒƒå›´: z[{gaussians.get_xyz[:, 2].min():.3f}, {gaussians.get_xyz[:, 2].max():.3f}]")
    print(f"   - é€æ˜åº¦èŒƒå›´: [{gaussians.get_opacity.min():.3f}, {gaussians.get_opacity.max():.3f}]")
    
    return gaussians

def verify_rendering_parameters():
    """éªŒè¯æ¸²æŸ“å‚æ•°è®¾ç½®"""
    print(f"\nâš™ï¸ éªŒè¯æ¸²æŸ“å‚æ•°...")
    
    # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
    try:
        from diff_gaussian_rasterization import SparseGaussianAdam
        SPARSE_ADAM_AVAILABLE = True
        print(f"âœ… SparseGaussianAdam å¯ç”¨")
    except:
        SPARSE_ADAM_AVAILABLE = False
        print(f"âŒ SparseGaussianAdam ä¸å¯ç”¨")
    
    # Pipelineå‚æ•°
    parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(parser)
    args = parser.parse_args([])
    pipe = pipe_parser.extract(args)
    
    print(f"âœ… Pipelineå‚æ•°:")
    print(f"   - convert_SHs_python: {pipe.convert_SHs_python}")
    print(f"   - compute_cov3D_python: {pipe.compute_cov3D_python}")
    print(f"   - debug: {pipe.debug}")
    
    # èƒŒæ™¯è®¾ç½®
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    print(f"âœ… èƒŒæ™¯é¢œè‰²: {background}")
    
    # æ¸²æŸ“å‚æ•°
    renderArgs = (pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, False)
    print(f"âœ… æ¸²æŸ“å‚æ•°: scaling_modifier=1.0, separate_sh={SPARSE_ADAM_AVAILABLE}, train_test_exp=False")
    
    return pipe, background, renderArgs

def verify_single_render(camera, gaussians, renderArgs):
    """éªŒè¯å•æ¬¡æ¸²æŸ“è¿‡ç¨‹"""
    print(f"\nğŸ¨ éªŒè¯å•æ¬¡æ¸²æŸ“...")
    
    # æ‰§è¡Œæ¸²æŸ“
    print(f"ğŸ“¸ æ¸²æŸ“ç›¸æœº: {camera.image_name}")
    render_result = render(camera, gaussians, *renderArgs)
    rendered_image = torch.clamp(render_result["render"], 0.0, 1.0)
    
    print(f"âœ… æ¸²æŸ“æˆåŠŸ")
    print(f"   - æ¸²æŸ“å›¾åƒå½¢çŠ¶: {rendered_image.shape}")
    print(f"   - æ¸²æŸ“å›¾åƒæ•°å€¼èŒƒå›´: [{rendered_image.min():.3f}, {rendered_image.max():.3f}]")
    
    # GTå›¾åƒ
    gt_image = torch.clamp(camera.original_image.to("cuda"), 0.0, 1.0)
    print(f"   - GTå›¾åƒå½¢çŠ¶: {gt_image.shape}")
    print(f"   - GTå›¾åƒæ•°å€¼èŒƒå›´: [{gt_image.min():.3f}, {gt_image.max():.3f}]")
    
    # æ£€æŸ¥å°ºå¯¸åŒ¹é…
    if rendered_image.shape != gt_image.shape:
        print(f"âŒ å°ºå¯¸ä¸åŒ¹é…!")
        print(f"   æ¸²æŸ“: {rendered_image.shape}")
        print(f"   GT: {gt_image.shape}")
        return None, None
    
    return rendered_image, gt_image

def verify_psnr_calculation(rendered_image, gt_image):
    """éªŒè¯PSNRè®¡ç®—"""
    print(f"\nğŸ“Š éªŒè¯PSNRè®¡ç®—...")
    
    # æ–¹æ³•1: ä½¿ç”¨è‡ªå®šä¹‰psnrå‡½æ•°
    psnr1 = psnr(rendered_image, gt_image).mean().item()
    print(f"âœ… æ–¹æ³•1 (è‡ªå®šä¹‰psnr): {psnr1:.3f} dB")
    
    # æ–¹æ³•2: å°è¯•ä½¿ç”¨utils.image_utils.psnr
    try:
        from utils.image_utils import psnr as train_psnr
        psnr2 = train_psnr(rendered_image, gt_image)
        print(f"âœ… æ–¹æ³•2 (utils.image_utils.psnr): {psnr2:.3f} dB")
    except Exception as e:
        print(f"âŒ æ–¹æ³•2å¤±è´¥: {e}")
        psnr2 = None
    
    # æ–¹æ³•3: æ‰‹åŠ¨è®¡ç®—
    mse = torch.mean((rendered_image - gt_image) ** 2)
    psnr3 = 20 * torch.log10(1.0 / torch.sqrt(mse)).item()
    print(f"âœ… æ–¹æ³•3 (æ‰‹åŠ¨è®¡ç®—): {psnr3:.3f} dB")
    
    # L1 loss
    l1 = l1_loss(rendered_image, gt_image).mean().item()
    print(f"âœ… L1 Loss: {l1:.6f}")
    
    return psnr1, l1

def save_verification_images(rendered_image, gt_image, camera_name):
    """ä¿å­˜éªŒè¯å›¾åƒ"""
    print(f"\nğŸ’¾ ä¿å­˜éªŒè¯å›¾åƒ...")
    
    os.makedirs("verification_output", exist_ok=True)
    
    # ä¿å­˜æ¸²æŸ“å›¾åƒ
    from torchvision.utils import save_image
    save_image(rendered_image, f"verification_output/{camera_name}_render.png")
    save_image(gt_image, f"verification_output/{camera_name}_gt.png")
    
    # ä¿å­˜å·®å¼‚å›¾
    diff = torch.abs(rendered_image - gt_image)
    save_image(diff, f"verification_output/{camera_name}_diff.png")
    
    print(f"âœ… å›¾åƒå·²ä¿å­˜åˆ° verification_output/")

def main():
    print("ğŸ” 3DGSæ¸²æŸ“Pipelineå®Œæ•´éªŒè¯\n" + "="*50)
    
    # å‚æ•°
    model_path = "./output/truck-150w"
    ply_path = "./output/truck-150w/gaussian_ball/iteration_994230_best_psnr/gaussian_ball.ply"
    
    # 1. éªŒè¯COLMAPåŠ è½½
    cam_intrinsics, cam_extrinsics = verify_colmap_loading()
    
    # 2. éªŒè¯Cameraæ„é€ 
    camera = verify_camera_construction(cam_intrinsics, cam_extrinsics, resolution_scale=2.0)
    if camera is None:
        print("âŒ Cameraæ„é€ å¤±è´¥ï¼Œç»ˆæ­¢éªŒè¯")
        return
    
    # 3. éªŒè¯é«˜æ–¯æ¨¡å‹åŠ è½½
    gaussians = verify_gaussian_loading(ply_path)
    if gaussians is None:
        print("âŒ é«˜æ–¯æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢éªŒè¯")
        return
    
    # 4. éªŒè¯æ¸²æŸ“å‚æ•°
    pipe, background, renderArgs = verify_rendering_parameters()
    
    # 5. éªŒè¯å•æ¬¡æ¸²æŸ“
    rendered_image, gt_image = verify_single_render(camera, gaussians, renderArgs)
    if rendered_image is None:
        print("âŒ æ¸²æŸ“å¤±è´¥ï¼Œç»ˆæ­¢éªŒè¯")
        return
    
    # 6. éªŒè¯PSNRè®¡ç®—
    psnr_value, l1_value = verify_psnr_calculation(rendered_image, gt_image)
    
    # 7. ä¿å­˜éªŒè¯å›¾åƒ
    save_verification_images(rendered_image, gt_image, camera.image_name.replace('.jpg', ''))
    
    print(f"\nğŸ‰ éªŒè¯å®Œæˆ!")
    print(f"ğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"   - PSNR: {psnr_value:.3f} dB")
    print(f"   - L1 Loss: {l1_value:.6f}")
    print(f"   - ç›¸æœº: {camera.image_name}")

if __name__ == "__main__":
    main() 