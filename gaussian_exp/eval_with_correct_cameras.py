#!/usr/bin/env python3
# ä½¿ç”¨çœŸå®COLMAPç›¸æœºå‚æ•°çš„è¯„ä¼°è„šæœ¬
import sys
sys.path.append("/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs")

import torch
import os
import argparse
from scene import GaussianModel
from arguments import PipelineParams
from gaussian_renderer import render
from scene.colmap_loader import read_intrinsics_binary, read_extrinsics_binary, qvec2rotmat
from utils.graphics_utils import focal2fov
from utils.camera_utils import Camera
from PIL import Image
from utils.general_utils import PILtoTorch
import numpy as np

# Set CUDA device
torch.cuda.set_device(1)

def psnr(img1, img2):
    """æŒ‰ç…§train.pyçš„PSNRè®¡ç®—"""
    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)
    return 20 * torch.log10(1.0 / torch.sqrt(mse))

def load_cameras_from_colmap(colmap_path, images_path, resolution_scale=1.0):
    """ä»COLMAPæ•°æ®ç›´æ¥åŠ è½½ç›¸æœºï¼Œä½¿ç”¨çœŸå®çš„ç›¸æœºå‚æ•°"""
    cameras_bin = os.path.join(colmap_path, 'cameras.bin')
    images_bin = os.path.join(colmap_path, 'images.bin')
    
    cam_intrinsics = read_intrinsics_binary(cameras_bin)
    cam_extrinsics = read_extrinsics_binary(images_bin)
    
    cameras = []
    
    print(f"ğŸ“· ä»COLMAPåŠ è½½ {len(cam_extrinsics)} ä¸ªç›¸æœº")
    
    for idx, (img_id, img_info) in enumerate(cam_extrinsics.items()):
        # è·å–å†…å‚
        cam_id = img_info.camera_id
        intrinsic = cam_intrinsics[cam_id]
        
        # è§£æå†…å‚
        if intrinsic.model == 'PINHOLE':
            fx, fy, cx, cy = intrinsic.params
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç›¸æœºæ¨¡å‹: {intrinsic.model}")
        
        # åº”ç”¨åˆ†è¾¨ç‡ç¼©æ”¾
        width = int(intrinsic.width / resolution_scale)
        height = int(intrinsic.height / resolution_scale)
        fx = fx / resolution_scale
        fy = fy / resolution_scale
        cx = cx / resolution_scale
        cy = cy / resolution_scale
        
        # è®¡ç®—æ­£ç¡®çš„FoV
        FoVx = focal2fov(fx, width)
        FoVy = focal2fov(fy, height)
        
        # å¤–å‚ï¼ˆå‚ç…§dataset_readers.pyçš„æ–¹å¼ï¼‰
        R = np.transpose(qvec2rotmat(img_info.qvec))
        T = np.array(img_info.tvec)
        
        # åŠ è½½å›¾åƒ
        image_path = os.path.join(images_path, img_info.name)
        image = Image.open(image_path)
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        if resolution_scale != 1.0:
            new_size = (width, height)
            image = image.resize(new_size, Image.LANCZOS)
        
        # è½¬æ¢ä¸ºtensor
        im_data = PILtoTorch(image, (width, height))
        
        # åˆ›å»ºç›¸æœºï¼ˆå‚ç…§camera_utils.pyä¸­loadCamçš„æ–¹å¼ï¼‰
        camera = Camera(
            resolution=(width, height),
            colmap_id=img_id,
            R=R,
            T=T,
            FoVx=FoVx,
            FoVy=FoVy,
            depth_params=None,
            image=image,
            invdepthmap=None,
            image_name=img_info.name,
            uid=idx,
            data_device="cuda",
            train_test_exp=False,
            is_test_dataset=False,
            is_test_view=False
        )
        
        cameras.append(camera)
        
        if idx < 3:  # æ˜¾ç¤ºå‰å‡ ä¸ªç›¸æœºçš„å‚æ•°
            print(f"  ç›¸æœº {idx} ({img_info.name}): {width}x{height}, FoVx={np.degrees(FoVx):.1f}Â°, FoVy={np.degrees(FoVy):.1f}Â°")
    
    return cameras

def eval_with_correct_cameras(model_path, ply_path):
    print("ğŸš€ ä½¿ç”¨çœŸå®COLMAPç›¸æœºå‚æ•°è¿›è¡Œè¯„ä¼°")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"ğŸ¯ PLYæ–‡ä»¶: {ply_path}")
    
    # æ£€æŸ¥SPARSE_ADAM_AVAILABLE
    try:
        from diff_gaussian_rasterization import SparseGaussianAdam
        SPARSE_ADAM_AVAILABLE = True
    except:
        SPARSE_ADAM_AVAILABLE = False
    
    print(f"ğŸ”§ SPARSE_ADAM_AVAILABLE: {SPARSE_ADAM_AVAILABLE}")
    
    # åŠ è½½é«˜æ–¯æ¨¡å‹
    gaussians = GaussianModel(3)
    gaussians.load_ply(ply_path, use_train_test_exp=False)
    print(f"âœ… åŠ è½½äº† {gaussians.get_xyz.shape[0]} ä¸ªé«˜æ–¯çƒ")
    
    # è®¾ç½®Pipelineå‚æ•°
    parser = argparse.ArgumentParser()
    pipe_parser = PipelineParams(parser)
    args = parser.parse_args([])
    pipe = pipe_parser.extract(args)
    
    # èƒŒæ™¯è®¾ç½®ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # ä»COLMAPåŠ è½½ç›¸æœºï¼ˆä½¿ç”¨é€‚å½“çš„åˆ†è¾¨ç‡ç¼©æ”¾ï¼‰
    colmap_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/sparse/0"
    images_path = "/shared/user59/workspace/cihan/3dgs_Vincent/my_3dgs/data/mipnerf360/360/tandt_db/tandt/truck/images"
    
    # å›åˆ°æœ€ä½³åˆ†è¾¨ç‡è®¾ç½®
    resolution_scale = 2.0  # è¿™ä¸ªè®¾ç½®ç»™å‡ºäº†æœ€å¥½çš„ç»“æœ
    cameras = load_cameras_from_colmap(colmap_path, images_path, resolution_scale)
    
    print(f"âœ… åŠ è½½äº† {len(cameras)} ä¸ªç›¸æœº")
    
    # æ¸²æŸ“å‚æ•°
    renderArgs = (pipe, background, 1., SPARSE_ADAM_AVAILABLE, None, False)  # train_test_exp=False
    
    # ğŸ” åªæŒ‰ç…§train.pyçš„æ–¹å¼é€‰æ‹©5ä¸ªç›¸æœºè¿›è¡Œå¿«é€Ÿè¯„ä¼°
    train_camera_indices = [idx % len(cameras) for idx in range(5, 30, 5)]
    selected_cameras = [cameras[idx] for idx in train_camera_indices]
    
    print(f"ğŸ¯ å¿«é€Ÿè¯„ä¼°ï¼šä½¿ç”¨ç´¢å¼• {train_camera_indices} çš„5ä¸ªè®­ç»ƒç›¸æœº...")
    total_psnr = 0.0
    camera_count = len(selected_cameras)
    
    for i, camera in enumerate(selected_cameras):
        camera_idx = train_camera_indices[i]
        # æ¸²æŸ“
        rendered = torch.clamp(render(camera, gaussians, *renderArgs)["render"], 0.0, 1.0)
        gt_image = torch.clamp(camera.original_image.to("cuda"), 0.0, 1.0)
        
        # è®¡ç®—PSNR
        psnr_val = psnr(rendered, gt_image).mean().item()
        total_psnr += psnr_val
    
    avg_psnr = total_psnr / camera_count
    print(f"ğŸ‰ è®­ç»ƒé£æ ¼è¯„ä¼°PSNR: {avg_psnr:.2f} dB (è¯„ä¼°äº† {camera_count} ä¸ªè®­ç»ƒç›¸æœº)")
    print(f"ğŸ“ˆ è¾¾æˆç‡: {(avg_psnr/33.83)*100:.1f}%")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', required=True)
    parser.add_argument('--ply-path', required=True)
    args = parser.parse_args()
    
    eval_with_correct_cameras(args.model_path, args.ply_path)

if __name__ == "__main__":
    main() 